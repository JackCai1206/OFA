2023-08-08 18:14:43 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-08-08 18:14:43 - utils.py[line:261] - INFO: Start init
2023-08-08 18:14:43 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-08 18:14:43 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2023-08-08 18:14:43 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-08-08 18:14:44 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_2_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 12, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt', 'restore_file': '../../checkpoints/OFA/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid=12, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv,../../dataset/OFA_data/vrd_mix//vg_val_wearing.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, decoder_prompt=True, decoder_prompt_length=100, decoder_prompt_type='prefix', device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, encoder_prompt=True, encoder_prompt_length=100, encoder_prompt_type='prefix', end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=2, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/OFA/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt', save_interval=1, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='vrd2', tensorboard_logdir='./tensorboard/_2_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vrd2', 'data': '../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv,../../dataset/OFA_data/vrd_mix//vg_val_wearing.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-08-08 18:14:44 - vrd2.py[line:90] - INFO: vrd setup: source dictionary: 59461 types
2023-08-08 18:14:44 - vrd2.py[line:91] - INFO: vrd setup: target dictionary: 59461 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-08-08 18:14:47 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_prompt_encoder): PromptEncoder(
      (embedding): Embedding(100, 9216)
    )
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59461, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (decoder_prompt_encoder): PromptEncoder(
      (embedding): Embedding(100, 9216)
    )
    (decoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59461, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59461, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-08-08 18:14:47 - train.py[line:111] - INFO: task: VRD2Task
2023-08-08 18:14:47 - train.py[line:112] - INFO: model: OFAModel
2023-08-08 18:14:47 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-08-08 18:14:47 - train.py[line:114] - INFO: num. shared model params: 184,084,808 (num. trained: 1,843,200)
2023-08-08 18:14:47 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/vrd_mix//vg_val_wearing.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_mix//vg_val_wearing.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_mix//vg_val_wearing.tsv slice_id 0 row count 163494 total row count 163494
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-08-08 18:14:47 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-08-08 18:14:47 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-08-08 18:14:47 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-08-08 18:14:47 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-08-08 18:14:47 - train.py[line:152] - INFO: training on 1 devices (GPUs/TPUs)
2023-08-08 18:14:47 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 12
2023-08-08 18:14:47 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/OFA/ofa_base.pt
2023-08-08 18:14:48 - trainer.py[line:617] - INFO: Loaded checkpoint ../../checkpoints/OFA/ofa_base.pt (epoch 48 @ 0 updates)
2023-08-08 18:14:48 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 row count 395175 total row count 395175
slice_id 0 seek offset 0
Total steps 16466, warmup steps 987, warmup_factor 0.0010131712259371835
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/vrd_2/wandb/run-20230808_181449-3h1afsvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _2_3e-5_512_mix_wearing_prompt
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/3h1afsvo
2023-08-08 18:14:55 - trainer.py[line:703] - INFO: begin training epoch 1
2023-08-08 18:14:55 - train.py[line:305] - INFO: Start iterating over samples
2023-08-08 18:15:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 18:15:11 - progress_bar.py[line:272] - INFO: epoch 001:     11 / 8233 loss=12.752, loss_v1=0, loss_v2=0, nll_loss=12.086, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=4346.78, wps=251.7, ups=0.75, wpb=335.3, bsz=48, num_updates=10, lr=3.03951e-07, gnorm=0.344, clip=0, loss_scale=64, train_wall=15, gb_free=14.5, wall=24
2023-08-08 18:15:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 18:15:24 - progress_bar.py[line:272] - INFO: epoch 001:     22 / 8233 loss=12.734, loss_v1=0, loss_v2=0, nll_loss=12.065, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=4285.7, wps=258.7, ups=0.76, wpb=340.6, bsz=48, num_updates=20, lr=6.07903e-07, gnorm=0.342, clip=0, loss_scale=32, train_wall=13, gb_free=14.5, wall=37
2023-08-08 18:15:36 - progress_bar.py[line:272] - INFO: epoch 001:     32 / 8233 loss=12.717, loss_v1=0, loss_v2=0, nll_loss=12.047, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=4232.48, wps=281.5, ups=0.83, wpb=338.5, bsz=48, num_updates=30, lr=9.11854e-07, gnorm=0.344, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=49
2023-08-08 18:15:48 - progress_bar.py[line:272] - INFO: epoch 001:     42 / 8233 loss=12.733, loss_v1=0, loss_v2=0, nll_loss=12.062, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=4274.96, wps=277.7, ups=0.83, wpb=335.4, bsz=48, num_updates=40, lr=1.21581e-06, gnorm=0.346, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=61
2023-08-08 18:15:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-08 18:16:01 - progress_bar.py[line:272] - INFO: epoch 001:     53 / 8233 loss=12.737, loss_v1=0, loss_v2=0, nll_loss=12.063, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=4277.78, wps=258.5, ups=0.76, wpb=338.8, bsz=48, num_updates=50, lr=1.51976e-06, gnorm=0.35, clip=0, loss_scale=16, train_wall=13, gb_free=14.5, wall=74
2023-08-08 18:16:13 - progress_bar.py[line:272] - INFO: epoch 001:     63 / 8233 loss=12.708, loss_v1=0, loss_v2=0, nll_loss=12.034, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=4194.81, wps=284.6, ups=0.84, wpb=338.8, bsz=48, num_updates=60, lr=1.82371e-06, gnorm=0.345, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=86
2023-08-08 18:16:25 - progress_bar.py[line:272] - INFO: epoch 001:     73 / 8233 loss=12.727, loss_v1=0, loss_v2=0, nll_loss=12.062, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=4274.43, wps=284.2, ups=0.84, wpb=338.9, bsz=48, num_updates=70, lr=2.12766e-06, gnorm=0.337, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=98
2023-08-08 18:16:37 - progress_bar.py[line:272] - INFO: epoch 001:     83 / 8233 loss=12.693, loss_v1=0, loss_v2=0, nll_loss=12.02, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=4152.69, wps=285.1, ups=0.84, wpb=339.9, bsz=48, num_updates=80, lr=2.43161e-06, gnorm=0.34, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=110
2023-08-08 18:16:49 - progress_bar.py[line:272] - INFO: epoch 001:     93 / 8233 loss=12.728, loss_v1=0, loss_v2=0, nll_loss=12.056, ntokens=333.6, nsentences=48, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=4257.73, wps=274.7, ups=0.82, wpb=333.6, bsz=48, num_updates=90, lr=2.73556e-06, gnorm=0.341, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=122
2023-08-08 18:17:01 - progress_bar.py[line:272] - INFO: epoch 001:    103 / 8233 loss=12.663, loss_v1=0, loss_v2=0, nll_loss=11.988, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=4061.41, wps=280, ups=0.83, wpb=338, bsz=48, num_updates=100, lr=3.03951e-06, gnorm=0.342, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=134
2023-08-08 18:17:13 - progress_bar.py[line:272] - INFO: epoch 001:    113 / 8233 loss=12.731, loss_v1=0, loss_v2=0, nll_loss=12.065, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=4285.46, wps=281.2, ups=0.83, wpb=336.8, bsz=48, num_updates=110, lr=3.34347e-06, gnorm=0.345, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=146
2023-08-08 18:17:25 - progress_bar.py[line:272] - INFO: epoch 001:    123 / 8233 loss=12.649, loss_v1=0, loss_v2=0, nll_loss=11.977, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=4031.7, wps=279.6, ups=0.83, wpb=337.8, bsz=48, num_updates=120, lr=3.64742e-06, gnorm=0.343, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=158
2023-08-08 18:17:37 - progress_bar.py[line:272] - INFO: epoch 001:    133 / 8233 loss=12.662, loss_v1=0, loss_v2=0, nll_loss=11.986, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=4056.09, wps=284.1, ups=0.84, wpb=340, bsz=48, num_updates=130, lr=3.95137e-06, gnorm=0.342, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=170
2023-08-08 18:17:49 - progress_bar.py[line:272] - INFO: epoch 001:    143 / 8233 loss=12.633, loss_v1=0, loss_v2=0, nll_loss=11.96, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=3984.22, wps=285.6, ups=0.84, wpb=341, bsz=48, num_updates=140, lr=4.25532e-06, gnorm=0.336, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=182
2023-08-08 18:18:01 - progress_bar.py[line:272] - INFO: epoch 001:    153 / 8233 loss=12.708, loss_v1=0, loss_v2=0, nll_loss=12.043, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=4218.99, wps=285.9, ups=0.84, wpb=340.5, bsz=48, num_updates=150, lr=4.55927e-06, gnorm=0.336, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=194
2023-08-08 18:18:13 - progress_bar.py[line:272] - INFO: epoch 001:    163 / 8233 loss=12.718, loss_v1=0, loss_v2=0, nll_loss=12.052, ntokens=333.6, nsentences=48, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=4246.85, wps=275.6, ups=0.83, wpb=333.6, bsz=48, num_updates=160, lr=4.86322e-06, gnorm=0.338, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=206
2023-08-08 18:18:25 - progress_bar.py[line:272] - INFO: epoch 001:    173 / 8233 loss=12.622, loss_v1=0, loss_v2=0, nll_loss=11.95, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=3957.78, wps=278.6, ups=0.83, wpb=337.5, bsz=48, num_updates=170, lr=5.16717e-06, gnorm=0.327, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=218
2023-08-08 18:18:37 - progress_bar.py[line:272] - INFO: epoch 001:    183 / 8233 loss=12.638, loss_v1=0, loss_v2=0, nll_loss=11.97, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=4011.55, wps=282.7, ups=0.83, wpb=339.4, bsz=48, num_updates=180, lr=5.47112e-06, gnorm=0.337, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=230
2023-08-08 18:18:49 - progress_bar.py[line:272] - INFO: epoch 001:    193 / 8233 loss=12.623, loss_v1=0, loss_v2=0, nll_loss=11.942, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=3934.68, wps=281.9, ups=0.83, wpb=339, bsz=48, num_updates=190, lr=5.77508e-06, gnorm=0.338, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=242
2023-08-08 18:19:01 - progress_bar.py[line:272] - INFO: epoch 001:    203 / 8233 loss=12.613, loss_v1=0, loss_v2=0, nll_loss=11.938, ntokens=341.5, nsentences=48, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=3924.65, wps=284.7, ups=0.83, wpb=341.5, bsz=48, num_updates=200, lr=6.07903e-06, gnorm=0.331, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=254
2023-08-08 18:19:13 - progress_bar.py[line:272] - INFO: epoch 001:    213 / 8233 loss=12.566, loss_v1=0, loss_v2=0, nll_loss=11.885, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=3781.05, wps=279, ups=0.83, wpb=337, bsz=48, num_updates=210, lr=6.38298e-06, gnorm=0.319, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=266
2023-08-08 18:19:25 - progress_bar.py[line:272] - INFO: epoch 001:    223 / 8233 loss=12.641, loss_v1=0, loss_v2=0, nll_loss=11.975, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=4025.1, wps=279.3, ups=0.83, wpb=335.8, bsz=48, num_updates=220, lr=6.68693e-06, gnorm=0.33, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=278
2023-08-08 18:19:37 - progress_bar.py[line:272] - INFO: epoch 001:    233 / 8233 loss=12.582, loss_v1=0, loss_v2=0, nll_loss=11.913, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=3856.01, wps=283.5, ups=0.84, wpb=339.5, bsz=48, num_updates=230, lr=6.99088e-06, gnorm=0.319, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=290
2023-08-08 18:19:49 - progress_bar.py[line:272] - INFO: epoch 001:    243 / 8233 loss=12.563, loss_v1=0, loss_v2=0, nll_loss=11.893, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=3803.77, wps=282.6, ups=0.83, wpb=338.5, bsz=48, num_updates=240, lr=7.29483e-06, gnorm=0.33, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=302
2023-08-08 18:20:01 - progress_bar.py[line:272] - INFO: epoch 001:    253 / 8233 loss=12.517, loss_v1=0, loss_v2=0, nll_loss=11.851, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=3692.84, wps=284.5, ups=0.84, wpb=338.9, bsz=48, num_updates=250, lr=7.59878e-06, gnorm=0.32, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=314
2023-08-08 18:20:13 - progress_bar.py[line:272] - INFO: epoch 001:    263 / 8233 loss=12.567, loss_v1=0, loss_v2=0, nll_loss=11.904, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=3832.28, wps=281, ups=0.83, wpb=337.8, bsz=48, num_updates=260, lr=7.90274e-06, gnorm=0.328, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=326
2023-08-08 18:20:25 - progress_bar.py[line:272] - INFO: epoch 001:    273 / 8233 loss=12.493, loss_v1=0, loss_v2=0, nll_loss=11.821, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=3617.25, wps=280.5, ups=0.83, wpb=338.7, bsz=48, num_updates=270, lr=8.20669e-06, gnorm=0.314, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=338
2023-08-08 18:20:37 - progress_bar.py[line:272] - INFO: epoch 001:    283 / 8233 loss=12.458, loss_v1=0, loss_v2=0, nll_loss=11.776, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=3505.94, wps=278.4, ups=0.83, wpb=335.6, bsz=48, num_updates=280, lr=8.51064e-06, gnorm=0.316, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=350
2023-08-08 18:20:49 - progress_bar.py[line:272] - INFO: epoch 001:    293 / 8233 loss=12.441, loss_v1=0, loss_v2=0, nll_loss=11.766, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=3482.8, wps=282.7, ups=0.84, wpb=337.7, bsz=48, num_updates=290, lr=8.81459e-06, gnorm=0.315, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=362
2023-08-08 18:21:01 - progress_bar.py[line:272] - INFO: epoch 001:    303 / 8233 loss=12.464, loss_v1=0, loss_v2=0, nll_loss=11.799, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=3562.86, wps=281, ups=0.83, wpb=337.8, bsz=48, num_updates=300, lr=9.11854e-06, gnorm=0.316, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=374
2023-08-08 18:21:13 - progress_bar.py[line:272] - INFO: epoch 001:    313 / 8233 loss=12.47, loss_v1=0, loss_v2=0, nll_loss=11.798, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=3559.75, wps=280.6, ups=0.83, wpb=337.3, bsz=48, num_updates=310, lr=9.42249e-06, gnorm=0.312, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=386
2023-08-08 18:21:25 - progress_bar.py[line:272] - INFO: epoch 001:    323 / 8233 loss=12.529, loss_v1=0, loss_v2=0, nll_loss=11.874, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=3753.57, wps=281.8, ups=0.83, wpb=338, bsz=48, num_updates=320, lr=9.72644e-06, gnorm=0.313, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=398
2023-08-08 18:21:38 - progress_bar.py[line:272] - INFO: epoch 001:    333 / 8233 loss=12.492, loss_v1=0, loss_v2=0, nll_loss=11.822, ntokens=334.3, nsentences=48, sample_size=334.3, sample_size_v1=0, sample_size_v2=0, ppl=3620.34, wps=275.4, ups=0.82, wpb=334.3, bsz=48, num_updates=330, lr=1.00304e-05, gnorm=0.308, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=410
2023-08-08 18:21:50 - progress_bar.py[line:272] - INFO: epoch 001:    343 / 8233 loss=12.48, loss_v1=0, loss_v2=0, nll_loss=11.819, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=3612.72, wps=282.2, ups=0.83, wpb=339.2, bsz=48, num_updates=340, lr=1.03343e-05, gnorm=0.305, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=423
2023-08-08 18:22:02 - progress_bar.py[line:272] - INFO: epoch 001:    353 / 8233 loss=12.439, loss_v1=0, loss_v2=0, nll_loss=11.776, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=3507.45, wps=279.8, ups=0.83, wpb=336.5, bsz=48, num_updates=350, lr=1.06383e-05, gnorm=0.308, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=435
2023-08-08 18:22:14 - progress_bar.py[line:272] - INFO: epoch 001:    363 / 8233 loss=12.364, loss_v1=0, loss_v2=0, nll_loss=11.683, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=3286.99, wps=279.8, ups=0.83, wpb=336.7, bsz=48, num_updates=360, lr=1.09422e-05, gnorm=0.308, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=447
2023-08-08 18:22:26 - progress_bar.py[line:272] - INFO: epoch 001:    373 / 8233 loss=12.405, loss_v1=0, loss_v2=0, nll_loss=11.746, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=3434.76, wps=280, ups=0.83, wpb=335.5, bsz=48, num_updates=370, lr=1.12462e-05, gnorm=0.306, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=459
2023-08-08 18:22:38 - progress_bar.py[line:272] - INFO: epoch 001:    383 / 8233 loss=12.425, loss_v1=0, loss_v2=0, nll_loss=11.77, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=3493.04, wps=285.9, ups=0.84, wpb=340.1, bsz=48, num_updates=380, lr=1.15502e-05, gnorm=0.306, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=470
2023-08-08 18:22:50 - progress_bar.py[line:272] - INFO: epoch 001:    393 / 8233 loss=12.403, loss_v1=0, loss_v2=0, nll_loss=11.739, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=3418.83, wps=280.4, ups=0.83, wpb=336.8, bsz=48, num_updates=390, lr=1.18541e-05, gnorm=0.306, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=482
2023-08-08 18:22:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-08 18:23:03 - progress_bar.py[line:272] - INFO: epoch 001:    404 / 8233 loss=12.276, loss_v1=0, loss_v2=0, nll_loss=11.604, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=3113.65, wps=251.1, ups=0.75, wpb=336.6, bsz=48, num_updates=400, lr=1.21581e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=13, gb_free=14.5, wall=496
2023-08-08 18:23:15 - progress_bar.py[line:272] - INFO: epoch 001:    414 / 8233 loss=12.235, loss_v1=0, loss_v2=0, nll_loss=11.558, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=3014.44, wps=280.8, ups=0.83, wpb=336.9, bsz=48, num_updates=410, lr=1.2462e-05, gnorm=0.293, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=508
2023-08-08 18:23:27 - progress_bar.py[line:272] - INFO: epoch 001:    424 / 8233 loss=12.316, loss_v1=0, loss_v2=0, nll_loss=11.649, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=3212.49, wps=279.9, ups=0.83, wpb=335.8, bsz=48, num_updates=420, lr=1.2766e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=520
2023-08-08 18:23:39 - progress_bar.py[line:272] - INFO: epoch 001:    434 / 8233 loss=12.252, loss_v1=0, loss_v2=0, nll_loss=11.588, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=3078.25, wps=284.7, ups=0.83, wpb=341.2, bsz=48, num_updates=430, lr=1.30699e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=532
2023-08-08 18:23:51 - progress_bar.py[line:272] - INFO: epoch 001:    444 / 8233 loss=12.234, loss_v1=0, loss_v2=0, nll_loss=11.565, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=3029.67, wps=279.2, ups=0.83, wpb=336.7, bsz=48, num_updates=440, lr=1.33739e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=544
2023-08-08 18:24:03 - progress_bar.py[line:272] - INFO: epoch 001:    454 / 8233 loss=12.214, loss_v1=0, loss_v2=0, nll_loss=11.54, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=2977.9, wps=281.6, ups=0.83, wpb=339, bsz=48, num_updates=450, lr=1.36778e-05, gnorm=0.289, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=556
2023-08-08 18:24:15 - progress_bar.py[line:272] - INFO: epoch 001:    464 / 8233 loss=12.25, loss_v1=0, loss_v2=0, nll_loss=11.591, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=3084.27, wps=279.1, ups=0.83, wpb=335.3, bsz=48, num_updates=460, lr=1.39818e-05, gnorm=0.291, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=568
2023-08-08 18:24:27 - progress_bar.py[line:272] - INFO: epoch 001:    474 / 8233 loss=12.245, loss_v1=0, loss_v2=0, nll_loss=11.583, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=3068.62, wps=280.6, ups=0.83, wpb=339.3, bsz=48, num_updates=470, lr=1.42857e-05, gnorm=0.289, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=580
2023-08-08 18:24:39 - progress_bar.py[line:272] - INFO: epoch 001:    484 / 8233 loss=12.122, loss_v1=0, loss_v2=0, nll_loss=11.451, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=2799.38, wps=280.1, ups=0.83, wpb=338.7, bsz=48, num_updates=480, lr=1.45897e-05, gnorm=0.287, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=592
2023-08-08 18:24:51 - progress_bar.py[line:272] - INFO: epoch 001:    494 / 8233 loss=12.239, loss_v1=0, loss_v2=0, nll_loss=11.587, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=3076.65, wps=277.2, ups=0.83, wpb=335.8, bsz=48, num_updates=490, lr=1.48936e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=604
2023-08-08 18:25:03 - progress_bar.py[line:272] - INFO: epoch 001:    504 / 8233 loss=12.171, loss_v1=0, loss_v2=0, nll_loss=11.508, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=2912.25, wps=285.3, ups=0.84, wpb=341.7, bsz=48, num_updates=500, lr=1.51976e-05, gnorm=0.285, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=616
2023-08-08 18:25:15 - progress_bar.py[line:272] - INFO: epoch 001:    514 / 8233 loss=12.184, loss_v1=0, loss_v2=0, nll_loss=11.522, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=2941.54, wps=284.8, ups=0.84, wpb=340.5, bsz=48, num_updates=510, lr=1.55015e-05, gnorm=0.282, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=628
2023-08-08 18:25:28 - progress_bar.py[line:272] - INFO: epoch 001:    524 / 8233 loss=12.155, loss_v1=0, loss_v2=0, nll_loss=11.502, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=2899.97, wps=274, ups=0.82, wpb=334.2, bsz=48, num_updates=520, lr=1.58055e-05, gnorm=0.282, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=640
2023-08-08 18:25:40 - progress_bar.py[line:272] - INFO: epoch 001:    534 / 8233 loss=12.113, loss_v1=0, loss_v2=0, nll_loss=11.449, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=2796.15, wps=285.1, ups=0.84, wpb=341.1, bsz=48, num_updates=530, lr=1.61094e-05, gnorm=0.277, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=652
2023-08-08 18:25:52 - progress_bar.py[line:272] - INFO: epoch 001:    544 / 8233 loss=12.023, loss_v1=0, loss_v2=0, nll_loss=11.353, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=2616.26, wps=283.4, ups=0.83, wpb=340, bsz=48, num_updates=540, lr=1.64134e-05, gnorm=0.28, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=664
2023-08-08 18:26:04 - progress_bar.py[line:272] - INFO: epoch 001:    554 / 8233 loss=12.05, loss_v1=0, loss_v2=0, nll_loss=11.397, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=2696.19, wps=280.7, ups=0.83, wpb=337.7, bsz=48, num_updates=550, lr=1.67173e-05, gnorm=0.275, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=676
2023-08-08 18:26:16 - progress_bar.py[line:272] - INFO: epoch 001:    564 / 8233 loss=12.002, loss_v1=0, loss_v2=0, nll_loss=11.338, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=2587.86, wps=281.2, ups=0.83, wpb=337.4, bsz=48, num_updates=560, lr=1.70213e-05, gnorm=0.281, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=688
2023-08-08 18:26:28 - progress_bar.py[line:272] - INFO: epoch 001:    574 / 8233 loss=12.02, loss_v1=0, loss_v2=0, nll_loss=11.359, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=2625.88, wps=284, ups=0.83, wpb=340.4, bsz=48, num_updates=570, lr=1.73252e-05, gnorm=0.273, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=700
2023-08-08 18:26:40 - progress_bar.py[line:272] - INFO: epoch 001:    584 / 8233 loss=11.96, loss_v1=0, loss_v2=0, nll_loss=11.296, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=2514.68, wps=281.8, ups=0.83, wpb=338.8, bsz=48, num_updates=580, lr=1.76292e-05, gnorm=0.277, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=712
2023-08-08 18:26:52 - progress_bar.py[line:272] - INFO: epoch 001:    594 / 8233 loss=11.948, loss_v1=0, loss_v2=0, nll_loss=11.289, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=2501.44, wps=282, ups=0.83, wpb=338.3, bsz=48, num_updates=590, lr=1.79331e-05, gnorm=0.275, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=724
2023-08-08 18:27:04 - progress_bar.py[line:272] - INFO: epoch 001:    604 / 8233 loss=11.863, loss_v1=0, loss_v2=0, nll_loss=11.194, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=2342.28, wps=277.6, ups=0.82, wpb=336.8, bsz=48, num_updates=600, lr=1.82371e-05, gnorm=0.27, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=737
2023-08-08 18:27:16 - progress_bar.py[line:272] - INFO: epoch 001:    614 / 8233 loss=11.945, loss_v1=0, loss_v2=0, nll_loss=11.28, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=2486.24, wps=279.5, ups=0.83, wpb=338.3, bsz=48, num_updates=610, lr=1.8541e-05, gnorm=0.271, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=749
2023-08-08 18:27:28 - progress_bar.py[line:272] - INFO: epoch 001:    624 / 8233 loss=11.889, loss_v1=0, loss_v2=0, nll_loss=11.226, ntokens=342.1, nsentences=48, sample_size=342.1, sample_size_v1=0, sample_size_v2=0, ppl=2394.65, wps=285.7, ups=0.84, wpb=342.1, bsz=48, num_updates=620, lr=1.8845e-05, gnorm=0.266, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=761
2023-08-08 18:27:40 - progress_bar.py[line:272] - INFO: epoch 001:    634 / 8233 loss=11.882, loss_v1=0, loss_v2=0, nll_loss=11.22, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=2385.61, wps=282.4, ups=0.84, wpb=337.8, bsz=48, num_updates=630, lr=1.91489e-05, gnorm=0.271, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=773
2023-08-08 18:27:52 - progress_bar.py[line:272] - INFO: epoch 001:    644 / 8233 loss=11.804, loss_v1=0, loss_v2=0, nll_loss=11.14, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=2256, wps=281.5, ups=0.83, wpb=338.6, bsz=48, num_updates=640, lr=1.94529e-05, gnorm=0.261, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=785
2023-08-08 18:28:04 - progress_bar.py[line:272] - INFO: epoch 001:    654 / 8233 loss=11.824, loss_v1=0, loss_v2=0, nll_loss=11.161, ntokens=342, nsentences=48, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=2290.09, wps=286.7, ups=0.84, wpb=342, bsz=48, num_updates=650, lr=1.97568e-05, gnorm=0.267, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=797
2023-08-08 18:28:16 - progress_bar.py[line:272] - INFO: epoch 001:    664 / 8233 loss=11.728, loss_v1=0, loss_v2=0, nll_loss=11.059, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=2133.68, wps=281, ups=0.83, wpb=338.1, bsz=48, num_updates=660, lr=2.00608e-05, gnorm=0.261, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=809
2023-08-08 18:28:28 - progress_bar.py[line:272] - INFO: epoch 001:    674 / 8233 loss=11.707, loss_v1=0, loss_v2=0, nll_loss=11.043, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=2109.92, wps=282.5, ups=0.83, wpb=340.1, bsz=48, num_updates=670, lr=2.03647e-05, gnorm=0.26, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=821
2023-08-08 18:28:40 - progress_bar.py[line:272] - INFO: epoch 001:    684 / 8233 loss=11.695, loss_v1=0, loss_v2=0, nll_loss=11.03, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=2090.78, wps=279.7, ups=0.83, wpb=338.3, bsz=48, num_updates=680, lr=2.06687e-05, gnorm=0.264, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=833
2023-08-08 18:28:52 - progress_bar.py[line:272] - INFO: epoch 001:    694 / 8233 loss=11.713, loss_v1=0, loss_v2=0, nll_loss=11.06, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=2134.97, wps=281.5, ups=0.83, wpb=338.1, bsz=48, num_updates=690, lr=2.09726e-05, gnorm=0.261, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=845
2023-08-08 18:29:04 - progress_bar.py[line:272] - INFO: epoch 001:    704 / 8233 loss=11.757, loss_v1=0, loss_v2=0, nll_loss=11.104, ntokens=332.5, nsentences=48, sample_size=332.5, sample_size_v1=0, sample_size_v2=0, ppl=2201.55, wps=274.7, ups=0.83, wpb=332.5, bsz=48, num_updates=700, lr=2.12766e-05, gnorm=0.259, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=857
2023-08-08 18:29:16 - progress_bar.py[line:272] - INFO: epoch 001:    714 / 8233 loss=11.616, loss_v1=0, loss_v2=0, nll_loss=10.955, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1985.26, wps=284.5, ups=0.84, wpb=340.2, bsz=48, num_updates=710, lr=2.15805e-05, gnorm=0.257, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=869
2023-08-08 18:29:28 - progress_bar.py[line:272] - INFO: epoch 001:    724 / 8233 loss=11.589, loss_v1=0, loss_v2=0, nll_loss=10.92, ntokens=341.6, nsentences=48, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1936.95, wps=286.9, ups=0.84, wpb=341.6, bsz=48, num_updates=720, lr=2.18845e-05, gnorm=0.257, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=881
2023-08-08 18:29:40 - progress_bar.py[line:272] - INFO: epoch 001:    734 / 8233 loss=11.627, loss_v1=0, loss_v2=0, nll_loss=10.969, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=2004.19, wps=283.7, ups=0.83, wpb=340.7, bsz=48, num_updates=730, lr=2.21884e-05, gnorm=0.259, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=893
2023-08-08 18:29:52 - progress_bar.py[line:272] - INFO: epoch 001:    744 / 8233 loss=11.584, loss_v1=0, loss_v2=0, nll_loss=10.927, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=1947.48, wps=283.8, ups=0.83, wpb=340.1, bsz=48, num_updates=740, lr=2.24924e-05, gnorm=0.258, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=905
2023-08-08 18:30:04 - progress_bar.py[line:272] - INFO: epoch 001:    754 / 8233 loss=11.533, loss_v1=0, loss_v2=0, nll_loss=10.874, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1876.66, wps=282, ups=0.83, wpb=339.2, bsz=48, num_updates=750, lr=2.27964e-05, gnorm=0.256, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=917
2023-08-08 18:30:16 - progress_bar.py[line:272] - INFO: epoch 001:    764 / 8233 loss=11.477, loss_v1=0, loss_v2=0, nll_loss=10.813, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=1798.93, wps=286.9, ups=0.84, wpb=340.9, bsz=48, num_updates=760, lr=2.31003e-05, gnorm=0.254, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=929
2023-08-08 18:30:28 - progress_bar.py[line:272] - INFO: epoch 001:    774 / 8233 loss=11.428, loss_v1=0, loss_v2=0, nll_loss=10.764, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1739.38, wps=284, ups=0.84, wpb=339.9, bsz=48, num_updates=770, lr=2.34043e-05, gnorm=0.258, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=941
2023-08-08 18:30:40 - progress_bar.py[line:272] - INFO: epoch 001:    784 / 8233 loss=11.371, loss_v1=0, loss_v2=0, nll_loss=10.706, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1670.25, wps=277.1, ups=0.83, wpb=335.1, bsz=48, num_updates=780, lr=2.37082e-05, gnorm=0.251, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=953
2023-08-08 18:30:52 - progress_bar.py[line:272] - INFO: epoch 001:    794 / 8233 loss=11.393, loss_v1=0, loss_v2=0, nll_loss=10.73, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=1697.91, wps=284.5, ups=0.84, wpb=340.5, bsz=48, num_updates=790, lr=2.40122e-05, gnorm=0.252, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=965
2023-08-08 18:31:04 - progress_bar.py[line:272] - INFO: epoch 001:    804 / 8233 loss=11.441, loss_v1=0, loss_v2=0, nll_loss=10.787, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1767.03, wps=281, ups=0.83, wpb=336.9, bsz=48, num_updates=800, lr=2.43161e-05, gnorm=0.255, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=977
2023-08-08 18:31:16 - progress_bar.py[line:272] - INFO: epoch 001:    814 / 8233 loss=11.36, loss_v1=0, loss_v2=0, nll_loss=10.714, ntokens=333.9, nsentences=48, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=1679.23, wps=275.6, ups=0.83, wpb=333.9, bsz=48, num_updates=810, lr=2.46201e-05, gnorm=0.254, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=989
2023-08-08 18:31:28 - progress_bar.py[line:272] - INFO: epoch 001:    824 / 8233 loss=11.356, loss_v1=0, loss_v2=0, nll_loss=10.702, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1665.8, wps=280.8, ups=0.83, wpb=339.1, bsz=48, num_updates=820, lr=2.4924e-05, gnorm=0.252, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1001
2023-08-08 18:31:40 - progress_bar.py[line:272] - INFO: epoch 001:    834 / 8233 loss=11.31, loss_v1=0, loss_v2=0, nll_loss=10.657, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1614.75, wps=279.4, ups=0.83, wpb=336.2, bsz=48, num_updates=830, lr=2.5228e-05, gnorm=0.261, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1013
2023-08-08 18:31:52 - progress_bar.py[line:272] - INFO: epoch 001:    844 / 8233 loss=11.271, loss_v1=0, loss_v2=0, nll_loss=10.619, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=1573.08, wps=275.8, ups=0.82, wpb=335.8, bsz=48, num_updates=840, lr=2.55319e-05, gnorm=0.25, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1025
2023-08-08 18:32:04 - progress_bar.py[line:272] - INFO: epoch 001:    854 / 8233 loss=11.154, loss_v1=0, loss_v2=0, nll_loss=10.497, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1445.2, wps=281.9, ups=0.83, wpb=338.5, bsz=48, num_updates=850, lr=2.58359e-05, gnorm=0.252, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1037
2023-08-08 18:32:16 - progress_bar.py[line:272] - INFO: epoch 001:    864 / 8233 loss=11.133, loss_v1=0, loss_v2=0, nll_loss=10.482, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1430.59, wps=285.5, ups=0.84, wpb=341.4, bsz=48, num_updates=860, lr=2.61398e-05, gnorm=0.246, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1049
2023-08-08 18:32:28 - progress_bar.py[line:272] - INFO: epoch 001:    874 / 8233 loss=11.108, loss_v1=0, loss_v2=0, nll_loss=10.45, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1399.05, wps=281.6, ups=0.83, wpb=338.9, bsz=48, num_updates=870, lr=2.64438e-05, gnorm=0.249, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1061
2023-08-08 18:32:40 - progress_bar.py[line:272] - INFO: epoch 001:    884 / 8233 loss=11.133, loss_v1=0, loss_v2=0, nll_loss=10.48, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1428.33, wps=282.7, ups=0.84, wpb=338.3, bsz=48, num_updates=880, lr=2.67477e-05, gnorm=0.246, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1073
2023-08-08 18:32:52 - progress_bar.py[line:272] - INFO: epoch 001:    894 / 8233 loss=11.108, loss_v1=0, loss_v2=0, nll_loss=10.46, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1408.87, wps=282.2, ups=0.83, wpb=338.3, bsz=48, num_updates=890, lr=2.70517e-05, gnorm=0.247, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1085
2023-08-08 18:33:04 - progress_bar.py[line:272] - INFO: epoch 001:    904 / 8233 loss=11.118, loss_v1=0, loss_v2=0, nll_loss=10.48, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1427.79, wps=281.8, ups=0.83, wpb=338, bsz=48, num_updates=900, lr=2.73556e-05, gnorm=0.255, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=1097
2023-08-08 18:33:16 - progress_bar.py[line:272] - INFO: epoch 001:    914 / 8233 loss=11.083, loss_v1=0, loss_v2=0, nll_loss=10.443, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1391.59, wps=281, ups=0.83, wpb=337.7, bsz=48, num_updates=910, lr=2.76596e-05, gnorm=0.253, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1109
2023-08-08 18:33:28 - progress_bar.py[line:272] - INFO: epoch 001:    924 / 8233 loss=10.97, loss_v1=0, loss_v2=0, nll_loss=10.321, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1278.86, wps=282.3, ups=0.83, wpb=339, bsz=48, num_updates=920, lr=2.79635e-05, gnorm=0.247, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1121
2023-08-08 18:33:40 - progress_bar.py[line:272] - INFO: epoch 001:    934 / 8233 loss=10.965, loss_v1=0, loss_v2=0, nll_loss=10.319, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=1277.83, wps=280.1, ups=0.83, wpb=337.3, bsz=48, num_updates=930, lr=2.82675e-05, gnorm=0.251, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1133
2023-08-08 18:33:52 - progress_bar.py[line:272] - INFO: epoch 001:    944 / 8233 loss=10.946, loss_v1=0, loss_v2=0, nll_loss=10.302, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1262.13, wps=275.4, ups=0.82, wpb=334.2, bsz=48, num_updates=940, lr=2.85714e-05, gnorm=0.25, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1145
2023-08-08 18:34:04 - progress_bar.py[line:272] - INFO: epoch 001:    954 / 8233 loss=10.856, loss_v1=0, loss_v2=0, nll_loss=10.216, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1189.58, wps=279.8, ups=0.83, wpb=337.6, bsz=48, num_updates=950, lr=2.88754e-05, gnorm=0.244, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1157
2023-08-08 18:34:17 - progress_bar.py[line:272] - INFO: epoch 001:    964 / 8233 loss=10.781, loss_v1=0, loss_v2=0, nll_loss=10.129, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1119.94, wps=282, ups=0.83, wpb=339.5, bsz=48, num_updates=960, lr=2.91793e-05, gnorm=0.245, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1169
2023-08-08 18:34:29 - progress_bar.py[line:272] - INFO: epoch 001:    974 / 8233 loss=10.776, loss_v1=0, loss_v2=0, nll_loss=10.134, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1124, wps=281.4, ups=0.83, wpb=338.6, bsz=48, num_updates=970, lr=2.94833e-05, gnorm=0.243, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1181
2023-08-08 18:34:41 - progress_bar.py[line:272] - INFO: epoch 001:    984 / 8233 loss=10.732, loss_v1=0, loss_v2=0, nll_loss=10.087, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1087.69, wps=278.3, ups=0.82, wpb=338.3, bsz=48, num_updates=980, lr=2.97872e-05, gnorm=0.243, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1194
2023-08-08 18:34:53 - progress_bar.py[line:272] - INFO: epoch 001:    994 / 8233 loss=10.682, loss_v1=0, loss_v2=0, nll_loss=10.039, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1052.33, wps=280.3, ups=0.83, wpb=337.6, bsz=48, num_updates=990, lr=2.99942e-05, gnorm=0.237, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1206
2023-08-08 18:35:05 - progress_bar.py[line:272] - INFO: epoch 001:   1004 / 8233 loss=10.671, loss_v1=0, loss_v2=0, nll_loss=10.035, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1049.18, wps=277.9, ups=0.83, wpb=336.3, bsz=48, num_updates=1000, lr=2.99748e-05, gnorm=0.238, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1218
2023-08-08 18:35:17 - progress_bar.py[line:272] - INFO: epoch 001:   1014 / 8233 loss=10.606, loss_v1=0, loss_v2=0, nll_loss=9.962, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=997.54, wps=278.2, ups=0.82, wpb=338.1, bsz=48, num_updates=1010, lr=2.99554e-05, gnorm=0.238, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1230
2023-08-08 18:35:29 - progress_bar.py[line:272] - INFO: epoch 001:   1024 / 8233 loss=10.645, loss_v1=0, loss_v2=0, nll_loss=10.011, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1032.13, wps=283.6, ups=0.83, wpb=340.4, bsz=48, num_updates=1020, lr=2.9936e-05, gnorm=0.239, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1242
2023-08-08 18:35:41 - progress_bar.py[line:272] - INFO: epoch 001:   1034 / 8233 loss=10.639, loss_v1=0, loss_v2=0, nll_loss=10.008, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1030.01, wps=281.9, ups=0.83, wpb=338, bsz=48, num_updates=1030, lr=2.99167e-05, gnorm=0.241, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1254
2023-08-08 18:35:53 - progress_bar.py[line:272] - INFO: epoch 001:   1044 / 8233 loss=10.563, loss_v1=0, loss_v2=0, nll_loss=9.937, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=980.06, wps=282.9, ups=0.83, wpb=338.9, bsz=48, num_updates=1040, lr=2.98973e-05, gnorm=0.237, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1266
2023-08-08 18:36:05 - progress_bar.py[line:272] - INFO: epoch 001:   1054 / 8233 loss=10.464, loss_v1=0, loss_v2=0, nll_loss=9.829, ntokens=344.1, nsentences=48, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=909.4, wps=291, ups=0.85, wpb=344.1, bsz=48, num_updates=1050, lr=2.98779e-05, gnorm=0.236, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1278
2023-08-08 18:36:17 - progress_bar.py[line:272] - INFO: epoch 001:   1064 / 8233 loss=10.513, loss_v1=0, loss_v2=0, nll_loss=9.89, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=948.67, wps=288.1, ups=0.85, wpb=340.7, bsz=48, num_updates=1060, lr=2.98585e-05, gnorm=0.236, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1290
2023-08-08 18:36:29 - progress_bar.py[line:272] - INFO: epoch 001:   1074 / 8233 loss=10.439, loss_v1=0, loss_v2=0, nll_loss=9.808, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=896.26, wps=283.1, ups=0.84, wpb=338.9, bsz=48, num_updates=1070, lr=2.98391e-05, gnorm=0.232, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1302
2023-08-08 18:36:41 - progress_bar.py[line:272] - INFO: epoch 001:   1084 / 8233 loss=10.376, loss_v1=0, loss_v2=0, nll_loss=9.743, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=857.05, wps=280.7, ups=0.83, wpb=338, bsz=48, num_updates=1080, lr=2.98198e-05, gnorm=0.227, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1314
2023-08-08 18:36:53 - progress_bar.py[line:272] - INFO: epoch 001:   1094 / 8233 loss=10.325, loss_v1=0, loss_v2=0, nll_loss=9.697, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=830.22, wps=278.8, ups=0.82, wpb=338, bsz=48, num_updates=1090, lr=2.98004e-05, gnorm=0.229, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1326
2023-08-08 18:37:05 - progress_bar.py[line:272] - INFO: epoch 001:   1104 / 8233 loss=10.399, loss_v1=0, loss_v2=0, nll_loss=9.78, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=879.13, wps=285.9, ups=0.84, wpb=340.4, bsz=48, num_updates=1100, lr=2.9781e-05, gnorm=0.226, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1338
2023-08-08 18:37:17 - progress_bar.py[line:272] - INFO: epoch 001:   1114 / 8233 loss=10.271, loss_v1=0, loss_v2=0, nll_loss=9.651, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=804.06, wps=277.6, ups=0.83, wpb=335.5, bsz=48, num_updates=1110, lr=2.97616e-05, gnorm=0.222, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1350
2023-08-08 18:37:29 - progress_bar.py[line:272] - INFO: epoch 001:   1124 / 8233 loss=10.281, loss_v1=0, loss_v2=0, nll_loss=9.661, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=809.75, wps=282.6, ups=0.83, wpb=338.5, bsz=48, num_updates=1120, lr=2.97422e-05, gnorm=0.221, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1362
2023-08-08 18:37:41 - progress_bar.py[line:272] - INFO: epoch 001:   1134 / 8233 loss=10.242, loss_v1=0, loss_v2=0, nll_loss=9.629, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=791.73, wps=277.1, ups=0.83, wpb=335.1, bsz=48, num_updates=1130, lr=2.97229e-05, gnorm=0.221, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1374
2023-08-08 18:37:53 - progress_bar.py[line:272] - INFO: epoch 001:   1144 / 8233 loss=10.156, loss_v1=0, loss_v2=0, nll_loss=9.537, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=742.81, wps=279.8, ups=0.83, wpb=337.5, bsz=48, num_updates=1140, lr=2.97035e-05, gnorm=0.217, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1386
2023-08-08 18:38:05 - progress_bar.py[line:272] - INFO: epoch 001:   1154 / 8233 loss=10.132, loss_v1=0, loss_v2=0, nll_loss=9.51, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=729.02, wps=282.4, ups=0.83, wpb=339.4, bsz=48, num_updates=1150, lr=2.96841e-05, gnorm=0.22, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1398
2023-08-08 18:38:17 - progress_bar.py[line:272] - INFO: epoch 001:   1164 / 8233 loss=10.138, loss_v1=0, loss_v2=0, nll_loss=9.515, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=731.59, wps=281.6, ups=0.83, wpb=338.1, bsz=48, num_updates=1160, lr=2.96647e-05, gnorm=0.218, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1410
2023-08-08 18:38:29 - progress_bar.py[line:272] - INFO: epoch 001:   1174 / 8233 loss=10.103, loss_v1=0, loss_v2=0, nll_loss=9.485, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=716.49, wps=285.1, ups=0.84, wpb=340.3, bsz=48, num_updates=1170, lr=2.96453e-05, gnorm=0.22, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1422
2023-08-08 18:38:41 - progress_bar.py[line:272] - INFO: epoch 001:   1184 / 8233 loss=10.127, loss_v1=0, loss_v2=0, nll_loss=9.51, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=728.99, wps=284.4, ups=0.84, wpb=340.4, bsz=48, num_updates=1180, lr=2.96259e-05, gnorm=0.216, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1434
2023-08-08 18:38:53 - progress_bar.py[line:272] - INFO: epoch 001:   1194 / 8233 loss=10.004, loss_v1=0, loss_v2=0, nll_loss=9.391, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=671.21, wps=282.4, ups=0.83, wpb=338.6, bsz=48, num_updates=1190, lr=2.96066e-05, gnorm=0.213, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1446
2023-08-08 18:39:05 - progress_bar.py[line:272] - INFO: epoch 001:   1204 / 8233 loss=10.002, loss_v1=0, loss_v2=0, nll_loss=9.39, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=670.84, wps=279.1, ups=0.83, wpb=334.7, bsz=48, num_updates=1200, lr=2.95872e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1458
2023-08-08 18:39:17 - progress_bar.py[line:272] - INFO: epoch 001:   1214 / 8233 loss=9.969, loss_v1=0, loss_v2=0, nll_loss=9.351, ntokens=343.5, nsentences=48, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=652.93, wps=288.8, ups=0.84, wpb=343.5, bsz=48, num_updates=1210, lr=2.95678e-05, gnorm=0.217, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1470
2023-08-08 18:39:29 - progress_bar.py[line:272] - INFO: epoch 001:   1224 / 8233 loss=9.971, loss_v1=0, loss_v2=0, nll_loss=9.366, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=659.94, wps=283.3, ups=0.84, wpb=337.5, bsz=48, num_updates=1220, lr=2.95484e-05, gnorm=0.213, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1482
2023-08-08 18:39:41 - progress_bar.py[line:272] - INFO: epoch 001:   1234 / 8233 loss=9.885, loss_v1=0, loss_v2=0, nll_loss=9.274, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=619.17, wps=285.3, ups=0.84, wpb=339.5, bsz=48, num_updates=1230, lr=2.9529e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1493
2023-08-08 18:39:53 - progress_bar.py[line:272] - INFO: epoch 001:   1244 / 8233 loss=9.857, loss_v1=0, loss_v2=0, nll_loss=9.244, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=606.16, wps=284, ups=0.84, wpb=338, bsz=48, num_updates=1240, lr=2.95097e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1505
2023-08-08 18:40:05 - progress_bar.py[line:272] - INFO: epoch 001:   1254 / 8233 loss=9.849, loss_v1=0, loss_v2=0, nll_loss=9.234, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=602.12, wps=281.8, ups=0.83, wpb=338.6, bsz=48, num_updates=1250, lr=2.94903e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1517
2023-08-08 18:40:16 - progress_bar.py[line:272] - INFO: epoch 001:   1264 / 8233 loss=9.837, loss_v1=0, loss_v2=0, nll_loss=9.23, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=600.58, wps=287.3, ups=0.84, wpb=341.7, bsz=48, num_updates=1260, lr=2.94709e-05, gnorm=0.211, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1529
2023-08-08 18:40:29 - progress_bar.py[line:272] - INFO: epoch 001:   1274 / 8233 loss=9.782, loss_v1=0, loss_v2=0, nll_loss=9.166, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=574.61, wps=278.1, ups=0.83, wpb=336.9, bsz=48, num_updates=1270, lr=2.94515e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1541
2023-08-08 18:40:41 - progress_bar.py[line:272] - INFO: epoch 001:   1284 / 8233 loss=9.758, loss_v1=0, loss_v2=0, nll_loss=9.14, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=564.25, wps=279, ups=0.83, wpb=337.7, bsz=48, num_updates=1280, lr=2.94321e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1554
2023-08-08 18:40:53 - progress_bar.py[line:272] - INFO: epoch 001:   1294 / 8233 loss=9.734, loss_v1=0, loss_v2=0, nll_loss=9.123, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=557.68, wps=276.6, ups=0.83, wpb=335.1, bsz=48, num_updates=1290, lr=2.94128e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1566
2023-08-08 18:41:05 - progress_bar.py[line:272] - INFO: epoch 001:   1304 / 8233 loss=9.761, loss_v1=0, loss_v2=0, nll_loss=9.157, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=571.05, wps=283.3, ups=0.84, wpb=338.7, bsz=48, num_updates=1300, lr=2.93934e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1578
2023-08-08 18:41:17 - progress_bar.py[line:272] - INFO: epoch 001:   1314 / 8233 loss=9.705, loss_v1=0, loss_v2=0, nll_loss=9.096, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=547.24, wps=283.3, ups=0.84, wpb=338.7, bsz=48, num_updates=1310, lr=2.9374e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1590
2023-08-08 18:41:29 - progress_bar.py[line:272] - INFO: epoch 001:   1324 / 8233 loss=9.662, loss_v1=0, loss_v2=0, nll_loss=9.05, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=530.09, wps=284.2, ups=0.84, wpb=339.4, bsz=48, num_updates=1320, lr=2.93546e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1602
2023-08-08 18:41:41 - progress_bar.py[line:272] - INFO: epoch 001:   1334 / 8233 loss=9.592, loss_v1=0, loss_v2=0, nll_loss=8.978, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=504.34, wps=281.6, ups=0.83, wpb=337.8, bsz=48, num_updates=1330, lr=2.93352e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1614
2023-08-08 18:41:53 - progress_bar.py[line:272] - INFO: epoch 001:   1344 / 8233 loss=9.614, loss_v1=0, loss_v2=0, nll_loss=9.003, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=512.95, wps=276.9, ups=0.82, wpb=336.1, bsz=48, num_updates=1340, lr=2.93158e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1626
2023-08-08 18:42:05 - progress_bar.py[line:272] - INFO: epoch 001:   1354 / 8233 loss=9.594, loss_v1=0, loss_v2=0, nll_loss=8.995, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=510.37, wps=283.7, ups=0.84, wpb=339.6, bsz=48, num_updates=1350, lr=2.92965e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1638
2023-08-08 18:42:17 - progress_bar.py[line:272] - INFO: epoch 001:   1364 / 8233 loss=9.584, loss_v1=0, loss_v2=0, nll_loss=8.982, ntokens=334.8, nsentences=48, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=505.61, wps=277.7, ups=0.83, wpb=334.8, bsz=48, num_updates=1360, lr=2.92771e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1650
2023-08-08 18:42:29 - progress_bar.py[line:272] - INFO: epoch 001:   1374 / 8233 loss=9.448, loss_v1=0, loss_v2=0, nll_loss=8.829, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=454.86, wps=286.4, ups=0.84, wpb=340.7, bsz=48, num_updates=1370, lr=2.92577e-05, gnorm=0.198, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1662
2023-08-08 18:42:41 - progress_bar.py[line:272] - INFO: epoch 001:   1384 / 8233 loss=9.458, loss_v1=0, loss_v2=0, nll_loss=8.851, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=461.75, wps=287.1, ups=0.84, wpb=341, bsz=48, num_updates=1380, lr=2.92383e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1673
2023-08-08 18:42:53 - progress_bar.py[line:272] - INFO: epoch 001:   1394 / 8233 loss=9.459, loss_v1=0, loss_v2=0, nll_loss=8.855, ntokens=342.7, nsentences=48, sample_size=342.7, sample_size_v1=0, sample_size_v2=0, ppl=463.01, wps=286.8, ups=0.84, wpb=342.7, bsz=48, num_updates=1390, lr=2.92189e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1685
2023-08-08 18:43:05 - progress_bar.py[line:272] - INFO: epoch 001:   1404 / 8233 loss=9.341, loss_v1=0, loss_v2=0, nll_loss=8.726, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=423.54, wps=277.6, ups=0.83, wpb=336.1, bsz=48, num_updates=1400, lr=2.91996e-05, gnorm=0.197, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1698
2023-08-08 18:43:17 - progress_bar.py[line:272] - INFO: epoch 001:   1414 / 8233 loss=9.426, loss_v1=0, loss_v2=0, nll_loss=8.824, ntokens=342.2, nsentences=48, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=453.06, wps=286.9, ups=0.84, wpb=342.2, bsz=48, num_updates=1410, lr=2.91802e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1709
2023-08-08 18:43:29 - progress_bar.py[line:272] - INFO: epoch 001:   1424 / 8233 loss=9.339, loss_v1=0, loss_v2=0, nll_loss=8.723, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=422.66, wps=280.1, ups=0.83, wpb=337.3, bsz=48, num_updates=1420, lr=2.91608e-05, gnorm=0.199, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=1722
2023-08-08 18:43:41 - progress_bar.py[line:272] - INFO: epoch 001:   1434 / 8233 loss=9.364, loss_v1=0, loss_v2=0, nll_loss=8.752, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=431.12, wps=277.6, ups=0.83, wpb=336.3, bsz=48, num_updates=1430, lr=2.91414e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1734
2023-08-08 18:43:53 - progress_bar.py[line:272] - INFO: epoch 001:   1444 / 8233 loss=9.321, loss_v1=0, loss_v2=0, nll_loss=8.715, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=420.28, wps=279.2, ups=0.83, wpb=337.1, bsz=48, num_updates=1440, lr=2.9122e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1746
2023-08-08 18:44:05 - progress_bar.py[line:272] - INFO: epoch 001:   1454 / 8233 loss=9.28, loss_v1=0, loss_v2=0, nll_loss=8.675, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=408.67, wps=276.3, ups=0.82, wpb=336, bsz=48, num_updates=1450, lr=2.91027e-05, gnorm=0.196, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1758
2023-08-08 18:44:17 - progress_bar.py[line:272] - INFO: epoch 001:   1464 / 8233 loss=9.23, loss_v1=0, loss_v2=0, nll_loss=8.616, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=392.34, wps=281.7, ups=0.83, wpb=338.7, bsz=48, num_updates=1460, lr=2.90833e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1770
2023-08-08 18:44:29 - progress_bar.py[line:272] - INFO: epoch 001:   1474 / 8233 loss=9.252, loss_v1=0, loss_v2=0, nll_loss=8.638, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=398.43, wps=283.2, ups=0.83, wpb=339.7, bsz=48, num_updates=1470, lr=2.90639e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1782
2023-08-08 18:44:41 - progress_bar.py[line:272] - INFO: epoch 001:   1484 / 8233 loss=9.149, loss_v1=0, loss_v2=0, nll_loss=8.539, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=371.93, wps=285.5, ups=0.84, wpb=341.3, bsz=48, num_updates=1480, lr=2.90445e-05, gnorm=0.197, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1794
2023-08-08 18:44:53 - progress_bar.py[line:272] - INFO: epoch 001:   1494 / 8233 loss=9.176, loss_v1=0, loss_v2=0, nll_loss=8.565, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=378.71, wps=280.3, ups=0.83, wpb=338.2, bsz=48, num_updates=1490, lr=2.90251e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1806
2023-08-08 18:45:05 - progress_bar.py[line:272] - INFO: epoch 001:   1504 / 8233 loss=9.186, loss_v1=0, loss_v2=0, nll_loss=8.575, ntokens=333.1, nsentences=48, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=381.24, wps=273.7, ups=0.82, wpb=333.1, bsz=48, num_updates=1500, lr=2.90057e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1818
2023-08-08 18:45:17 - progress_bar.py[line:272] - INFO: epoch 001:   1514 / 8233 loss=9.109, loss_v1=0, loss_v2=0, nll_loss=8.501, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=362.27, wps=279.5, ups=0.83, wpb=336.9, bsz=48, num_updates=1510, lr=2.89864e-05, gnorm=0.196, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1830
2023-08-08 18:45:29 - progress_bar.py[line:272] - INFO: epoch 001:   1524 / 8233 loss=9.108, loss_v1=0, loss_v2=0, nll_loss=8.496, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=361.16, wps=281, ups=0.83, wpb=338.1, bsz=48, num_updates=1520, lr=2.8967e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1842
2023-08-08 18:45:41 - progress_bar.py[line:272] - INFO: epoch 001:   1534 / 8233 loss=9.056, loss_v1=0, loss_v2=0, nll_loss=8.446, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=348.85, wps=282.5, ups=0.83, wpb=339.5, bsz=48, num_updates=1530, lr=2.89476e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1854
2023-08-08 18:45:53 - progress_bar.py[line:272] - INFO: epoch 001:   1544 / 8233 loss=9.024, loss_v1=0, loss_v2=0, nll_loss=8.409, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=340.01, wps=279.4, ups=0.83, wpb=337, bsz=48, num_updates=1540, lr=2.89282e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1866
2023-08-08 18:46:06 - progress_bar.py[line:272] - INFO: epoch 001:   1554 / 8233 loss=9.011, loss_v1=0, loss_v2=0, nll_loss=8.398, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=337.25, wps=276.8, ups=0.82, wpb=335.8, bsz=48, num_updates=1550, lr=2.89088e-05, gnorm=0.196, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1878
2023-08-08 18:46:17 - progress_bar.py[line:272] - INFO: epoch 001:   1564 / 8233 loss=9.046, loss_v1=0, loss_v2=0, nll_loss=8.438, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=346.8, wps=284.8, ups=0.84, wpb=340.3, bsz=48, num_updates=1560, lr=2.88895e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1890
2023-08-08 18:46:29 - progress_bar.py[line:272] - INFO: epoch 001:   1574 / 8233 loss=8.963, loss_v1=0, loss_v2=0, nll_loss=8.351, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=326.5, wps=282.3, ups=0.83, wpb=338.6, bsz=48, num_updates=1570, lr=2.88701e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1902
2023-08-08 18:46:41 - progress_bar.py[line:272] - INFO: epoch 001:   1584 / 8233 loss=8.931, loss_v1=0, loss_v2=0, nll_loss=8.314, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=318.31, wps=282.6, ups=0.83, wpb=338.7, bsz=48, num_updates=1580, lr=2.88507e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1914
2023-08-08 18:46:53 - progress_bar.py[line:272] - INFO: epoch 001:   1594 / 8233 loss=8.928, loss_v1=0, loss_v2=0, nll_loss=8.312, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=317.77, wps=283.1, ups=0.84, wpb=337.9, bsz=48, num_updates=1590, lr=2.88313e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1926
2023-08-08 18:47:05 - progress_bar.py[line:272] - INFO: epoch 001:   1604 / 8233 loss=8.928, loss_v1=0, loss_v2=0, nll_loss=8.315, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=318.57, wps=283.2, ups=0.83, wpb=339.3, bsz=48, num_updates=1600, lr=2.88119e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1938
2023-08-08 18:47:17 - progress_bar.py[line:272] - INFO: epoch 001:   1614 / 8233 loss=8.863, loss_v1=0, loss_v2=0, nll_loss=8.243, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=302.86, wps=284.1, ups=0.83, wpb=341.1, bsz=48, num_updates=1610, lr=2.87926e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1950
2023-08-08 18:47:29 - progress_bar.py[line:272] - INFO: epoch 001:   1624 / 8233 loss=8.885, loss_v1=0, loss_v2=0, nll_loss=8.276, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=309.97, wps=278.2, ups=0.83, wpb=336.5, bsz=48, num_updates=1620, lr=2.87732e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1962
2023-08-08 18:47:42 - progress_bar.py[line:272] - INFO: epoch 001:   1634 / 8233 loss=8.806, loss_v1=0, loss_v2=0, nll_loss=8.193, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=292.59, wps=282.4, ups=0.83, wpb=339.7, bsz=48, num_updates=1630, lr=2.87538e-05, gnorm=0.195, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1974
2023-08-08 18:47:54 - progress_bar.py[line:272] - INFO: epoch 001:   1644 / 8233 loss=8.74, loss_v1=0, loss_v2=0, nll_loss=8.114, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=277.06, wps=283.1, ups=0.83, wpb=340.5, bsz=48, num_updates=1640, lr=2.87344e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1986
2023-08-08 18:48:05 - progress_bar.py[line:272] - INFO: epoch 001:   1654 / 8233 loss=8.76, loss_v1=0, loss_v2=0, nll_loss=8.142, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=282.57, wps=284.8, ups=0.84, wpb=340.1, bsz=48, num_updates=1650, lr=2.8715e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=1998
2023-08-08 18:48:17 - progress_bar.py[line:272] - INFO: epoch 001:   1664 / 8233 loss=8.75, loss_v1=0, loss_v2=0, nll_loss=8.124, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=279.06, wps=285.9, ups=0.84, wpb=340.4, bsz=48, num_updates=1660, lr=2.86957e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2010
2023-08-08 18:48:29 - progress_bar.py[line:272] - INFO: epoch 001:   1674 / 8233 loss=8.682, loss_v1=0, loss_v2=0, nll_loss=8.058, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=266.58, wps=283.5, ups=0.83, wpb=339.8, bsz=48, num_updates=1670, lr=2.86763e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2022
2023-08-08 18:48:42 - progress_bar.py[line:272] - INFO: epoch 001:   1684 / 8233 loss=8.675, loss_v1=0, loss_v2=0, nll_loss=8.051, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=265.27, wps=276.1, ups=0.82, wpb=335.3, bsz=48, num_updates=1680, lr=2.86569e-05, gnorm=0.194, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2034
2023-08-08 18:48:54 - progress_bar.py[line:272] - INFO: epoch 001:   1694 / 8233 loss=8.655, loss_v1=0, loss_v2=0, nll_loss=8.028, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=261.07, wps=283.6, ups=0.83, wpb=340.1, bsz=48, num_updates=1690, lr=2.86375e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2046
2023-08-08 18:49:06 - progress_bar.py[line:272] - INFO: epoch 001:   1704 / 8233 loss=8.633, loss_v1=0, loss_v2=0, nll_loss=8.009, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=257.67, wps=280, ups=0.83, wpb=336.1, bsz=48, num_updates=1700, lr=2.86181e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2058
2023-08-08 18:49:18 - progress_bar.py[line:272] - INFO: epoch 001:   1714 / 8233 loss=8.533, loss_v1=0, loss_v2=0, nll_loss=7.898, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=238.53, wps=280, ups=0.83, wpb=337.9, bsz=48, num_updates=1710, lr=2.85987e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2071
2023-08-08 18:49:30 - progress_bar.py[line:272] - INFO: epoch 001:   1724 / 8233 loss=8.564, loss_v1=0, loss_v2=0, nll_loss=7.93, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=243.83, wps=280, ups=0.83, wpb=337.4, bsz=48, num_updates=1720, lr=2.85794e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2083
2023-08-08 18:49:42 - progress_bar.py[line:272] - INFO: epoch 001:   1734 / 8233 loss=8.513, loss_v1=0, loss_v2=0, nll_loss=7.879, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=235.45, wps=279, ups=0.83, wpb=336.8, bsz=48, num_updates=1730, lr=2.856e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2095
2023-08-08 18:49:54 - progress_bar.py[line:272] - INFO: epoch 001:   1744 / 8233 loss=8.509, loss_v1=0, loss_v2=0, nll_loss=7.868, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=233.66, wps=281.5, ups=0.83, wpb=339.4, bsz=48, num_updates=1740, lr=2.85406e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2107
2023-08-08 18:50:06 - progress_bar.py[line:272] - INFO: epoch 001:   1754 / 8233 loss=8.463, loss_v1=0, loss_v2=0, nll_loss=7.822, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=226.22, wps=285.7, ups=0.83, wpb=342.3, bsz=48, num_updates=1750, lr=2.85212e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2119
2023-08-08 18:50:18 - progress_bar.py[line:272] - INFO: epoch 001:   1764 / 8233 loss=8.432, loss_v1=0, loss_v2=0, nll_loss=7.788, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=221.03, wps=278.4, ups=0.83, wpb=337.1, bsz=48, num_updates=1760, lr=2.85018e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2131
2023-08-08 18:50:30 - progress_bar.py[line:272] - INFO: epoch 001:   1774 / 8233 loss=8.447, loss_v1=0, loss_v2=0, nll_loss=7.808, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=224.09, wps=282.9, ups=0.83, wpb=340.2, bsz=48, num_updates=1770, lr=2.84825e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2143
2023-08-08 18:50:42 - progress_bar.py[line:272] - INFO: epoch 001:   1784 / 8233 loss=8.398, loss_v1=0, loss_v2=0, nll_loss=7.752, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=215.55, wps=284.3, ups=0.84, wpb=340.5, bsz=48, num_updates=1780, lr=2.84631e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2155
2023-08-08 18:50:54 - progress_bar.py[line:272] - INFO: epoch 001:   1794 / 8233 loss=8.433, loss_v1=0, loss_v2=0, nll_loss=7.787, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=220.84, wps=283.1, ups=0.83, wpb=339.1, bsz=48, num_updates=1790, lr=2.84437e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=2167
2023-08-08 18:51:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-08 18:51:07 - progress_bar.py[line:272] - INFO: epoch 001:   1805 / 8233 loss=8.359, loss_v1=0, loss_v2=0, nll_loss=7.714, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=209.92, wps=256.9, ups=0.76, wpb=339.9, bsz=48, num_updates=1800, lr=2.84243e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=13, gb_free=14.5, wall=2180
2023-08-08 18:51:19 - progress_bar.py[line:272] - INFO: epoch 001:   1815 / 8233 loss=8.257, loss_v1=0, loss_v2=0, nll_loss=7.6, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=194.07, wps=274.7, ups=0.82, wpb=334.2, bsz=48, num_updates=1810, lr=2.84049e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2192
2023-08-08 18:51:31 - progress_bar.py[line:272] - INFO: epoch 001:   1825 / 8233 loss=8.334, loss_v1=0, loss_v2=0, nll_loss=7.686, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=205.87, wps=284.4, ups=0.84, wpb=339.9, bsz=48, num_updates=1820, lr=2.83856e-05, gnorm=0.199, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2204
2023-08-08 18:51:43 - progress_bar.py[line:272] - INFO: epoch 001:   1835 / 8233 loss=8.309, loss_v1=0, loss_v2=0, nll_loss=7.658, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=201.94, wps=286.2, ups=0.84, wpb=341.4, bsz=48, num_updates=1830, lr=2.83662e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2216
2023-08-08 18:51:55 - progress_bar.py[line:272] - INFO: epoch 001:   1845 / 8233 loss=8.198, loss_v1=0, loss_v2=0, nll_loss=7.538, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=185.81, wps=283.1, ups=0.83, wpb=340.6, bsz=48, num_updates=1840, lr=2.83468e-05, gnorm=0.197, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2228
2023-08-08 18:52:07 - progress_bar.py[line:272] - INFO: epoch 001:   1855 / 8233 loss=8.18, loss_v1=0, loss_v2=0, nll_loss=7.505, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=181.65, wps=285.3, ups=0.84, wpb=341.4, bsz=48, num_updates=1850, lr=2.83274e-05, gnorm=0.198, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2240
2023-08-08 18:52:19 - progress_bar.py[line:272] - INFO: epoch 001:   1865 / 8233 loss=8.172, loss_v1=0, loss_v2=0, nll_loss=7.501, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=181.1, wps=285.5, ups=0.84, wpb=340.6, bsz=48, num_updates=1860, lr=2.8308e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2252
2023-08-08 18:52:31 - progress_bar.py[line:272] - INFO: epoch 001:   1875 / 8233 loss=8.102, loss_v1=0, loss_v2=0, nll_loss=7.426, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=172.01, wps=280.2, ups=0.83, wpb=338, bsz=48, num_updates=1870, lr=2.82886e-05, gnorm=0.193, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2264
2023-08-08 18:52:43 - progress_bar.py[line:272] - INFO: epoch 001:   1885 / 8233 loss=8.191, loss_v1=0, loss_v2=0, nll_loss=7.526, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=184.3, wps=282.9, ups=0.83, wpb=339.3, bsz=48, num_updates=1880, lr=2.82693e-05, gnorm=0.195, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2276
2023-08-08 18:52:55 - progress_bar.py[line:272] - INFO: epoch 001:   1895 / 8233 loss=8.112, loss_v1=0, loss_v2=0, nll_loss=7.432, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=172.73, wps=283.4, ups=0.83, wpb=339.5, bsz=48, num_updates=1890, lr=2.82499e-05, gnorm=0.196, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2288
2023-08-08 18:53:07 - progress_bar.py[line:272] - INFO: epoch 001:   1905 / 8233 loss=8.093, loss_v1=0, loss_v2=0, nll_loss=7.412, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=170.3, wps=283.9, ups=0.83, wpb=340.1, bsz=48, num_updates=1900, lr=2.82305e-05, gnorm=0.197, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2300
2023-08-08 18:53:19 - progress_bar.py[line:272] - INFO: epoch 001:   1915 / 8233 loss=8.117, loss_v1=0, loss_v2=0, nll_loss=7.431, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=172.6, wps=280.6, ups=0.83, wpb=338.3, bsz=48, num_updates=1910, lr=2.82111e-05, gnorm=0.195, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2312
2023-08-08 18:53:31 - progress_bar.py[line:272] - INFO: epoch 001:   1925 / 8233 loss=8.048, loss_v1=0, loss_v2=0, nll_loss=7.362, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=164.53, wps=283.9, ups=0.83, wpb=340.1, bsz=48, num_updates=1920, lr=2.81917e-05, gnorm=0.193, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2324
2023-08-08 18:53:43 - progress_bar.py[line:272] - INFO: epoch 001:   1935 / 8233 loss=8.013, loss_v1=0, loss_v2=0, nll_loss=7.326, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=160.43, wps=282, ups=0.83, wpb=339.4, bsz=48, num_updates=1930, lr=2.81724e-05, gnorm=0.193, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2336
2023-08-08 18:53:55 - progress_bar.py[line:272] - INFO: epoch 001:   1945 / 8233 loss=7.979, loss_v1=0, loss_v2=0, nll_loss=7.285, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=155.94, wps=282.7, ups=0.83, wpb=339.6, bsz=48, num_updates=1940, lr=2.8153e-05, gnorm=0.191, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2348
2023-08-08 18:54:07 - progress_bar.py[line:272] - INFO: epoch 001:   1955 / 8233 loss=8.009, loss_v1=0, loss_v2=0, nll_loss=7.317, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=159.49, wps=285, ups=0.84, wpb=340.1, bsz=48, num_updates=1950, lr=2.81336e-05, gnorm=0.195, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2360
2023-08-08 18:54:19 - progress_bar.py[line:272] - INFO: epoch 001:   1965 / 8233 loss=7.958, loss_v1=0, loss_v2=0, nll_loss=7.261, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=153.38, wps=275.7, ups=0.82, wpb=335.1, bsz=48, num_updates=1960, lr=2.81142e-05, gnorm=0.188, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2372
2023-08-08 18:54:31 - progress_bar.py[line:272] - INFO: epoch 001:   1975 / 8233 loss=7.949, loss_v1=0, loss_v2=0, nll_loss=7.249, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=152.09, wps=283.6, ups=0.84, wpb=337.5, bsz=48, num_updates=1970, lr=2.80948e-05, gnorm=0.189, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=2384
2023-08-08 18:54:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-08 18:54:45 - progress_bar.py[line:272] - INFO: epoch 001:   1986 / 8233 loss=7.918, loss_v1=0, loss_v2=0, nll_loss=7.214, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=148.48, wps=254.3, ups=0.75, wpb=337.4, bsz=48, num_updates=1980, lr=2.80755e-05, gnorm=0.186, clip=0, loss_scale=8, train_wall=13, gb_free=14.5, wall=2397
2023-08-08 18:54:57 - progress_bar.py[line:272] - INFO: epoch 001:   1996 / 8233 loss=7.871, loss_v1=0, loss_v2=0, nll_loss=7.165, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=143.53, wps=282.2, ups=0.83, wpb=339, bsz=48, num_updates=1990, lr=2.80561e-05, gnorm=0.189, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2409
2023-08-08 18:55:09 - progress_bar.py[line:272] - INFO: epoch 001:   2006 / 8233 loss=7.875, loss_v1=0, loss_v2=0, nll_loss=7.161, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=143.08, wps=280.7, ups=0.83, wpb=337.4, bsz=48, num_updates=2000, lr=2.80367e-05, gnorm=0.19, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2421
2023-08-08 18:55:21 - progress_bar.py[line:272] - INFO: epoch 001:   2016 / 8233 loss=7.865, loss_v1=0, loss_v2=0, nll_loss=7.153, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=142.32, wps=282.3, ups=0.83, wpb=338.3, bsz=48, num_updates=2010, lr=2.80173e-05, gnorm=0.188, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2433
2023-08-08 18:55:33 - progress_bar.py[line:272] - INFO: epoch 001:   2026 / 8233 loss=7.785, loss_v1=0, loss_v2=0, nll_loss=7.066, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=134, wps=280.7, ups=0.83, wpb=338.5, bsz=48, num_updates=2020, lr=2.79979e-05, gnorm=0.182, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2445
2023-08-08 18:55:45 - progress_bar.py[line:272] - INFO: epoch 001:   2036 / 8233 loss=7.766, loss_v1=0, loss_v2=0, nll_loss=7.036, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=131.21, wps=279.7, ups=0.83, wpb=336.7, bsz=48, num_updates=2030, lr=2.79786e-05, gnorm=0.189, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2458
2023-08-08 18:55:57 - progress_bar.py[line:272] - INFO: epoch 001:   2046 / 8233 loss=7.785, loss_v1=0, loss_v2=0, nll_loss=7.059, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=133.33, wps=281.2, ups=0.83, wpb=338.2, bsz=48, num_updates=2040, lr=2.79592e-05, gnorm=0.183, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2470
2023-08-08 18:56:09 - progress_bar.py[line:272] - INFO: epoch 001:   2056 / 8233 loss=7.704, loss_v1=0, loss_v2=0, nll_loss=6.971, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=125.43, wps=286.4, ups=0.84, wpb=342.3, bsz=48, num_updates=2050, lr=2.79398e-05, gnorm=0.185, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2482
2023-08-08 18:56:21 - progress_bar.py[line:272] - INFO: epoch 001:   2066 / 8233 loss=7.821, loss_v1=0, loss_v2=0, nll_loss=7.098, ntokens=333.8, nsentences=48, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=137.02, wps=275.1, ups=0.82, wpb=333.8, bsz=48, num_updates=2060, lr=2.79204e-05, gnorm=0.185, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2494
2023-08-08 18:56:33 - progress_bar.py[line:272] - INFO: epoch 001:   2076 / 8233 loss=7.697, loss_v1=0, loss_v2=0, nll_loss=6.966, ntokens=341.8, nsentences=48, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=125, wps=285.9, ups=0.84, wpb=341.8, bsz=48, num_updates=2070, lr=2.7901e-05, gnorm=0.183, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2506
2023-08-08 18:56:45 - progress_bar.py[line:272] - INFO: epoch 001:   2086 / 8233 loss=7.69, loss_v1=0, loss_v2=0, nll_loss=6.951, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=123.74, wps=280.2, ups=0.83, wpb=337.7, bsz=48, num_updates=2080, lr=2.78816e-05, gnorm=0.181, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2518
2023-08-08 18:56:57 - progress_bar.py[line:272] - INFO: epoch 001:   2096 / 8233 loss=7.694, loss_v1=0, loss_v2=0, nll_loss=6.951, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=123.72, wps=281.6, ups=0.84, wpb=336.9, bsz=48, num_updates=2090, lr=2.78623e-05, gnorm=0.183, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2530
2023-08-08 18:57:09 - progress_bar.py[line:272] - INFO: epoch 001:   2106 / 8233 loss=7.658, loss_v1=0, loss_v2=0, nll_loss=6.91, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=120.28, wps=282.8, ups=0.84, wpb=338.6, bsz=48, num_updates=2100, lr=2.78429e-05, gnorm=0.181, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2542
2023-08-08 18:57:21 - progress_bar.py[line:272] - INFO: epoch 001:   2116 / 8233 loss=7.696, loss_v1=0, loss_v2=0, nll_loss=6.953, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=123.89, wps=283.6, ups=0.84, wpb=338.9, bsz=48, num_updates=2110, lr=2.78235e-05, gnorm=0.176, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2554
2023-08-08 18:57:33 - progress_bar.py[line:272] - INFO: epoch 001:   2126 / 8233 loss=7.608, loss_v1=0, loss_v2=0, nll_loss=6.863, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=116.39, wps=281, ups=0.83, wpb=338.4, bsz=48, num_updates=2120, lr=2.78041e-05, gnorm=0.179, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2566
2023-08-08 18:57:45 - progress_bar.py[line:272] - INFO: epoch 001:   2136 / 8233 loss=7.644, loss_v1=0, loss_v2=0, nll_loss=6.9, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=119.42, wps=282.1, ups=0.83, wpb=338.8, bsz=48, num_updates=2130, lr=2.77847e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2578
2023-08-08 18:57:57 - progress_bar.py[line:272] - INFO: epoch 001:   2146 / 8233 loss=7.577, loss_v1=0, loss_v2=0, nll_loss=6.818, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=112.86, wps=283.2, ups=0.83, wpb=339.6, bsz=48, num_updates=2140, lr=2.77654e-05, gnorm=0.179, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2590
2023-08-08 18:58:09 - progress_bar.py[line:272] - INFO: epoch 001:   2156 / 8233 loss=7.588, loss_v1=0, loss_v2=0, nll_loss=6.826, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=113.49, wps=277.2, ups=0.83, wpb=334.7, bsz=48, num_updates=2150, lr=2.7746e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2602
2023-08-08 18:58:21 - progress_bar.py[line:272] - INFO: epoch 001:   2166 / 8233 loss=7.536, loss_v1=0, loss_v2=0, nll_loss=6.772, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=109.27, wps=283.6, ups=0.84, wpb=339.1, bsz=48, num_updates=2160, lr=2.77266e-05, gnorm=0.179, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2614
2023-08-08 18:58:33 - progress_bar.py[line:272] - INFO: epoch 001:   2176 / 8233 loss=7.537, loss_v1=0, loss_v2=0, nll_loss=6.773, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=109.39, wps=281.4, ups=0.83, wpb=338.7, bsz=48, num_updates=2170, lr=2.77072e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2626
2023-08-08 18:58:45 - progress_bar.py[line:272] - INFO: epoch 001:   2186 / 8233 loss=7.533, loss_v1=0, loss_v2=0, nll_loss=6.764, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=108.71, wps=286, ups=0.84, wpb=341, bsz=48, num_updates=2180, lr=2.76878e-05, gnorm=0.18, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2638
2023-08-08 18:58:57 - progress_bar.py[line:272] - INFO: epoch 001:   2196 / 8233 loss=7.495, loss_v1=0, loss_v2=0, nll_loss=6.724, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=105.74, wps=277.5, ups=0.82, wpb=336.5, bsz=48, num_updates=2190, lr=2.76685e-05, gnorm=0.173, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2650
2023-08-08 18:59:09 - progress_bar.py[line:272] - INFO: epoch 001:   2206 / 8233 loss=7.45, loss_v1=0, loss_v2=0, nll_loss=6.672, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=101.94, wps=279.7, ups=0.83, wpb=338, bsz=48, num_updates=2200, lr=2.76491e-05, gnorm=0.179, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2662
2023-08-08 18:59:21 - progress_bar.py[line:272] - INFO: epoch 001:   2216 / 8233 loss=7.461, loss_v1=0, loss_v2=0, nll_loss=6.679, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=102.48, wps=280.7, ups=0.83, wpb=337.6, bsz=48, num_updates=2210, lr=2.76297e-05, gnorm=0.184, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2674
2023-08-08 18:59:33 - progress_bar.py[line:272] - INFO: epoch 001:   2226 / 8233 loss=7.497, loss_v1=0, loss_v2=0, nll_loss=6.72, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=105.41, wps=280, ups=0.83, wpb=337.2, bsz=48, num_updates=2220, lr=2.76103e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2686
2023-08-08 18:59:45 - progress_bar.py[line:272] - INFO: epoch 001:   2236 / 8233 loss=7.475, loss_v1=0, loss_v2=0, nll_loss=6.693, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=103.45, wps=283.7, ups=0.84, wpb=339.5, bsz=48, num_updates=2230, lr=2.75909e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2698
2023-08-08 18:59:57 - progress_bar.py[line:272] - INFO: epoch 001:   2246 / 8233 loss=7.406, loss_v1=0, loss_v2=0, nll_loss=6.614, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=97.93, wps=281.7, ups=0.83, wpb=338.4, bsz=48, num_updates=2240, lr=2.75715e-05, gnorm=0.181, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2710
2023-08-08 19:00:09 - progress_bar.py[line:272] - INFO: epoch 001:   2256 / 8233 loss=7.444, loss_v1=0, loss_v2=0, nll_loss=6.663, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=101.31, wps=282.3, ups=0.83, wpb=338.6, bsz=48, num_updates=2250, lr=2.75522e-05, gnorm=0.177, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2722
2023-08-08 19:00:21 - progress_bar.py[line:272] - INFO: epoch 001:   2266 / 8233 loss=7.369, loss_v1=0, loss_v2=0, nll_loss=6.576, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=95.41, wps=285.5, ups=0.84, wpb=339.5, bsz=48, num_updates=2260, lr=2.75328e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2734
2023-08-08 19:00:33 - progress_bar.py[line:272] - INFO: epoch 001:   2276 / 8233 loss=7.312, loss_v1=0, loss_v2=0, nll_loss=6.51, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=91.15, wps=282, ups=0.83, wpb=338.7, bsz=48, num_updates=2270, lr=2.75134e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2746
2023-08-08 19:00:45 - progress_bar.py[line:272] - INFO: epoch 001:   2286 / 8233 loss=7.259, loss_v1=0, loss_v2=0, nll_loss=6.446, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=87.16, wps=281.9, ups=0.83, wpb=337.9, bsz=48, num_updates=2280, lr=2.7494e-05, gnorm=0.179, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2758
2023-08-08 19:00:57 - progress_bar.py[line:272] - INFO: epoch 001:   2296 / 8233 loss=7.306, loss_v1=0, loss_v2=0, nll_loss=6.504, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=90.74, wps=282.3, ups=0.84, wpb=338.1, bsz=48, num_updates=2290, lr=2.74746e-05, gnorm=0.177, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2770
2023-08-08 19:01:09 - progress_bar.py[line:272] - INFO: epoch 001:   2306 / 8233 loss=7.28, loss_v1=0, loss_v2=0, nll_loss=6.468, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=88.55, wps=281.4, ups=0.83, wpb=338.1, bsz=48, num_updates=2300, lr=2.74553e-05, gnorm=0.184, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2782
2023-08-08 19:01:21 - progress_bar.py[line:272] - INFO: epoch 001:   2316 / 8233 loss=7.274, loss_v1=0, loss_v2=0, nll_loss=6.467, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=88.48, wps=280.5, ups=0.83, wpb=336.9, bsz=48, num_updates=2310, lr=2.74359e-05, gnorm=0.178, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2794
2023-08-08 19:01:33 - progress_bar.py[line:272] - INFO: epoch 001:   2326 / 8233 loss=7.283, loss_v1=0, loss_v2=0, nll_loss=6.467, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=88.47, wps=284.6, ups=0.84, wpb=338.9, bsz=48, num_updates=2320, lr=2.74165e-05, gnorm=0.183, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2806
2023-08-08 19:01:45 - progress_bar.py[line:272] - INFO: epoch 001:   2336 / 8233 loss=7.241, loss_v1=0, loss_v2=0, nll_loss=6.424, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=85.87, wps=280.1, ups=0.83, wpb=338.1, bsz=48, num_updates=2330, lr=2.73971e-05, gnorm=0.174, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2818
2023-08-08 19:01:57 - progress_bar.py[line:272] - INFO: epoch 001:   2346 / 8233 loss=7.232, loss_v1=0, loss_v2=0, nll_loss=6.411, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=85.07, wps=283.4, ups=0.83, wpb=340.3, bsz=48, num_updates=2340, lr=2.73777e-05, gnorm=0.177, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2830
2023-08-08 19:02:09 - progress_bar.py[line:272] - INFO: epoch 001:   2356 / 8233 loss=7.242, loss_v1=0, loss_v2=0, nll_loss=6.422, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=85.72, wps=279, ups=0.83, wpb=337, bsz=48, num_updates=2350, lr=2.73584e-05, gnorm=0.181, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2842
2023-08-08 19:02:21 - progress_bar.py[line:272] - INFO: epoch 001:   2366 / 8233 loss=7.227, loss_v1=0, loss_v2=0, nll_loss=6.402, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=84.56, wps=285.7, ups=0.84, wpb=340.7, bsz=48, num_updates=2360, lr=2.7339e-05, gnorm=0.174, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2854
2023-08-08 19:02:33 - progress_bar.py[line:272] - INFO: epoch 001:   2376 / 8233 loss=7.248, loss_v1=0, loss_v2=0, nll_loss=6.419, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=85.6, wps=282.4, ups=0.84, wpb=335.2, bsz=48, num_updates=2370, lr=2.73196e-05, gnorm=0.177, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2866
2023-08-08 19:02:45 - progress_bar.py[line:272] - INFO: epoch 001:   2386 / 8233 loss=7.171, loss_v1=0, loss_v2=0, nll_loss=6.342, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=81.1, wps=282, ups=0.83, wpb=338.2, bsz=48, num_updates=2380, lr=2.73002e-05, gnorm=0.174, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2878
2023-08-08 19:02:57 - progress_bar.py[line:272] - INFO: epoch 001:   2396 / 8233 loss=7.197, loss_v1=0, loss_v2=0, nll_loss=6.365, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=82.4, wps=284.5, ups=0.84, wpb=339.4, bsz=48, num_updates=2390, lr=2.72808e-05, gnorm=0.176, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2890
2023-08-08 19:03:09 - progress_bar.py[line:272] - INFO: epoch 001:   2406 / 8233 loss=7.157, loss_v1=0, loss_v2=0, nll_loss=6.32, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=79.91, wps=282.6, ups=0.83, wpb=338.9, bsz=48, num_updates=2400, lr=2.72615e-05, gnorm=0.18, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2902
2023-08-08 19:03:21 - progress_bar.py[line:272] - INFO: epoch 001:   2416 / 8233 loss=7.2, loss_v1=0, loss_v2=0, nll_loss=6.36, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=82.16, wps=280.1, ups=0.83, wpb=337.3, bsz=48, num_updates=2410, lr=2.72421e-05, gnorm=0.175, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2914
2023-08-08 19:03:33 - progress_bar.py[line:272] - INFO: epoch 001:   2426 / 8233 loss=7.062, loss_v1=0, loss_v2=0, nll_loss=6.208, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=73.92, wps=280.5, ups=0.83, wpb=336.9, bsz=48, num_updates=2420, lr=2.72227e-05, gnorm=0.179, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2926
2023-08-08 19:03:45 - progress_bar.py[line:272] - INFO: epoch 001:   2436 / 8233 loss=7.085, loss_v1=0, loss_v2=0, nll_loss=6.236, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=75.39, wps=283.6, ups=0.84, wpb=338.8, bsz=48, num_updates=2430, lr=2.72033e-05, gnorm=0.176, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2938
2023-08-08 19:03:57 - progress_bar.py[line:272] - INFO: epoch 001:   2446 / 8233 loss=7.022, loss_v1=0, loss_v2=0, nll_loss=6.167, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=71.84, wps=278.6, ups=0.83, wpb=336.8, bsz=48, num_updates=2440, lr=2.71839e-05, gnorm=0.174, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2950
2023-08-08 19:04:09 - progress_bar.py[line:272] - INFO: epoch 001:   2456 / 8233 loss=7.04, loss_v1=0, loss_v2=0, nll_loss=6.178, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=72.42, wps=277.6, ups=0.83, wpb=335.2, bsz=48, num_updates=2450, lr=2.71645e-05, gnorm=0.181, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2962
2023-08-08 19:04:21 - progress_bar.py[line:272] - INFO: epoch 001:   2466 / 8233 loss=7.031, loss_v1=0, loss_v2=0, nll_loss=6.178, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=72.39, wps=279.4, ups=0.83, wpb=336, bsz=48, num_updates=2460, lr=2.71452e-05, gnorm=0.179, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2974
2023-08-08 19:04:33 - progress_bar.py[line:272] - INFO: epoch 001:   2476 / 8233 loss=7.014, loss_v1=0, loss_v2=0, nll_loss=6.157, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=71.35, wps=282.2, ups=0.83, wpb=338.9, bsz=48, num_updates=2470, lr=2.71258e-05, gnorm=0.174, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2986
2023-08-08 19:04:45 - progress_bar.py[line:272] - INFO: epoch 001:   2486 / 8233 loss=6.978, loss_v1=0, loss_v2=0, nll_loss=6.114, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=69.24, wps=279.1, ups=0.83, wpb=337.9, bsz=48, num_updates=2480, lr=2.71064e-05, gnorm=0.175, clip=0, loss_scale=8, train_wall=12, gb_free=14.5, wall=2998
2023-08-08 19:04:57 - progress_bar.py[line:272] - INFO: epoch 001:   2496 / 8233 loss=7.013, loss_v1=0, loss_v2=0, nll_loss=6.149, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=70.95, wps=279.1, ups=0.83, wpb=338.1, bsz=48, num_updates=2490, lr=2.7087e-05, gnorm=0.181, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3010
2023-08-08 19:05:09 - progress_bar.py[line:272] - INFO: epoch 001:   2506 / 8233 loss=6.983, loss_v1=0, loss_v2=0, nll_loss=6.112, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=69.15, wps=277.7, ups=0.83, wpb=336.5, bsz=48, num_updates=2500, lr=2.70676e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3022
2023-08-08 19:05:21 - progress_bar.py[line:272] - INFO: epoch 001:   2516 / 8233 loss=6.936, loss_v1=0, loss_v2=0, nll_loss=6.062, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=66.81, wps=280.8, ups=0.83, wpb=337.2, bsz=48, num_updates=2510, lr=2.70483e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3034
2023-08-08 19:05:33 - progress_bar.py[line:272] - INFO: epoch 001:   2526 / 8233 loss=6.927, loss_v1=0, loss_v2=0, nll_loss=6.045, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=66.03, wps=278.6, ups=0.83, wpb=335.4, bsz=48, num_updates=2520, lr=2.70289e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3046
2023-08-08 19:05:45 - progress_bar.py[line:272] - INFO: epoch 001:   2536 / 8233 loss=6.915, loss_v1=0, loss_v2=0, nll_loss=6.035, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=65.57, wps=280.4, ups=0.83, wpb=338, bsz=48, num_updates=2530, lr=2.70095e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3058
2023-08-08 19:05:57 - progress_bar.py[line:272] - INFO: epoch 001:   2546 / 8233 loss=6.938, loss_v1=0, loss_v2=0, nll_loss=6.059, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=66.66, wps=282.8, ups=0.83, wpb=340.3, bsz=48, num_updates=2540, lr=2.69901e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3070
2023-08-08 19:06:09 - progress_bar.py[line:272] - INFO: epoch 001:   2556 / 8233 loss=6.898, loss_v1=0, loss_v2=0, nll_loss=6.014, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=64.61, wps=280.5, ups=0.83, wpb=337.7, bsz=48, num_updates=2550, lr=2.69707e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3082
2023-08-08 19:06:21 - progress_bar.py[line:272] - INFO: epoch 001:   2566 / 8233 loss=6.891, loss_v1=0, loss_v2=0, nll_loss=6.011, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=64.47, wps=285.9, ups=0.84, wpb=340, bsz=48, num_updates=2560, lr=2.69514e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3094
2023-08-08 19:06:33 - progress_bar.py[line:272] - INFO: epoch 001:   2576 / 8233 loss=6.856, loss_v1=0, loss_v2=0, nll_loss=5.96, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=62.23, wps=280.7, ups=0.83, wpb=337.8, bsz=48, num_updates=2570, lr=2.6932e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3106
2023-08-08 19:06:45 - progress_bar.py[line:272] - INFO: epoch 001:   2586 / 8233 loss=6.828, loss_v1=0, loss_v2=0, nll_loss=5.936, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=61.23, wps=285.1, ups=0.84, wpb=341.2, bsz=48, num_updates=2580, lr=2.69126e-05, gnorm=0.18, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3118
2023-08-08 19:06:57 - progress_bar.py[line:272] - INFO: epoch 001:   2596 / 8233 loss=6.82, loss_v1=0, loss_v2=0, nll_loss=5.931, ntokens=334, nsentences=48, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=61.01, wps=279.2, ups=0.84, wpb=334, bsz=48, num_updates=2590, lr=2.68932e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3130
2023-08-08 19:07:09 - progress_bar.py[line:272] - INFO: epoch 001:   2606 / 8233 loss=6.785, loss_v1=0, loss_v2=0, nll_loss=5.885, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=59.08, wps=283.9, ups=0.83, wpb=340.5, bsz=48, num_updates=2600, lr=2.68738e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3142
2023-08-08 19:07:21 - progress_bar.py[line:272] - INFO: epoch 001:   2616 / 8233 loss=6.768, loss_v1=0, loss_v2=0, nll_loss=5.865, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=58.28, wps=279.9, ups=0.83, wpb=337.3, bsz=48, num_updates=2610, lr=2.68544e-05, gnorm=0.178, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3154
2023-08-08 19:07:33 - progress_bar.py[line:272] - INFO: epoch 001:   2626 / 8233 loss=6.787, loss_v1=0, loss_v2=0, nll_loss=5.881, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=58.92, wps=280.5, ups=0.83, wpb=337.8, bsz=48, num_updates=2620, lr=2.68351e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3166
2023-08-08 19:07:45 - progress_bar.py[line:272] - INFO: epoch 001:   2636 / 8233 loss=6.753, loss_v1=0, loss_v2=0, nll_loss=5.847, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=57.57, wps=281.3, ups=0.83, wpb=337.8, bsz=48, num_updates=2630, lr=2.68157e-05, gnorm=0.178, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3178
2023-08-08 19:07:57 - progress_bar.py[line:272] - INFO: epoch 001:   2646 / 8233 loss=6.768, loss_v1=0, loss_v2=0, nll_loss=5.862, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=58.17, wps=284.5, ups=0.83, wpb=340.8, bsz=48, num_updates=2640, lr=2.67963e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3190
2023-08-08 19:08:10 - progress_bar.py[line:272] - INFO: epoch 001:   2656 / 8233 loss=6.71, loss_v1=0, loss_v2=0, nll_loss=5.795, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=55.52, wps=276.7, ups=0.82, wpb=335.4, bsz=48, num_updates=2650, lr=2.67769e-05, gnorm=0.18, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3202
2023-08-08 19:08:22 - progress_bar.py[line:272] - INFO: epoch 001:   2666 / 8233 loss=6.742, loss_v1=0, loss_v2=0, nll_loss=5.828, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=56.79, wps=280.2, ups=0.83, wpb=337.1, bsz=48, num_updates=2660, lr=2.67575e-05, gnorm=0.182, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3214
2023-08-08 19:08:34 - progress_bar.py[line:272] - INFO: epoch 001:   2676 / 8233 loss=6.729, loss_v1=0, loss_v2=0, nll_loss=5.808, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=56.01, wps=280.5, ups=0.83, wpb=338.5, bsz=48, num_updates=2670, lr=2.67382e-05, gnorm=0.173, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3227
2023-08-08 19:08:46 - progress_bar.py[line:272] - INFO: epoch 001:   2686 / 8233 loss=6.725, loss_v1=0, loss_v2=0, nll_loss=5.815, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=56.31, wps=283.7, ups=0.84, wpb=338.7, bsz=48, num_updates=2680, lr=2.67188e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3239
2023-08-08 19:08:58 - progress_bar.py[line:272] - INFO: epoch 001:   2696 / 8233 loss=6.767, loss_v1=0, loss_v2=0, nll_loss=5.849, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=57.65, wps=282.5, ups=0.84, wpb=337.5, bsz=48, num_updates=2690, lr=2.66994e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3250
2023-08-08 19:09:10 - progress_bar.py[line:272] - INFO: epoch 001:   2706 / 8233 loss=6.654, loss_v1=0, loss_v2=0, nll_loss=5.732, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=53.17, wps=284.4, ups=0.84, wpb=339.8, bsz=48, num_updates=2700, lr=2.668e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3262
2023-08-08 19:09:21 - progress_bar.py[line:272] - INFO: epoch 001:   2716 / 8233 loss=6.7, loss_v1=0, loss_v2=0, nll_loss=5.779, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=54.92, wps=282.6, ups=0.84, wpb=337.9, bsz=48, num_updates=2710, lr=2.66606e-05, gnorm=0.179, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3274
2023-08-08 19:09:33 - progress_bar.py[line:272] - INFO: epoch 001:   2726 / 8233 loss=6.666, loss_v1=0, loss_v2=0, nll_loss=5.738, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=53.37, wps=284.3, ups=0.84, wpb=339.6, bsz=48, num_updates=2720, lr=2.66413e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3286
2023-08-08 19:09:45 - progress_bar.py[line:272] - INFO: epoch 001:   2736 / 8233 loss=6.628, loss_v1=0, loss_v2=0, nll_loss=5.701, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=52.04, wps=282.8, ups=0.83, wpb=338.9, bsz=48, num_updates=2730, lr=2.66219e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3298
2023-08-08 19:09:57 - progress_bar.py[line:272] - INFO: epoch 001:   2746 / 8233 loss=6.668, loss_v1=0, loss_v2=0, nll_loss=5.736, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=53.3, wps=287.4, ups=0.84, wpb=341.4, bsz=48, num_updates=2740, lr=2.66025e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3310
2023-08-08 19:10:09 - progress_bar.py[line:272] - INFO: epoch 001:   2756 / 8233 loss=6.588, loss_v1=0, loss_v2=0, nll_loss=5.65, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=50.2, wps=285.4, ups=0.84, wpb=340.3, bsz=48, num_updates=2750, lr=2.65831e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3322
2023-08-08 19:10:21 - progress_bar.py[line:272] - INFO: epoch 001:   2766 / 8233 loss=6.586, loss_v1=0, loss_v2=0, nll_loss=5.652, ntokens=334.8, nsentences=48, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=50.29, wps=278.2, ups=0.83, wpb=334.8, bsz=48, num_updates=2760, lr=2.65637e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3334
2023-08-08 19:10:33 - progress_bar.py[line:272] - INFO: epoch 001:   2776 / 8233 loss=6.556, loss_v1=0, loss_v2=0, nll_loss=5.614, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=48.98, wps=282.7, ups=0.84, wpb=337.8, bsz=48, num_updates=2770, lr=2.65444e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3346
2023-08-08 19:10:45 - progress_bar.py[line:272] - INFO: epoch 001:   2786 / 8233 loss=6.585, loss_v1=0, loss_v2=0, nll_loss=5.644, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=50.01, wps=284.1, ups=0.83, wpb=340.3, bsz=48, num_updates=2780, lr=2.6525e-05, gnorm=0.173, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3358
2023-08-08 19:10:57 - progress_bar.py[line:272] - INFO: epoch 001:   2796 / 8233 loss=6.455, loss_v1=0, loss_v2=0, nll_loss=5.5, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=45.24, wps=280.1, ups=0.83, wpb=335.8, bsz=48, num_updates=2790, lr=2.65056e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3370
2023-08-08 19:11:09 - progress_bar.py[line:272] - INFO: epoch 001:   2806 / 8233 loss=6.549, loss_v1=0, loss_v2=0, nll_loss=5.603, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=48.6, wps=278.2, ups=0.83, wpb=335.9, bsz=48, num_updates=2800, lr=2.64862e-05, gnorm=0.172, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3382
2023-08-08 19:11:21 - progress_bar.py[line:272] - INFO: epoch 001:   2816 / 8233 loss=6.502, loss_v1=0, loss_v2=0, nll_loss=5.55, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=46.87, wps=282.6, ups=0.83, wpb=339.3, bsz=48, num_updates=2810, lr=2.64668e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3394
2023-08-08 19:11:33 - progress_bar.py[line:272] - INFO: epoch 001:   2826 / 8233 loss=6.533, loss_v1=0, loss_v2=0, nll_loss=5.587, ntokens=334.4, nsentences=48, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=48.08, wps=277, ups=0.83, wpb=334.4, bsz=48, num_updates=2820, lr=2.64474e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3406
2023-08-08 19:11:45 - progress_bar.py[line:272] - INFO: epoch 001:   2836 / 8233 loss=6.48, loss_v1=0, loss_v2=0, nll_loss=5.525, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=46.05, wps=279.4, ups=0.83, wpb=336.9, bsz=48, num_updates=2830, lr=2.64281e-05, gnorm=0.174, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3418
2023-08-08 19:11:57 - progress_bar.py[line:272] - INFO: epoch 001:   2846 / 8233 loss=6.377, loss_v1=0, loss_v2=0, nll_loss=5.404, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=42.33, wps=283.6, ups=0.84, wpb=339.1, bsz=48, num_updates=2840, lr=2.64087e-05, gnorm=0.173, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3430
2023-08-08 19:12:09 - progress_bar.py[line:272] - INFO: epoch 001:   2856 / 8233 loss=6.458, loss_v1=0, loss_v2=0, nll_loss=5.5, ntokens=334.4, nsentences=48, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=45.26, wps=276.4, ups=0.83, wpb=334.4, bsz=48, num_updates=2850, lr=2.63893e-05, gnorm=0.177, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3442
2023-08-08 19:12:21 - progress_bar.py[line:272] - INFO: epoch 001:   2866 / 8233 loss=6.486, loss_v1=0, loss_v2=0, nll_loss=5.529, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=46.19, wps=281.1, ups=0.83, wpb=338, bsz=48, num_updates=2860, lr=2.63699e-05, gnorm=0.179, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3454
2023-08-08 19:12:34 - progress_bar.py[line:272] - INFO: epoch 001:   2876 / 8233 loss=6.446, loss_v1=0, loss_v2=0, nll_loss=5.477, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=44.55, wps=277.4, ups=0.83, wpb=336.1, bsz=48, num_updates=2870, lr=2.63505e-05, gnorm=0.179, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3467
2023-08-08 19:12:46 - progress_bar.py[line:272] - INFO: epoch 001:   2886 / 8233 loss=6.377, loss_v1=0, loss_v2=0, nll_loss=5.403, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=42.3, wps=279.3, ups=0.83, wpb=335.2, bsz=48, num_updates=2880, lr=2.63312e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3479
2023-08-08 19:12:58 - progress_bar.py[line:272] - INFO: epoch 001:   2896 / 8233 loss=6.404, loss_v1=0, loss_v2=0, nll_loss=5.437, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=43.32, wps=281.7, ups=0.84, wpb=337.2, bsz=48, num_updates=2890, lr=2.63118e-05, gnorm=0.178, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3490
2023-08-08 19:13:10 - progress_bar.py[line:272] - INFO: epoch 001:   2906 / 8233 loss=6.396, loss_v1=0, loss_v2=0, nll_loss=5.421, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=42.85, wps=280.9, ups=0.83, wpb=337.4, bsz=48, num_updates=2900, lr=2.62924e-05, gnorm=0.179, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3502
2023-08-08 19:13:22 - progress_bar.py[line:272] - INFO: epoch 001:   2916 / 8233 loss=6.38, loss_v1=0, loss_v2=0, nll_loss=5.404, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=42.34, wps=282.8, ups=0.83, wpb=339.4, bsz=48, num_updates=2910, lr=2.6273e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3515
2023-08-08 19:13:34 - progress_bar.py[line:272] - INFO: epoch 001:   2926 / 8233 loss=6.332, loss_v1=0, loss_v2=0, nll_loss=5.349, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=40.76, wps=283.3, ups=0.84, wpb=338, bsz=48, num_updates=2920, lr=2.62536e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3526
2023-08-08 19:13:46 - progress_bar.py[line:272] - INFO: epoch 001:   2936 / 8233 loss=6.365, loss_v1=0, loss_v2=0, nll_loss=5.386, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=41.81, wps=281.7, ups=0.83, wpb=338.8, bsz=48, num_updates=2930, lr=2.62343e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3538
2023-08-08 19:13:58 - progress_bar.py[line:272] - INFO: epoch 001:   2946 / 8233 loss=6.358, loss_v1=0, loss_v2=0, nll_loss=5.38, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=41.64, wps=282.7, ups=0.83, wpb=340.5, bsz=48, num_updates=2940, lr=2.62149e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3551
2023-08-08 19:14:10 - progress_bar.py[line:272] - INFO: epoch 001:   2956 / 8233 loss=6.33, loss_v1=0, loss_v2=0, nll_loss=5.339, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=40.48, wps=280, ups=0.83, wpb=337.3, bsz=48, num_updates=2950, lr=2.61955e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3563
2023-08-08 19:14:22 - progress_bar.py[line:272] - INFO: epoch 001:   2966 / 8233 loss=6.319, loss_v1=0, loss_v2=0, nll_loss=5.328, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=40.18, wps=284, ups=0.84, wpb=340, bsz=48, num_updates=2960, lr=2.61761e-05, gnorm=0.175, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3575
2023-08-08 19:14:34 - progress_bar.py[line:272] - INFO: epoch 001:   2976 / 8233 loss=6.319, loss_v1=0, loss_v2=0, nll_loss=5.331, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=40.27, wps=287, ups=0.84, wpb=341.2, bsz=48, num_updates=2970, lr=2.61567e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3586
2023-08-08 19:14:46 - progress_bar.py[line:272] - INFO: epoch 001:   2986 / 8233 loss=6.258, loss_v1=0, loss_v2=0, nll_loss=5.262, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=38.37, wps=280.3, ups=0.83, wpb=337.2, bsz=48, num_updates=2980, lr=2.61373e-05, gnorm=0.174, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3598
2023-08-08 19:14:58 - progress_bar.py[line:272] - INFO: epoch 001:   2996 / 8233 loss=6.229, loss_v1=0, loss_v2=0, nll_loss=5.233, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=37.6, wps=279.2, ups=0.83, wpb=337.5, bsz=48, num_updates=2990, lr=2.6118e-05, gnorm=0.176, clip=0, loss_scale=16, train_wall=12, gb_free=14.5, wall=3611
2023-08-08 19:15:10 - progress_bar.py[line:272] - INFO: epoch 001:   3006 / 8233 loss=6.262, loss_v1=0, loss_v2=0, nll_loss=5.262, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=38.38, wps=281.9, ups=0.83, wpb=339.5, bsz=48, num_updates=3000, lr=2.60986e-05, gnorm=0.179, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3623
2023-08-08 19:15:22 - progress_bar.py[line:272] - INFO: epoch 001:   3016 / 8233 loss=6.281, loss_v1=0, loss_v2=0, nll_loss=5.285, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=38.98, wps=276.3, ups=0.83, wpb=334.5, bsz=48, num_updates=3010, lr=2.60792e-05, gnorm=0.179, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3635
2023-08-08 19:15:34 - progress_bar.py[line:272] - INFO: epoch 001:   3026 / 8233 loss=6.185, loss_v1=0, loss_v2=0, nll_loss=5.176, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=36.16, wps=283.1, ups=0.84, wpb=339, bsz=48, num_updates=3020, lr=2.60598e-05, gnorm=0.167, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3647
2023-08-08 19:15:46 - progress_bar.py[line:272] - INFO: epoch 001:   3036 / 8233 loss=6.224, loss_v1=0, loss_v2=0, nll_loss=5.217, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=37.2, wps=282, ups=0.83, wpb=339.3, bsz=48, num_updates=3030, lr=2.60404e-05, gnorm=0.172, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3659
2023-08-08 19:15:58 - progress_bar.py[line:272] - INFO: epoch 001:   3046 / 8233 loss=6.196, loss_v1=0, loss_v2=0, nll_loss=5.191, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=36.53, wps=278.7, ups=0.83, wpb=335.9, bsz=48, num_updates=3040, lr=2.60211e-05, gnorm=0.176, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3671
2023-08-08 19:16:10 - progress_bar.py[line:272] - INFO: epoch 001:   3056 / 8233 loss=6.278, loss_v1=0, loss_v2=0, nll_loss=5.279, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=38.84, wps=281.3, ups=0.83, wpb=339.1, bsz=48, num_updates=3050, lr=2.60017e-05, gnorm=0.18, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3683
2023-08-08 19:16:22 - progress_bar.py[line:272] - INFO: epoch 001:   3066 / 8233 loss=6.237, loss_v1=0, loss_v2=0, nll_loss=5.234, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=37.64, wps=278.9, ups=0.83, wpb=335.9, bsz=48, num_updates=3060, lr=2.59823e-05, gnorm=0.173, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3695
2023-08-08 19:16:34 - progress_bar.py[line:272] - INFO: epoch 001:   3076 / 8233 loss=6.133, loss_v1=0, loss_v2=0, nll_loss=5.112, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=34.59, wps=278.2, ups=0.83, wpb=336.6, bsz=48, num_updates=3070, lr=2.59629e-05, gnorm=0.177, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3707
2023-08-08 19:16:46 - progress_bar.py[line:272] - INFO: epoch 001:   3086 / 8233 loss=6.169, loss_v1=0, loss_v2=0, nll_loss=5.153, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=35.57, wps=281.1, ups=0.83, wpb=338, bsz=48, num_updates=3080, lr=2.59435e-05, gnorm=0.173, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3719
2023-08-08 19:16:58 - progress_bar.py[line:272] - INFO: epoch 001:   3096 / 8233 loss=6.131, loss_v1=0, loss_v2=0, nll_loss=5.117, ntokens=341.9, nsentences=48, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=34.7, wps=285.3, ups=0.83, wpb=341.9, bsz=48, num_updates=3090, lr=2.59242e-05, gnorm=0.172, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3731
2023-08-08 19:17:10 - progress_bar.py[line:272] - INFO: epoch 001:   3106 / 8233 loss=6.058, loss_v1=0, loss_v2=0, nll_loss=5.029, ntokens=344.4, nsentences=48, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=32.66, wps=289.6, ups=0.84, wpb=344.4, bsz=48, num_updates=3100, lr=2.59048e-05, gnorm=0.175, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3743
2023-08-08 19:17:22 - progress_bar.py[line:272] - INFO: epoch 001:   3116 / 8233 loss=6.071, loss_v1=0, loss_v2=0, nll_loss=5.046, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=33.05, wps=280.9, ups=0.83, wpb=338, bsz=48, num_updates=3110, lr=2.58854e-05, gnorm=0.17, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3755
2023-08-08 19:17:34 - progress_bar.py[line:272] - INFO: epoch 001:   3126 / 8233 loss=6.148, loss_v1=0, loss_v2=0, nll_loss=5.124, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=34.87, wps=280.9, ups=0.83, wpb=338.5, bsz=48, num_updates=3120, lr=2.5866e-05, gnorm=0.176, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3767
2023-08-08 19:17:46 - progress_bar.py[line:272] - INFO: epoch 001:   3136 / 8233 loss=6.161, loss_v1=0, loss_v2=0, nll_loss=5.143, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=35.33, wps=284.8, ups=0.84, wpb=340.2, bsz=48, num_updates=3130, lr=2.58466e-05, gnorm=0.175, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3779
2023-08-08 19:17:58 - progress_bar.py[line:272] - INFO: epoch 001:   3146 / 8233 loss=6.08, loss_v1=0, loss_v2=0, nll_loss=5.053, ntokens=333.6, nsentences=48, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=33.19, wps=276.7, ups=0.83, wpb=333.6, bsz=48, num_updates=3140, lr=2.58272e-05, gnorm=0.173, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3791
2023-08-08 19:18:10 - progress_bar.py[line:272] - INFO: epoch 001:   3156 / 8233 loss=6.112, loss_v1=0, loss_v2=0, nll_loss=5.084, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=33.93, wps=282.1, ups=0.84, wpb=337, bsz=48, num_updates=3150, lr=2.58079e-05, gnorm=0.175, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3803
2023-08-08 19:18:22 - progress_bar.py[line:272] - INFO: epoch 001:   3166 / 8233 loss=6.11, loss_v1=0, loss_v2=0, nll_loss=5.08, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=33.82, wps=284.1, ups=0.83, wpb=340.3, bsz=48, num_updates=3160, lr=2.57885e-05, gnorm=0.175, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3815
2023-08-08 19:18:34 - progress_bar.py[line:272] - INFO: epoch 001:   3176 / 8233 loss=6.078, loss_v1=0, loss_v2=0, nll_loss=5.046, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=33.05, wps=281.4, ups=0.83, wpb=338.8, bsz=48, num_updates=3170, lr=2.57691e-05, gnorm=0.174, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3827
2023-08-08 19:18:46 - progress_bar.py[line:272] - INFO: epoch 001:   3186 / 8233 loss=6.04, loss_v1=0, loss_v2=0, nll_loss=5.004, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=32.08, wps=280.4, ups=0.83, wpb=337.3, bsz=48, num_updates=3180, lr=2.57497e-05, gnorm=0.167, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3839
2023-08-08 19:18:58 - progress_bar.py[line:272] - INFO: epoch 001:   3196 / 8233 loss=6.066, loss_v1=0, loss_v2=0, nll_loss=5.029, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=32.65, wps=281.4, ups=0.83, wpb=338.7, bsz=48, num_updates=3190, lr=2.57303e-05, gnorm=0.171, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3851
2023-08-08 19:19:10 - progress_bar.py[line:272] - INFO: epoch 001:   3206 / 8233 loss=6.056, loss_v1=0, loss_v2=0, nll_loss=5.018, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=32.4, wps=284.3, ups=0.84, wpb=338.1, bsz=48, num_updates=3200, lr=2.5711e-05, gnorm=0.171, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3863
2023-08-08 19:19:22 - progress_bar.py[line:272] - INFO: epoch 001:   3216 / 8233 loss=6.035, loss_v1=0, loss_v2=0, nll_loss=4.998, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=31.95, wps=285, ups=0.84, wpb=340.1, bsz=48, num_updates=3210, lr=2.56916e-05, gnorm=0.166, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3875
2023-08-08 19:19:34 - progress_bar.py[line:272] - INFO: epoch 001:   3226 / 8233 loss=6.02, loss_v1=0, loss_v2=0, nll_loss=4.982, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=31.6, wps=281.5, ups=0.83, wpb=339, bsz=48, num_updates=3220, lr=2.56722e-05, gnorm=0.169, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3887
2023-08-08 19:19:46 - progress_bar.py[line:272] - INFO: epoch 001:   3236 / 8233 loss=5.988, loss_v1=0, loss_v2=0, nll_loss=4.938, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=30.66, wps=279.6, ups=0.83, wpb=336.4, bsz=48, num_updates=3230, lr=2.56528e-05, gnorm=0.165, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3899
2023-08-08 19:19:58 - progress_bar.py[line:272] - INFO: epoch 001:   3246 / 8233 loss=5.991, loss_v1=0, loss_v2=0, nll_loss=4.945, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=30.8, wps=280.7, ups=0.83, wpb=339.3, bsz=48, num_updates=3240, lr=2.56334e-05, gnorm=0.168, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3911
2023-08-08 19:20:10 - progress_bar.py[line:272] - INFO: epoch 001:   3256 / 8233 loss=6.03, loss_v1=0, loss_v2=0, nll_loss=4.995, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=31.88, wps=279.4, ups=0.83, wpb=336.7, bsz=48, num_updates=3250, lr=2.56141e-05, gnorm=0.174, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3923
2023-08-08 19:20:22 - progress_bar.py[line:272] - INFO: epoch 001:   3266 / 8233 loss=5.912, loss_v1=0, loss_v2=0, nll_loss=4.853, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=28.91, wps=279.5, ups=0.83, wpb=337.9, bsz=48, num_updates=3260, lr=2.55947e-05, gnorm=0.166, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3935
2023-08-08 19:20:34 - progress_bar.py[line:272] - INFO: epoch 001:   3276 / 8233 loss=5.914, loss_v1=0, loss_v2=0, nll_loss=4.857, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=28.97, wps=280.7, ups=0.83, wpb=337.8, bsz=48, num_updates=3270, lr=2.55753e-05, gnorm=0.163, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3947
2023-08-08 19:20:46 - progress_bar.py[line:272] - INFO: epoch 001:   3286 / 8233 loss=5.943, loss_v1=0, loss_v2=0, nll_loss=4.891, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=29.67, wps=281.8, ups=0.83, wpb=338.7, bsz=48, num_updates=3280, lr=2.55559e-05, gnorm=0.165, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3959
2023-08-08 19:20:58 - progress_bar.py[line:272] - INFO: epoch 001:   3296 / 8233 loss=5.92, loss_v1=0, loss_v2=0, nll_loss=4.862, ntokens=335, nsentences=48, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=29.08, wps=277.6, ups=0.83, wpb=335, bsz=48, num_updates=3290, lr=2.55365e-05, gnorm=0.164, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3971
2023-08-08 19:21:10 - progress_bar.py[line:272] - INFO: epoch 001:   3306 / 8233 loss=5.909, loss_v1=0, loss_v2=0, nll_loss=4.846, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=28.76, wps=280.3, ups=0.83, wpb=337.3, bsz=48, num_updates=3300, lr=2.55172e-05, gnorm=0.168, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3983
2023-08-08 19:21:22 - progress_bar.py[line:272] - INFO: epoch 001:   3316 / 8233 loss=5.938, loss_v1=0, loss_v2=0, nll_loss=4.884, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=29.52, wps=283.1, ups=0.83, wpb=340.2, bsz=48, num_updates=3310, lr=2.54978e-05, gnorm=0.168, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=3995
2023-08-08 19:21:34 - progress_bar.py[line:272] - INFO: epoch 001:   3326 / 8233 loss=5.91, loss_v1=0, loss_v2=0, nll_loss=4.848, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=28.81, wps=284.6, ups=0.84, wpb=340.7, bsz=48, num_updates=3320, lr=2.54784e-05, gnorm=0.17, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4007
2023-08-08 19:21:47 - progress_bar.py[line:272] - INFO: epoch 001:   3336 / 8233 loss=5.933, loss_v1=0, loss_v2=0, nll_loss=4.874, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=29.33, wps=279.8, ups=0.83, wpb=336.9, bsz=48, num_updates=3330, lr=2.5459e-05, gnorm=0.169, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4019
2023-08-08 19:21:59 - progress_bar.py[line:272] - INFO: epoch 001:   3346 / 8233 loss=5.891, loss_v1=0, loss_v2=0, nll_loss=4.827, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=28.37, wps=283.3, ups=0.83, wpb=339.7, bsz=48, num_updates=3340, lr=2.54396e-05, gnorm=0.162, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4031
2023-08-08 19:22:10 - progress_bar.py[line:272] - INFO: epoch 001:   3356 / 8233 loss=5.829, loss_v1=0, loss_v2=0, nll_loss=4.755, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=27.01, wps=281.4, ups=0.83, wpb=337.3, bsz=48, num_updates=3350, lr=2.54202e-05, gnorm=0.168, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4043
2023-08-08 19:22:22 - progress_bar.py[line:272] - INFO: epoch 001:   3366 / 8233 loss=5.873, loss_v1=0, loss_v2=0, nll_loss=4.803, ntokens=341.9, nsentences=48, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=27.91, wps=285.7, ups=0.84, wpb=341.9, bsz=48, num_updates=3360, lr=2.54009e-05, gnorm=0.165, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4055
2023-08-08 19:22:34 - progress_bar.py[line:272] - INFO: epoch 001:   3376 / 8233 loss=5.866, loss_v1=0, loss_v2=0, nll_loss=4.798, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=27.82, wps=283.4, ups=0.83, wpb=340.2, bsz=48, num_updates=3370, lr=2.53815e-05, gnorm=0.167, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4067
2023-08-08 19:22:46 - progress_bar.py[line:272] - INFO: epoch 001:   3386 / 8233 loss=5.836, loss_v1=0, loss_v2=0, nll_loss=4.765, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=27.19, wps=284.5, ups=0.84, wpb=339.9, bsz=48, num_updates=3380, lr=2.53621e-05, gnorm=0.169, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4079
2023-08-08 19:22:58 - progress_bar.py[line:272] - INFO: epoch 001:   3396 / 8233 loss=5.86, loss_v1=0, loss_v2=0, nll_loss=4.793, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=27.72, wps=278.5, ups=0.83, wpb=336.4, bsz=48, num_updates=3390, lr=2.53427e-05, gnorm=0.165, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4091
2023-08-08 19:23:10 - progress_bar.py[line:272] - INFO: epoch 001:   3406 / 8233 loss=5.81, loss_v1=0, loss_v2=0, nll_loss=4.726, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=26.46, wps=284.5, ups=0.84, wpb=340.1, bsz=48, num_updates=3400, lr=2.53233e-05, gnorm=0.159, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4103
2023-08-08 19:23:22 - progress_bar.py[line:272] - INFO: epoch 001:   3416 / 8233 loss=5.85, loss_v1=0, loss_v2=0, nll_loss=4.783, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=27.52, wps=285.1, ups=0.84, wpb=340.5, bsz=48, num_updates=3410, lr=2.5304e-05, gnorm=0.163, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4115
2023-08-08 19:23:34 - progress_bar.py[line:272] - INFO: epoch 001:   3426 / 8233 loss=5.854, loss_v1=0, loss_v2=0, nll_loss=4.774, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=27.36, wps=284.3, ups=0.84, wpb=340, bsz=48, num_updates=3420, lr=2.52846e-05, gnorm=0.167, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4127
2023-08-08 19:23:46 - progress_bar.py[line:272] - INFO: epoch 001:   3436 / 8233 loss=5.803, loss_v1=0, loss_v2=0, nll_loss=4.717, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=26.3, wps=283.3, ups=0.83, wpb=339.5, bsz=48, num_updates=3430, lr=2.52652e-05, gnorm=0.163, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4139
2023-08-08 19:23:58 - progress_bar.py[line:272] - INFO: epoch 001:   3446 / 8233 loss=5.835, loss_v1=0, loss_v2=0, nll_loss=4.761, ntokens=333.9, nsentences=48, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=27.12, wps=276, ups=0.83, wpb=333.9, bsz=48, num_updates=3440, lr=2.52458e-05, gnorm=0.161, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4151
2023-08-08 19:24:11 - progress_bar.py[line:272] - INFO: epoch 001:   3456 / 8233 loss=5.842, loss_v1=0, loss_v2=0, nll_loss=4.764, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=27.18, wps=280, ups=0.83, wpb=338.1, bsz=48, num_updates=3450, lr=2.52264e-05, gnorm=0.165, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4163
2023-08-08 19:24:23 - progress_bar.py[line:272] - INFO: epoch 001:   3466 / 8233 loss=5.796, loss_v1=0, loss_v2=0, nll_loss=4.718, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=26.32, wps=280.2, ups=0.83, wpb=337.7, bsz=48, num_updates=3460, lr=2.52071e-05, gnorm=0.16, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4175
2023-08-08 19:24:35 - progress_bar.py[line:272] - INFO: epoch 001:   3476 / 8233 loss=5.701, loss_v1=0, loss_v2=0, nll_loss=4.596, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=24.19, wps=282, ups=0.83, wpb=340.1, bsz=48, num_updates=3470, lr=2.51877e-05, gnorm=0.157, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4188
2023-08-08 19:24:47 - progress_bar.py[line:272] - INFO: epoch 001:   3486 / 8233 loss=5.786, loss_v1=0, loss_v2=0, nll_loss=4.695, ntokens=334.3, nsentences=48, sample_size=334.3, sample_size_v1=0, sample_size_v2=0, ppl=25.9, wps=276.6, ups=0.83, wpb=334.3, bsz=48, num_updates=3480, lr=2.51683e-05, gnorm=0.162, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4200
2023-08-08 19:24:59 - progress_bar.py[line:272] - INFO: epoch 001:   3496 / 8233 loss=5.802, loss_v1=0, loss_v2=0, nll_loss=4.716, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=26.28, wps=285, ups=0.84, wpb=340.1, bsz=48, num_updates=3490, lr=2.51489e-05, gnorm=0.162, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4212
2023-08-08 19:25:11 - progress_bar.py[line:272] - INFO: epoch 001:   3506 / 8233 loss=5.717, loss_v1=0, loss_v2=0, nll_loss=4.615, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=24.51, wps=282.6, ups=0.83, wpb=338.5, bsz=48, num_updates=3500, lr=2.51295e-05, gnorm=0.157, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4224
2023-08-08 19:25:23 - progress_bar.py[line:272] - INFO: epoch 001:   3516 / 8233 loss=5.796, loss_v1=0, loss_v2=0, nll_loss=4.702, ntokens=335.7, nsentences=48, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=26.04, wps=277.4, ups=0.83, wpb=335.7, bsz=48, num_updates=3510, lr=2.51101e-05, gnorm=0.155, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4236
2023-08-08 19:25:35 - progress_bar.py[line:272] - INFO: epoch 001:   3526 / 8233 loss=5.771, loss_v1=0, loss_v2=0, nll_loss=4.68, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=25.63, wps=286.6, ups=0.84, wpb=341, bsz=48, num_updates=3520, lr=2.50908e-05, gnorm=0.16, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4248
2023-08-08 19:25:47 - progress_bar.py[line:272] - INFO: epoch 001:   3536 / 8233 loss=5.761, loss_v1=0, loss_v2=0, nll_loss=4.671, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=25.48, wps=281.5, ups=0.84, wpb=336.8, bsz=48, num_updates=3530, lr=2.50714e-05, gnorm=0.158, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4260
2023-08-08 19:25:59 - progress_bar.py[line:272] - INFO: epoch 001:   3546 / 8233 loss=5.724, loss_v1=0, loss_v2=0, nll_loss=4.627, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=24.71, wps=284.3, ups=0.84, wpb=339.5, bsz=48, num_updates=3540, lr=2.5052e-05, gnorm=0.164, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4271
2023-08-08 19:26:11 - progress_bar.py[line:272] - INFO: epoch 001:   3556 / 8233 loss=5.711, loss_v1=0, loss_v2=0, nll_loss=4.606, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=24.36, wps=281.7, ups=0.83, wpb=338.3, bsz=48, num_updates=3550, lr=2.50326e-05, gnorm=0.161, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4283
2023-08-08 19:26:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 19:26:24 - progress_bar.py[line:272] - INFO: epoch 001:   3567 / 8233 loss=5.763, loss_v1=0, loss_v2=0, nll_loss=4.666, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=25.39, wps=259.8, ups=0.76, wpb=340.3, bsz=48, num_updates=3560, lr=2.50132e-05, gnorm=0.16, clip=0, loss_scale=32, train_wall=13, gb_free=14.5, wall=4297
2023-08-08 19:26:36 - progress_bar.py[line:272] - INFO: epoch 001:   3577 / 8233 loss=5.711, loss_v1=0, loss_v2=0, nll_loss=4.605, ntokens=331.8, nsentences=48, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=24.34, wps=275.1, ups=0.83, wpb=331.8, bsz=48, num_updates=3570, lr=2.49939e-05, gnorm=0.16, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4309
2023-08-08 19:26:48 - progress_bar.py[line:272] - INFO: epoch 001:   3587 / 8233 loss=5.686, loss_v1=0, loss_v2=0, nll_loss=4.577, ntokens=335.7, nsentences=48, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=23.87, wps=277.8, ups=0.83, wpb=335.7, bsz=48, num_updates=3580, lr=2.49745e-05, gnorm=0.155, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4321
2023-08-08 19:27:00 - progress_bar.py[line:272] - INFO: epoch 001:   3597 / 8233 loss=5.75, loss_v1=0, loss_v2=0, nll_loss=4.653, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=25.16, wps=283.7, ups=0.84, wpb=339.6, bsz=48, num_updates=3590, lr=2.49551e-05, gnorm=0.156, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4333
2023-08-08 19:27:12 - progress_bar.py[line:272] - INFO: epoch 001:   3607 / 8233 loss=5.578, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=22.01, wps=281.6, ups=0.83, wpb=338.5, bsz=48, num_updates=3600, lr=2.49357e-05, gnorm=0.156, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4345
2023-08-08 19:27:24 - progress_bar.py[line:272] - INFO: epoch 001:   3617 / 8233 loss=5.687, loss_v1=0, loss_v2=0, nll_loss=4.575, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=23.84, wps=286.5, ups=0.84, wpb=341.7, bsz=48, num_updates=3610, lr=2.49163e-05, gnorm=0.158, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4357
2023-08-08 19:27:36 - progress_bar.py[line:272] - INFO: epoch 001:   3627 / 8233 loss=5.668, loss_v1=0, loss_v2=0, nll_loss=4.558, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=23.56, wps=280.8, ups=0.83, wpb=338.5, bsz=48, num_updates=3620, lr=2.4897e-05, gnorm=0.158, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4369
2023-08-08 19:27:48 - progress_bar.py[line:272] - INFO: epoch 001:   3637 / 8233 loss=5.669, loss_v1=0, loss_v2=0, nll_loss=4.557, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=23.55, wps=281.4, ups=0.83, wpb=339.3, bsz=48, num_updates=3630, lr=2.48776e-05, gnorm=0.158, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4381
2023-08-08 19:28:00 - progress_bar.py[line:272] - INFO: epoch 001:   3647 / 8233 loss=5.643, loss_v1=0, loss_v2=0, nll_loss=4.522, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=22.98, wps=279.7, ups=0.83, wpb=337.1, bsz=48, num_updates=3640, lr=2.48582e-05, gnorm=0.154, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4393
2023-08-08 19:28:12 - progress_bar.py[line:272] - INFO: epoch 001:   3657 / 8233 loss=5.673, loss_v1=0, loss_v2=0, nll_loss=4.557, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=23.53, wps=278.9, ups=0.83, wpb=337.1, bsz=48, num_updates=3650, lr=2.48388e-05, gnorm=0.155, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4405
2023-08-08 19:28:24 - progress_bar.py[line:272] - INFO: epoch 001:   3667 / 8233 loss=5.7, loss_v1=0, loss_v2=0, nll_loss=4.587, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=24.03, wps=275.4, ups=0.82, wpb=334.2, bsz=48, num_updates=3660, lr=2.48194e-05, gnorm=0.154, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4417
2023-08-08 19:28:36 - progress_bar.py[line:272] - INFO: epoch 001:   3677 / 8233 loss=5.646, loss_v1=0, loss_v2=0, nll_loss=4.529, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=23.08, wps=282.8, ups=0.83, wpb=339.8, bsz=48, num_updates=3670, lr=2.48001e-05, gnorm=0.165, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4429
2023-08-08 19:28:48 - progress_bar.py[line:272] - INFO: epoch 001:   3687 / 8233 loss=5.662, loss_v1=0, loss_v2=0, nll_loss=4.549, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=23.41, wps=284, ups=0.84, wpb=340, bsz=48, num_updates=3680, lr=2.47807e-05, gnorm=0.157, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4441
2023-08-08 19:29:00 - progress_bar.py[line:272] - INFO: epoch 001:   3697 / 8233 loss=5.646, loss_v1=0, loss_v2=0, nll_loss=4.524, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=23.01, wps=279.7, ups=0.83, wpb=337.9, bsz=48, num_updates=3690, lr=2.47613e-05, gnorm=0.152, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4453
2023-08-08 19:29:12 - progress_bar.py[line:272] - INFO: epoch 001:   3707 / 8233 loss=5.584, loss_v1=0, loss_v2=0, nll_loss=4.451, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=21.88, wps=283.2, ups=0.83, wpb=339.3, bsz=48, num_updates=3700, lr=2.47419e-05, gnorm=0.153, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4465
2023-08-08 19:29:24 - progress_bar.py[line:272] - INFO: epoch 001:   3717 / 8233 loss=5.665, loss_v1=0, loss_v2=0, nll_loss=4.535, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=23.18, wps=284.4, ups=0.84, wpb=340.2, bsz=48, num_updates=3710, lr=2.47225e-05, gnorm=0.155, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4477
2023-08-08 19:29:36 - progress_bar.py[line:272] - INFO: epoch 001:   3727 / 8233 loss=5.573, loss_v1=0, loss_v2=0, nll_loss=4.441, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=21.73, wps=285, ups=0.84, wpb=340.4, bsz=48, num_updates=3720, lr=2.47031e-05, gnorm=0.151, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4489
2023-08-08 19:29:48 - progress_bar.py[line:272] - INFO: epoch 001:   3737 / 8233 loss=5.595, loss_v1=0, loss_v2=0, nll_loss=4.473, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=22.21, wps=281.1, ups=0.83, wpb=338, bsz=48, num_updates=3730, lr=2.46838e-05, gnorm=0.154, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4501
2023-08-08 19:30:00 - progress_bar.py[line:272] - INFO: epoch 001:   3747 / 8233 loss=5.566, loss_v1=0, loss_v2=0, nll_loss=4.426, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=21.49, wps=278.4, ups=0.83, wpb=335.5, bsz=48, num_updates=3740, lr=2.46644e-05, gnorm=0.148, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4513
2023-08-08 19:30:12 - progress_bar.py[line:272] - INFO: epoch 001:   3757 / 8233 loss=5.624, loss_v1=0, loss_v2=0, nll_loss=4.499, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=22.61, wps=283.7, ups=0.84, wpb=339.5, bsz=48, num_updates=3750, lr=2.4645e-05, gnorm=0.15, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4525
2023-08-08 19:30:24 - progress_bar.py[line:272] - INFO: epoch 001:   3767 / 8233 loss=5.589, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=22.01, wps=283.4, ups=0.83, wpb=339.7, bsz=48, num_updates=3760, lr=2.46256e-05, gnorm=0.152, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4537
2023-08-08 19:30:36 - progress_bar.py[line:272] - INFO: epoch 001:   3777 / 8233 loss=5.579, loss_v1=0, loss_v2=0, nll_loss=4.445, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=21.79, wps=283.1, ups=0.84, wpb=338.9, bsz=48, num_updates=3770, lr=2.46062e-05, gnorm=0.151, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4549
2023-08-08 19:30:48 - progress_bar.py[line:272] - INFO: epoch 001:   3787 / 8233 loss=5.592, loss_v1=0, loss_v2=0, nll_loss=4.455, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=21.94, wps=281.4, ups=0.83, wpb=338.3, bsz=48, num_updates=3780, lr=2.45869e-05, gnorm=0.155, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4561
2023-08-08 19:31:00 - progress_bar.py[line:272] - INFO: epoch 001:   3797 / 8233 loss=5.562, loss_v1=0, loss_v2=0, nll_loss=4.427, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=21.52, wps=282.7, ups=0.83, wpb=339.3, bsz=48, num_updates=3790, lr=2.45675e-05, gnorm=0.15, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4573
2023-08-08 19:31:12 - progress_bar.py[line:272] - INFO: epoch 001:   3807 / 8233 loss=5.61, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=22.33, wps=278.1, ups=0.83, wpb=334.5, bsz=48, num_updates=3800, lr=2.45481e-05, gnorm=0.153, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4585
2023-08-08 19:31:24 - progress_bar.py[line:272] - INFO: epoch 001:   3817 / 8233 loss=5.539, loss_v1=0, loss_v2=0, nll_loss=4.404, ntokens=332.5, nsentences=47.1, sample_size=332.5, sample_size_v1=0, sample_size_v2=0, ppl=21.16, wps=281.1, ups=0.85, wpb=332.5, bsz=47.1, num_updates=3810, lr=2.45287e-05, gnorm=0.15, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4597
2023-08-08 19:31:36 - progress_bar.py[line:272] - INFO: epoch 001:   3827 / 8233 loss=5.555, loss_v1=0, loss_v2=0, nll_loss=4.415, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=21.34, wps=279.7, ups=0.83, wpb=337.7, bsz=48, num_updates=3820, lr=2.45093e-05, gnorm=0.153, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4609
2023-08-08 19:31:48 - progress_bar.py[line:272] - INFO: epoch 001:   3837 / 8233 loss=5.586, loss_v1=0, loss_v2=0, nll_loss=4.448, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=21.83, wps=284.9, ups=0.83, wpb=341.7, bsz=48, num_updates=3830, lr=2.449e-05, gnorm=0.155, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4621
2023-08-08 19:32:00 - progress_bar.py[line:272] - INFO: epoch 001:   3847 / 8233 loss=5.552, loss_v1=0, loss_v2=0, nll_loss=4.415, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=21.34, wps=280.4, ups=0.83, wpb=336.1, bsz=48, num_updates=3840, lr=2.44706e-05, gnorm=0.152, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4633
2023-08-08 19:32:12 - progress_bar.py[line:272] - INFO: epoch 001:   3857 / 8233 loss=5.545, loss_v1=0, loss_v2=0, nll_loss=4.402, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=21.14, wps=283.6, ups=0.84, wpb=339.3, bsz=48, num_updates=3850, lr=2.44512e-05, gnorm=0.149, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4645
2023-08-08 19:32:24 - progress_bar.py[line:272] - INFO: epoch 001:   3867 / 8233 loss=5.538, loss_v1=0, loss_v2=0, nll_loss=4.395, ntokens=333.6, nsentences=48, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=21.03, wps=274.8, ups=0.82, wpb=333.6, bsz=48, num_updates=3860, lr=2.44318e-05, gnorm=0.146, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4657
2023-08-08 19:32:36 - progress_bar.py[line:272] - INFO: epoch 001:   3877 / 8233 loss=5.567, loss_v1=0, loss_v2=0, nll_loss=4.431, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=21.57, wps=277.1, ups=0.83, wpb=335.1, bsz=48, num_updates=3870, lr=2.44124e-05, gnorm=0.148, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4669
2023-08-08 19:32:48 - progress_bar.py[line:272] - INFO: epoch 001:   3887 / 8233 loss=5.583, loss_v1=0, loss_v2=0, nll_loss=4.451, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=21.88, wps=279.3, ups=0.83, wpb=337, bsz=48, num_updates=3880, lr=2.4393e-05, gnorm=0.153, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4681
2023-08-08 19:33:00 - progress_bar.py[line:272] - INFO: epoch 001:   3897 / 8233 loss=5.518, loss_v1=0, loss_v2=0, nll_loss=4.368, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=20.66, wps=278, ups=0.83, wpb=335.9, bsz=48, num_updates=3890, lr=2.43737e-05, gnorm=0.148, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4693
2023-08-08 19:33:13 - progress_bar.py[line:272] - INFO: epoch 001:   3907 / 8233 loss=5.483, loss_v1=0, loss_v2=0, nll_loss=4.327, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=20.06, wps=280.2, ups=0.83, wpb=338.5, bsz=48, num_updates=3900, lr=2.43543e-05, gnorm=0.142, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4705
2023-08-08 19:33:25 - progress_bar.py[line:272] - INFO: epoch 001:   3917 / 8233 loss=5.558, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=21.41, wps=285.4, ups=0.84, wpb=340.6, bsz=48, num_updates=3910, lr=2.43349e-05, gnorm=0.15, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4717
2023-08-08 19:33:36 - progress_bar.py[line:272] - INFO: epoch 001:   3927 / 8233 loss=5.527, loss_v1=0, loss_v2=0, nll_loss=4.373, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=20.72, wps=286.6, ups=0.84, wpb=341.7, bsz=48, num_updates=3920, lr=2.43155e-05, gnorm=0.15, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4729
2023-08-08 19:33:48 - progress_bar.py[line:272] - INFO: epoch 001:   3937 / 8233 loss=5.532, loss_v1=0, loss_v2=0, nll_loss=4.381, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=20.83, wps=283.3, ups=0.84, wpb=338.4, bsz=48, num_updates=3930, lr=2.42961e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4741
2023-08-08 19:34:00 - progress_bar.py[line:272] - INFO: epoch 001:   3947 / 8233 loss=5.555, loss_v1=0, loss_v2=0, nll_loss=4.41, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=21.26, wps=281.8, ups=0.83, wpb=337.6, bsz=48, num_updates=3940, lr=2.42768e-05, gnorm=0.146, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4753
2023-08-08 19:34:12 - progress_bar.py[line:272] - INFO: epoch 001:   3957 / 8233 loss=5.51, loss_v1=0, loss_v2=0, nll_loss=4.354, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=20.44, wps=281.2, ups=0.83, wpb=337.8, bsz=48, num_updates=3950, lr=2.42574e-05, gnorm=0.148, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4765
2023-08-08 19:34:24 - progress_bar.py[line:272] - INFO: epoch 001:   3967 / 8233 loss=5.488, loss_v1=0, loss_v2=0, nll_loss=4.333, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=20.16, wps=282.2, ups=0.83, wpb=339.8, bsz=48, num_updates=3960, lr=2.4238e-05, gnorm=0.144, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4777
2023-08-08 19:34:36 - progress_bar.py[line:272] - INFO: epoch 001:   3977 / 8233 loss=5.48, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=19.97, wps=279.6, ups=0.83, wpb=337, bsz=48, num_updates=3970, lr=2.42186e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4789
2023-08-08 19:34:49 - progress_bar.py[line:272] - INFO: epoch 001:   3987 / 8233 loss=5.538, loss_v1=0, loss_v2=0, nll_loss=4.387, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=20.93, wps=278.7, ups=0.83, wpb=336.3, bsz=48, num_updates=3980, lr=2.41992e-05, gnorm=0.155, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4801
2023-08-08 19:35:01 - progress_bar.py[line:272] - INFO: epoch 001:   3997 / 8233 loss=5.496, loss_v1=0, loss_v2=0, nll_loss=4.338, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=20.23, wps=277.6, ups=0.83, wpb=335.9, bsz=48, num_updates=3990, lr=2.41799e-05, gnorm=0.147, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4814
2023-08-08 19:35:13 - progress_bar.py[line:272] - INFO: epoch 001:   4007 / 8233 loss=5.458, loss_v1=0, loss_v2=0, nll_loss=4.298, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=19.67, wps=279.3, ups=0.83, wpb=337, bsz=48, num_updates=4000, lr=2.41605e-05, gnorm=0.144, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4826
2023-08-08 19:35:25 - progress_bar.py[line:272] - INFO: epoch 001:   4017 / 8233 loss=5.558, loss_v1=0, loss_v2=0, nll_loss=4.415, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=21.34, wps=281.3, ups=0.83, wpb=339.1, bsz=48, num_updates=4010, lr=2.41411e-05, gnorm=0.151, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4838
2023-08-08 19:35:37 - progress_bar.py[line:272] - INFO: epoch 001:   4027 / 8233 loss=5.518, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=20.54, wps=287.2, ups=0.84, wpb=341.4, bsz=48, num_updates=4020, lr=2.41217e-05, gnorm=0.151, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4850
2023-08-08 19:35:49 - progress_bar.py[line:272] - INFO: epoch 001:   4037 / 8233 loss=5.468, loss_v1=0, loss_v2=0, nll_loss=4.317, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=19.93, wps=282.9, ups=0.84, wpb=338.6, bsz=48, num_updates=4030, lr=2.41023e-05, gnorm=0.147, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4862
2023-08-08 19:36:01 - progress_bar.py[line:272] - INFO: epoch 001:   4047 / 8233 loss=5.511, loss_v1=0, loss_v2=0, nll_loss=4.363, ntokens=332.9, nsentences=48, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=20.58, wps=275.2, ups=0.83, wpb=332.9, bsz=48, num_updates=4040, lr=2.4083e-05, gnorm=0.142, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4874
2023-08-08 19:36:13 - progress_bar.py[line:272] - INFO: epoch 001:   4057 / 8233 loss=5.518, loss_v1=0, loss_v2=0, nll_loss=4.365, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=20.6, wps=280.9, ups=0.83, wpb=337.3, bsz=48, num_updates=4050, lr=2.40636e-05, gnorm=0.153, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4886
2023-08-08 19:36:25 - progress_bar.py[line:272] - INFO: epoch 001:   4067 / 8233 loss=5.46, loss_v1=0, loss_v2=0, nll_loss=4.3, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=19.7, wps=279.5, ups=0.83, wpb=337, bsz=48, num_updates=4060, lr=2.40442e-05, gnorm=0.147, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=4898
2023-08-08 19:36:37 - progress_bar.py[line:272] - INFO: epoch 001:   4077 / 8233 loss=5.427, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=283.6, ups=0.83, wpb=340.6, bsz=48, num_updates=4070, lr=2.40248e-05, gnorm=0.143, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4910
2023-08-08 19:36:49 - progress_bar.py[line:272] - INFO: epoch 001:   4087 / 8233 loss=5.514, loss_v1=0, loss_v2=0, nll_loss=4.356, ntokens=333.9, nsentences=48, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=20.48, wps=275.1, ups=0.82, wpb=333.9, bsz=48, num_updates=4080, lr=2.40054e-05, gnorm=0.149, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4922
2023-08-08 19:37:01 - progress_bar.py[line:272] - INFO: epoch 001:   4097 / 8233 loss=5.406, loss_v1=0, loss_v2=0, nll_loss=4.23, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=18.77, wps=281.3, ups=0.84, wpb=336.8, bsz=48, num_updates=4090, lr=2.3986e-05, gnorm=0.146, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4934
2023-08-08 19:37:13 - progress_bar.py[line:272] - INFO: epoch 001:   4107 / 8233 loss=5.481, loss_v1=0, loss_v2=0, nll_loss=4.322, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=20, wps=280, ups=0.83, wpb=337.8, bsz=48, num_updates=4100, lr=2.39667e-05, gnorm=0.142, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4946
2023-08-08 19:37:25 - progress_bar.py[line:272] - INFO: epoch 001:   4117 / 8233 loss=5.432, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=280.6, ups=0.83, wpb=337.7, bsz=48, num_updates=4110, lr=2.39473e-05, gnorm=0.14, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4958
2023-08-08 19:37:37 - progress_bar.py[line:272] - INFO: epoch 001:   4127 / 8233 loss=5.437, loss_v1=0, loss_v2=0, nll_loss=4.27, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=19.3, wps=279.1, ups=0.83, wpb=335.9, bsz=48, num_updates=4120, lr=2.39279e-05, gnorm=0.144, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4970
2023-08-08 19:37:49 - progress_bar.py[line:272] - INFO: epoch 001:   4137 / 8233 loss=5.461, loss_v1=0, loss_v2=0, nll_loss=4.286, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=19.51, wps=287.2, ups=0.84, wpb=340.4, bsz=48, num_updates=4130, lr=2.39085e-05, gnorm=0.146, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4982
2023-08-08 19:38:01 - progress_bar.py[line:272] - INFO: epoch 001:   4147 / 8233 loss=5.429, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=19.19, wps=282.6, ups=0.83, wpb=338.5, bsz=48, num_updates=4140, lr=2.38891e-05, gnorm=0.141, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=4994
2023-08-08 19:38:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 19:38:14 - progress_bar.py[line:272] - INFO: epoch 001:   4158 / 8233 loss=5.418, loss_v1=0, loss_v2=0, nll_loss=4.25, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=19.03, wps=259.9, ups=0.76, wpb=339.8, bsz=48, num_updates=4150, lr=2.38698e-05, gnorm=0.147, clip=0, loss_scale=32, train_wall=13, gb_free=14.5, wall=5007
2023-08-08 19:38:26 - progress_bar.py[line:272] - INFO: epoch 001:   4168 / 8233 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.252, ntokens=342.8, nsentences=48, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=19.05, wps=287.5, ups=0.84, wpb=342.8, bsz=48, num_updates=4160, lr=2.38504e-05, gnorm=0.147, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5019
2023-08-08 19:38:38 - progress_bar.py[line:272] - INFO: epoch 001:   4178 / 8233 loss=5.44, loss_v1=0, loss_v2=0, nll_loss=4.266, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=19.25, wps=279.2, ups=0.83, wpb=337, bsz=48, num_updates=4170, lr=2.3831e-05, gnorm=0.142, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5031
2023-08-08 19:38:50 - progress_bar.py[line:272] - INFO: epoch 001:   4188 / 8233 loss=5.439, loss_v1=0, loss_v2=0, nll_loss=4.268, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=19.26, wps=283.4, ups=0.83, wpb=340, bsz=48, num_updates=4180, lr=2.38116e-05, gnorm=0.15, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5043
2023-08-08 19:39:02 - progress_bar.py[line:272] - INFO: epoch 001:   4198 / 8233 loss=5.378, loss_v1=0, loss_v2=0, nll_loss=4.198, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=18.35, wps=284.1, ups=0.84, wpb=339.8, bsz=48, num_updates=4190, lr=2.37922e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5055
2023-08-08 19:39:14 - progress_bar.py[line:272] - INFO: epoch 001:   4208 / 8233 loss=5.411, loss_v1=0, loss_v2=0, nll_loss=4.235, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=18.83, wps=281, ups=0.83, wpb=338, bsz=48, num_updates=4200, lr=2.37729e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5067
2023-08-08 19:39:26 - progress_bar.py[line:272] - INFO: epoch 001:   4218 / 8233 loss=5.428, loss_v1=0, loss_v2=0, nll_loss=4.259, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=19.14, wps=281.8, ups=0.83, wpb=339.6, bsz=48, num_updates=4210, lr=2.37535e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5079
2023-08-08 19:39:38 - progress_bar.py[line:272] - INFO: epoch 001:   4228 / 8233 loss=5.391, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=283.7, ups=0.83, wpb=340, bsz=48, num_updates=4220, lr=2.37341e-05, gnorm=0.137, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5091
2023-08-08 19:39:50 - progress_bar.py[line:272] - INFO: epoch 001:   4238 / 8233 loss=5.395, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=279.6, ups=0.83, wpb=337, bsz=48, num_updates=4230, lr=2.37147e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5103
2023-08-08 19:40:02 - progress_bar.py[line:272] - INFO: epoch 001:   4248 / 8233 loss=5.399, loss_v1=0, loss_v2=0, nll_loss=4.225, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=18.7, wps=280.9, ups=0.83, wpb=338.8, bsz=48, num_updates=4240, lr=2.36953e-05, gnorm=0.14, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5115
2023-08-08 19:40:14 - progress_bar.py[line:272] - INFO: epoch 001:   4258 / 8233 loss=5.398, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=276.5, ups=0.83, wpb=335.1, bsz=48, num_updates=4250, lr=2.36759e-05, gnorm=0.146, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5127
2023-08-08 19:40:26 - progress_bar.py[line:272] - INFO: epoch 001:   4268 / 8233 loss=5.371, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=18.35, wps=284.9, ups=0.83, wpb=341.3, bsz=48, num_updates=4260, lr=2.36566e-05, gnorm=0.147, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5139
2023-08-08 19:40:38 - progress_bar.py[line:272] - INFO: epoch 001:   4278 / 8233 loss=5.429, loss_v1=0, loss_v2=0, nll_loss=4.253, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=19.06, wps=284.9, ups=0.83, wpb=341.2, bsz=48, num_updates=4270, lr=2.36372e-05, gnorm=0.142, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5151
2023-08-08 19:40:50 - progress_bar.py[line:272] - INFO: epoch 001:   4288 / 8233 loss=5.38, loss_v1=0, loss_v2=0, nll_loss=4.198, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=18.35, wps=279.1, ups=0.83, wpb=336.2, bsz=48, num_updates=4280, lr=2.36178e-05, gnorm=0.144, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5163
2023-08-08 19:41:02 - progress_bar.py[line:272] - INFO: epoch 001:   4298 / 8233 loss=5.362, loss_v1=0, loss_v2=0, nll_loss=4.178, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=18.1, wps=279.5, ups=0.83, wpb=337.1, bsz=48, num_updates=4290, lr=2.35984e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5175
2023-08-08 19:41:14 - progress_bar.py[line:272] - INFO: epoch 001:   4308 / 8233 loss=5.372, loss_v1=0, loss_v2=0, nll_loss=4.189, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=18.24, wps=283, ups=0.83, wpb=339.7, bsz=48, num_updates=4300, lr=2.3579e-05, gnorm=0.142, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5187
2023-08-08 19:41:27 - progress_bar.py[line:272] - INFO: epoch 001:   4318 / 8233 loss=5.412, loss_v1=0, loss_v2=0, nll_loss=4.232, ntokens=333.1, nsentences=48, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=18.79, wps=273.9, ups=0.82, wpb=333.1, bsz=48, num_updates=4310, lr=2.35597e-05, gnorm=0.146, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5199
2023-08-08 19:41:39 - progress_bar.py[line:272] - INFO: epoch 001:   4328 / 8233 loss=5.348, loss_v1=0, loss_v2=0, nll_loss=4.161, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=17.89, wps=280.7, ups=0.83, wpb=337.3, bsz=48, num_updates=4320, lr=2.35403e-05, gnorm=0.145, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5211
2023-08-08 19:41:51 - progress_bar.py[line:272] - INFO: epoch 001:   4338 / 8233 loss=5.393, loss_v1=0, loss_v2=0, nll_loss=4.212, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=18.53, wps=283.2, ups=0.84, wpb=338.5, bsz=48, num_updates=4330, lr=2.35209e-05, gnorm=0.146, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5223
2023-08-08 19:42:02 - progress_bar.py[line:272] - INFO: epoch 001:   4348 / 8233 loss=5.349, loss_v1=0, loss_v2=0, nll_loss=4.157, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=17.84, wps=281.9, ups=0.84, wpb=337.4, bsz=48, num_updates=4340, lr=2.35015e-05, gnorm=0.148, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5235
2023-08-08 19:42:15 - progress_bar.py[line:272] - INFO: epoch 001:   4358 / 8233 loss=5.371, loss_v1=0, loss_v2=0, nll_loss=4.182, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=18.15, wps=280.4, ups=0.83, wpb=337.2, bsz=48, num_updates=4350, lr=2.34821e-05, gnorm=0.141, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5247
2023-08-08 19:42:26 - progress_bar.py[line:272] - INFO: epoch 001:   4368 / 8233 loss=5.299, loss_v1=0, loss_v2=0, nll_loss=4.098, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=17.13, wps=283.7, ups=0.84, wpb=339.3, bsz=48, num_updates=4360, lr=2.34628e-05, gnorm=0.138, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5259
2023-08-08 19:42:38 - progress_bar.py[line:272] - INFO: epoch 001:   4378 / 8233 loss=5.329, loss_v1=0, loss_v2=0, nll_loss=4.142, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=17.65, wps=282.6, ups=0.83, wpb=338.9, bsz=48, num_updates=4370, lr=2.34434e-05, gnorm=0.14, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5271
2023-08-08 19:42:50 - progress_bar.py[line:272] - INFO: epoch 001:   4388 / 8233 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.136, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=17.58, wps=283.1, ups=0.83, wpb=339.8, bsz=48, num_updates=4380, lr=2.3424e-05, gnorm=0.138, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5283
2023-08-08 19:43:02 - progress_bar.py[line:272] - INFO: epoch 001:   4398 / 8233 loss=5.335, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=285.2, ups=0.84, wpb=340.6, bsz=48, num_updates=4390, lr=2.34046e-05, gnorm=0.145, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5295
2023-08-08 19:43:14 - progress_bar.py[line:272] - INFO: epoch 001:   4408 / 8233 loss=5.293, loss_v1=0, loss_v2=0, nll_loss=4.093, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=17.07, wps=286.5, ups=0.84, wpb=340.5, bsz=48, num_updates=4400, lr=2.33852e-05, gnorm=0.14, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5307
2023-08-08 19:43:26 - progress_bar.py[line:272] - INFO: epoch 001:   4418 / 8233 loss=5.35, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=17.85, wps=279.3, ups=0.83, wpb=334.7, bsz=48, num_updates=4410, lr=2.33659e-05, gnorm=0.14, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5319
2023-08-08 19:43:38 - progress_bar.py[line:272] - INFO: epoch 001:   4428 / 8233 loss=5.377, loss_v1=0, loss_v2=0, nll_loss=4.19, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=18.25, wps=286.1, ups=0.84, wpb=339.8, bsz=48, num_updates=4420, lr=2.33465e-05, gnorm=0.141, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5331
2023-08-08 19:43:50 - progress_bar.py[line:272] - INFO: epoch 001:   4438 / 8233 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.123, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=17.43, wps=282.8, ups=0.83, wpb=340.6, bsz=48, num_updates=4430, lr=2.33271e-05, gnorm=0.137, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5343
2023-08-08 19:44:02 - progress_bar.py[line:272] - INFO: epoch 001:   4448 / 8233 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.078, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=16.89, wps=281.5, ups=0.83, wpb=339.7, bsz=48, num_updates=4440, lr=2.33077e-05, gnorm=0.141, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5355
2023-08-08 19:44:14 - progress_bar.py[line:272] - INFO: epoch 001:   4458 / 8233 loss=5.283, loss_v1=0, loss_v2=0, nll_loss=4.085, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=16.97, wps=282, ups=0.83, wpb=339.1, bsz=48, num_updates=4450, lr=2.32883e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5367
2023-08-08 19:44:26 - progress_bar.py[line:272] - INFO: epoch 001:   4468 / 8233 loss=5.319, loss_v1=0, loss_v2=0, nll_loss=4.124, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=17.44, wps=280.2, ups=0.83, wpb=337.4, bsz=48, num_updates=4460, lr=2.32689e-05, gnorm=0.145, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5379
2023-08-08 19:44:38 - progress_bar.py[line:272] - INFO: epoch 001:   4478 / 8233 loss=5.307, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=282.5, ups=0.83, wpb=338.5, bsz=48, num_updates=4470, lr=2.32496e-05, gnorm=0.138, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5391
2023-08-08 19:44:50 - progress_bar.py[line:272] - INFO: epoch 001:   4488 / 8233 loss=5.322, loss_v1=0, loss_v2=0, nll_loss=4.121, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=17.4, wps=279.6, ups=0.83, wpb=338.1, bsz=48, num_updates=4480, lr=2.32302e-05, gnorm=0.144, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5403
2023-08-08 19:45:03 - progress_bar.py[line:272] - INFO: epoch 001:   4498 / 8233 loss=5.323, loss_v1=0, loss_v2=0, nll_loss=4.126, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=17.47, wps=279.7, ups=0.83, wpb=337.3, bsz=48, num_updates=4490, lr=2.32108e-05, gnorm=0.134, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5415
2023-08-08 19:45:15 - progress_bar.py[line:272] - INFO: epoch 001:   4508 / 8233 loss=5.335, loss_v1=0, loss_v2=0, nll_loss=4.143, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=17.67, wps=283.3, ups=0.83, wpb=339.7, bsz=48, num_updates=4500, lr=2.31914e-05, gnorm=0.142, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5427
2023-08-08 19:45:27 - progress_bar.py[line:272] - INFO: epoch 001:   4518 / 8233 loss=5.267, loss_v1=0, loss_v2=0, nll_loss=4.066, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=16.75, wps=280.7, ups=0.83, wpb=337.8, bsz=48, num_updates=4510, lr=2.3172e-05, gnorm=0.138, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5439
2023-08-08 19:45:39 - progress_bar.py[line:272] - INFO: epoch 001:   4528 / 8233 loss=5.321, loss_v1=0, loss_v2=0, nll_loss=4.127, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=17.48, wps=282.8, ups=0.83, wpb=339.6, bsz=48, num_updates=4520, lr=2.31527e-05, gnorm=0.138, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5451
2023-08-08 19:45:51 - progress_bar.py[line:272] - INFO: epoch 001:   4538 / 8233 loss=5.37, loss_v1=0, loss_v2=0, nll_loss=4.183, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=18.16, wps=280.2, ups=0.83, wpb=337.5, bsz=48, num_updates=4530, lr=2.31333e-05, gnorm=0.14, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5463
2023-08-08 19:46:03 - progress_bar.py[line:272] - INFO: epoch 001:   4548 / 8233 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.111, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=17.28, wps=283.4, ups=0.84, wpb=339, bsz=48, num_updates=4540, lr=2.31139e-05, gnorm=0.137, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5475
2023-08-08 19:46:15 - progress_bar.py[line:272] - INFO: epoch 001:   4558 / 8233 loss=5.305, loss_v1=0, loss_v2=0, nll_loss=4.106, ntokens=333.1, nsentences=48, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=17.22, wps=277.1, ups=0.83, wpb=333.1, bsz=48, num_updates=4550, lr=2.30945e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5487
2023-08-08 19:46:27 - progress_bar.py[line:272] - INFO: epoch 001:   4568 / 8233 loss=5.351, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=17.88, wps=280.9, ups=0.83, wpb=339.2, bsz=48, num_updates=4560, lr=2.30751e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5500
2023-08-08 19:46:39 - progress_bar.py[line:272] - INFO: epoch 001:   4578 / 8233 loss=5.318, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=17.39, wps=281.1, ups=0.83, wpb=338.2, bsz=48, num_updates=4570, lr=2.30558e-05, gnorm=0.143, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5512
2023-08-08 19:46:51 - progress_bar.py[line:272] - INFO: epoch 001:   4588 / 8233 loss=5.28, loss_v1=0, loss_v2=0, nll_loss=4.085, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=16.97, wps=285.2, ups=0.84, wpb=341.4, bsz=48, num_updates=4580, lr=2.30364e-05, gnorm=0.138, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5524
2023-08-08 19:47:03 - progress_bar.py[line:272] - INFO: epoch 001:   4598 / 8233 loss=5.283, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=16.98, wps=281, ups=0.83, wpb=338.6, bsz=48, num_updates=4590, lr=2.3017e-05, gnorm=0.135, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5536
2023-08-08 19:47:15 - progress_bar.py[line:272] - INFO: epoch 001:   4608 / 8233 loss=5.302, loss_v1=0, loss_v2=0, nll_loss=4.099, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=17.14, wps=282.8, ups=0.84, wpb=338.4, bsz=48, num_updates=4600, lr=2.29976e-05, gnorm=0.141, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5548
2023-08-08 19:47:27 - progress_bar.py[line:272] - INFO: epoch 001:   4618 / 8233 loss=5.274, loss_v1=0, loss_v2=0, nll_loss=4.066, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=16.75, wps=285.4, ups=0.84, wpb=341.4, bsz=48, num_updates=4610, lr=2.29782e-05, gnorm=0.14, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5560
2023-08-08 19:47:39 - progress_bar.py[line:272] - INFO: epoch 001:   4628 / 8233 loss=5.333, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=17.7, wps=281.9, ups=0.83, wpb=338.8, bsz=48, num_updates=4620, lr=2.29588e-05, gnorm=0.145, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5572
2023-08-08 19:47:51 - progress_bar.py[line:272] - INFO: epoch 001:   4638 / 8233 loss=5.259, loss_v1=0, loss_v2=0, nll_loss=4.055, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=16.62, wps=280.2, ups=0.83, wpb=337.8, bsz=48, num_updates=4630, lr=2.29395e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5584
2023-08-08 19:48:03 - progress_bar.py[line:272] - INFO: epoch 001:   4648 / 8233 loss=5.266, loss_v1=0, loss_v2=0, nll_loss=4.058, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=16.66, wps=283.1, ups=0.83, wpb=341, bsz=48, num_updates=4640, lr=2.29201e-05, gnorm=0.139, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5596
2023-08-08 19:48:15 - progress_bar.py[line:272] - INFO: epoch 001:   4658 / 8233 loss=5.269, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=16.79, wps=280.8, ups=0.83, wpb=338.5, bsz=48, num_updates=4650, lr=2.29007e-05, gnorm=0.138, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=5608
2023-08-08 19:48:27 - progress_bar.py[line:272] - INFO: epoch 001:   4668 / 8233 loss=5.247, loss_v1=0, loss_v2=0, nll_loss=4.035, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=16.39, wps=283.4, ups=0.83, wpb=341.2, bsz=48, num_updates=4660, lr=2.28813e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5620
2023-08-08 19:48:39 - progress_bar.py[line:272] - INFO: epoch 001:   4678 / 8233 loss=5.323, loss_v1=0, loss_v2=0, nll_loss=4.117, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=17.35, wps=278.4, ups=0.83, wpb=336.4, bsz=48, num_updates=4670, lr=2.28619e-05, gnorm=0.144, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5632
2023-08-08 19:48:51 - progress_bar.py[line:272] - INFO: epoch 001:   4688 / 8233 loss=5.225, loss_v1=0, loss_v2=0, nll_loss=4.012, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=16.13, wps=279.8, ups=0.83, wpb=337.3, bsz=48, num_updates=4680, lr=2.28426e-05, gnorm=0.138, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5644
2023-08-08 19:49:03 - progress_bar.py[line:272] - INFO: epoch 001:   4698 / 8233 loss=5.271, loss_v1=0, loss_v2=0, nll_loss=4.064, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=16.72, wps=282.9, ups=0.83, wpb=339.3, bsz=48, num_updates=4690, lr=2.28232e-05, gnorm=0.135, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5656
2023-08-08 19:49:15 - progress_bar.py[line:272] - INFO: epoch 001:   4708 / 8233 loss=5.262, loss_v1=0, loss_v2=0, nll_loss=4.053, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=16.6, wps=279.3, ups=0.83, wpb=337.7, bsz=48, num_updates=4700, lr=2.28038e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5668
2023-08-08 19:49:27 - progress_bar.py[line:272] - INFO: epoch 001:   4718 / 8233 loss=5.247, loss_v1=0, loss_v2=0, nll_loss=4.036, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=16.4, wps=282.1, ups=0.83, wpb=339.4, bsz=48, num_updates=4710, lr=2.27844e-05, gnorm=0.136, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5680
2023-08-08 19:49:39 - progress_bar.py[line:272] - INFO: epoch 001:   4728 / 8233 loss=5.246, loss_v1=0, loss_v2=0, nll_loss=4.029, ntokens=330.9, nsentences=48, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=16.32, wps=270.9, ups=0.82, wpb=330.9, bsz=48, num_updates=4720, lr=2.2765e-05, gnorm=0.137, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5692
2023-08-08 19:49:51 - progress_bar.py[line:272] - INFO: epoch 001:   4738 / 8233 loss=5.226, loss_v1=0, loss_v2=0, nll_loss=4.015, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=16.17, wps=280.6, ups=0.83, wpb=338.5, bsz=48, num_updates=4730, lr=2.27457e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5704
2023-08-08 19:50:03 - progress_bar.py[line:272] - INFO: epoch 001:   4748 / 8233 loss=5.214, loss_v1=0, loss_v2=0, nll_loss=4.004, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=16.05, wps=281.8, ups=0.83, wpb=338.2, bsz=48, num_updates=4740, lr=2.27263e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5716
2023-08-08 19:50:15 - progress_bar.py[line:272] - INFO: epoch 001:   4758 / 8233 loss=5.28, loss_v1=0, loss_v2=0, nll_loss=4.077, ntokens=342, nsentences=48, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=16.88, wps=286.7, ups=0.84, wpb=342, bsz=48, num_updates=4750, lr=2.27069e-05, gnorm=0.141, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5728
2023-08-08 19:50:27 - progress_bar.py[line:272] - INFO: epoch 001:   4768 / 8233 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.026, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=16.29, wps=280.8, ups=0.83, wpb=337.2, bsz=48, num_updates=4760, lr=2.26875e-05, gnorm=0.138, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5740
2023-08-08 19:50:39 - progress_bar.py[line:272] - INFO: epoch 001:   4778 / 8233 loss=5.239, loss_v1=0, loss_v2=0, nll_loss=4.02, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=16.23, wps=283.8, ups=0.84, wpb=339.3, bsz=48, num_updates=4770, lr=2.26681e-05, gnorm=0.133, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5752
2023-08-08 19:50:51 - progress_bar.py[line:272] - INFO: epoch 001:   4788 / 8233 loss=5.271, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=16.74, wps=279.2, ups=0.83, wpb=336.8, bsz=48, num_updates=4780, lr=2.26487e-05, gnorm=0.142, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5764
2023-08-08 19:51:04 - progress_bar.py[line:272] - INFO: epoch 001:   4798 / 8233 loss=5.254, loss_v1=0, loss_v2=0, nll_loss=4.042, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=16.48, wps=278.6, ups=0.83, wpb=336.9, bsz=48, num_updates=4790, lr=2.26294e-05, gnorm=0.141, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5776
2023-08-08 19:51:16 - progress_bar.py[line:272] - INFO: epoch 001:   4808 / 8233 loss=5.196, loss_v1=0, loss_v2=0, nll_loss=3.978, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=15.76, wps=282.6, ups=0.83, wpb=339, bsz=48, num_updates=4800, lr=2.261e-05, gnorm=0.129, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5788
2023-08-08 19:51:27 - progress_bar.py[line:272] - INFO: epoch 001:   4818 / 8233 loss=5.27, loss_v1=0, loss_v2=0, nll_loss=4.067, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=16.76, wps=286.1, ups=0.84, wpb=339.6, bsz=48, num_updates=4810, lr=2.25906e-05, gnorm=0.136, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5800
2023-08-08 19:51:39 - progress_bar.py[line:272] - INFO: epoch 001:   4828 / 8233 loss=5.21, loss_v1=0, loss_v2=0, nll_loss=3.993, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=15.92, wps=285, ups=0.84, wpb=340.8, bsz=48, num_updates=4820, lr=2.25712e-05, gnorm=0.143, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5812
2023-08-08 19:51:51 - progress_bar.py[line:272] - INFO: epoch 001:   4838 / 8233 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.028, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=16.31, wps=280.4, ups=0.83, wpb=337.6, bsz=48, num_updates=4830, lr=2.25518e-05, gnorm=0.135, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5824
2023-08-08 19:52:03 - progress_bar.py[line:272] - INFO: epoch 001:   4848 / 8233 loss=5.245, loss_v1=0, loss_v2=0, nll_loss=4.028, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=16.31, wps=279.7, ups=0.83, wpb=336.2, bsz=48, num_updates=4840, lr=2.25325e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5836
2023-08-08 19:52:15 - progress_bar.py[line:272] - INFO: epoch 001:   4858 / 8233 loss=5.244, loss_v1=0, loss_v2=0, nll_loss=4.037, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=16.41, wps=280.4, ups=0.83, wpb=337.6, bsz=48, num_updates=4850, lr=2.25131e-05, gnorm=0.137, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5848
2023-08-08 19:52:28 - progress_bar.py[line:272] - INFO: epoch 001:   4868 / 8233 loss=5.251, loss_v1=0, loss_v2=0, nll_loss=4.037, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=16.42, wps=282.8, ups=0.83, wpb=340.2, bsz=48, num_updates=4860, lr=2.24937e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5860
2023-08-08 19:52:40 - progress_bar.py[line:272] - INFO: epoch 001:   4878 / 8233 loss=5.253, loss_v1=0, loss_v2=0, nll_loss=4.041, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=16.47, wps=282, ups=0.83, wpb=340.1, bsz=48, num_updates=4870, lr=2.24743e-05, gnorm=0.135, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5872
2023-08-08 19:52:52 - progress_bar.py[line:272] - INFO: epoch 001:   4888 / 8233 loss=5.181, loss_v1=0, loss_v2=0, nll_loss=3.961, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=15.57, wps=280.6, ups=0.83, wpb=338.4, bsz=48, num_updates=4880, lr=2.24549e-05, gnorm=0.133, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5885
2023-08-08 19:53:04 - progress_bar.py[line:272] - INFO: epoch 001:   4898 / 8233 loss=5.187, loss_v1=0, loss_v2=0, nll_loss=3.972, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=15.7, wps=281.5, ups=0.83, wpb=338.4, bsz=48, num_updates=4890, lr=2.24356e-05, gnorm=0.132, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5897
2023-08-08 19:53:16 - progress_bar.py[line:272] - INFO: epoch 001:   4908 / 8233 loss=5.185, loss_v1=0, loss_v2=0, nll_loss=3.959, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=15.55, wps=282.2, ups=0.84, wpb=337.8, bsz=48, num_updates=4900, lr=2.24162e-05, gnorm=0.131, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5909
2023-08-08 19:53:28 - progress_bar.py[line:272] - INFO: epoch 001:   4918 / 8233 loss=5.21, loss_v1=0, loss_v2=0, nll_loss=3.993, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=15.92, wps=283.3, ups=0.83, wpb=339.8, bsz=48, num_updates=4910, lr=2.23968e-05, gnorm=0.14, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5921
2023-08-08 19:53:40 - progress_bar.py[line:272] - INFO: epoch 001:   4928 / 8233 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=3.99, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=15.89, wps=282.1, ups=0.83, wpb=339, bsz=48, num_updates=4920, lr=2.23774e-05, gnorm=0.138, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5933
2023-08-08 19:53:52 - progress_bar.py[line:272] - INFO: epoch 001:   4938 / 8233 loss=5.178, loss_v1=0, loss_v2=0, nll_loss=3.956, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=15.52, wps=282.4, ups=0.83, wpb=338.4, bsz=48, num_updates=4930, lr=2.2358e-05, gnorm=0.133, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5945
2023-08-08 19:54:04 - progress_bar.py[line:272] - INFO: epoch 001:   4948 / 8233 loss=5.192, loss_v1=0, loss_v2=0, nll_loss=3.967, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=15.63, wps=285.8, ups=0.84, wpb=341.1, bsz=48, num_updates=4940, lr=2.23387e-05, gnorm=0.137, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5956
2023-08-08 19:54:16 - progress_bar.py[line:272] - INFO: epoch 001:   4958 / 8233 loss=5.152, loss_v1=0, loss_v2=0, nll_loss=3.921, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=15.15, wps=280.4, ups=0.83, wpb=337.1, bsz=48, num_updates=4950, lr=2.23193e-05, gnorm=0.132, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5968
2023-08-08 19:54:27 - progress_bar.py[line:272] - INFO: epoch 001:   4968 / 8233 loss=5.197, loss_v1=0, loss_v2=0, nll_loss=3.972, ntokens=342.9, nsentences=48, sample_size=342.9, sample_size_v1=0, sample_size_v2=0, ppl=15.7, wps=290.5, ups=0.85, wpb=342.9, bsz=48, num_updates=4960, lr=2.22999e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5980
2023-08-08 19:54:39 - progress_bar.py[line:272] - INFO: epoch 001:   4978 / 8233 loss=5.213, loss_v1=0, loss_v2=0, nll_loss=3.99, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=15.89, wps=285.7, ups=0.84, wpb=341.3, bsz=48, num_updates=4970, lr=2.22805e-05, gnorm=0.145, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=5992
2023-08-08 19:54:51 - progress_bar.py[line:272] - INFO: epoch 001:   4988 / 8233 loss=5.21, loss_v1=0, loss_v2=0, nll_loss=3.986, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=15.85, wps=282.2, ups=0.83, wpb=338.8, bsz=48, num_updates=4980, lr=2.22611e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6004
2023-08-08 19:55:03 - progress_bar.py[line:272] - INFO: epoch 001:   4998 / 8233 loss=5.204, loss_v1=0, loss_v2=0, nll_loss=3.979, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=15.77, wps=278.8, ups=0.83, wpb=336.8, bsz=48, num_updates=4990, lr=2.22417e-05, gnorm=0.143, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6016
2023-08-08 19:55:16 - progress_bar.py[line:272] - INFO: epoch 001:   5008 / 8233 loss=5.176, loss_v1=0, loss_v2=0, nll_loss=3.949, ntokens=334.6, nsentences=48, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=15.45, wps=277.2, ups=0.83, wpb=334.6, bsz=48, num_updates=5000, lr=2.22224e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6028
2023-08-08 19:55:28 - progress_bar.py[line:272] - INFO: epoch 001:   5018 / 8233 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=3.972, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=15.69, wps=282.8, ups=0.83, wpb=339.1, bsz=48, num_updates=5010, lr=2.2203e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6040
2023-08-08 19:55:39 - progress_bar.py[line:272] - INFO: epoch 001:   5028 / 8233 loss=5.145, loss_v1=0, loss_v2=0, nll_loss=3.914, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=15.08, wps=282.4, ups=0.84, wpb=337.7, bsz=48, num_updates=5020, lr=2.21836e-05, gnorm=0.139, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6052
2023-08-08 19:55:51 - progress_bar.py[line:272] - INFO: epoch 001:   5038 / 8233 loss=5.227, loss_v1=0, loss_v2=0, nll_loss=4.005, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=16.05, wps=281.6, ups=0.83, wpb=337.2, bsz=48, num_updates=5030, lr=2.21642e-05, gnorm=0.141, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6064
2023-08-08 19:56:04 - progress_bar.py[line:272] - INFO: epoch 001:   5048 / 8233 loss=5.133, loss_v1=0, loss_v2=0, nll_loss=3.896, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=14.89, wps=279.9, ups=0.83, wpb=337.3, bsz=48, num_updates=5040, lr=2.21448e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6076
2023-08-08 19:56:15 - progress_bar.py[line:272] - INFO: epoch 001:   5058 / 8233 loss=5.18, loss_v1=0, loss_v2=0, nll_loss=3.954, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=15.5, wps=283.9, ups=0.83, wpb=340.2, bsz=48, num_updates=5050, lr=2.21255e-05, gnorm=0.138, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6088
2023-08-08 19:56:28 - progress_bar.py[line:272] - INFO: epoch 001:   5068 / 8233 loss=5.147, loss_v1=0, loss_v2=0, nll_loss=3.914, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=15.07, wps=277.7, ups=0.83, wpb=336.3, bsz=48, num_updates=5060, lr=2.21061e-05, gnorm=0.138, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6101
2023-08-08 19:56:40 - progress_bar.py[line:272] - INFO: epoch 001:   5078 / 8233 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=3.921, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=15.15, wps=283.1, ups=0.83, wpb=340.6, bsz=48, num_updates=5070, lr=2.20867e-05, gnorm=0.13, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6113
2023-08-08 19:56:52 - progress_bar.py[line:272] - INFO: epoch 001:   5088 / 8233 loss=5.244, loss_v1=0, loss_v2=0, nll_loss=4.021, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=16.24, wps=280.8, ups=0.83, wpb=337.1, bsz=48, num_updates=5080, lr=2.20673e-05, gnorm=0.14, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6125
2023-08-08 19:57:04 - progress_bar.py[line:272] - INFO: epoch 001:   5098 / 8233 loss=5.19, loss_v1=0, loss_v2=0, nll_loss=3.965, ntokens=334.8, nsentences=48, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=15.62, wps=274.2, ups=0.82, wpb=334.8, bsz=48, num_updates=5090, lr=2.20479e-05, gnorm=0.141, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6137
2023-08-08 19:57:16 - progress_bar.py[line:272] - INFO: epoch 001:   5108 / 8233 loss=5.138, loss_v1=0, loss_v2=0, nll_loss=3.902, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=14.95, wps=279.9, ups=0.83, wpb=337.7, bsz=48, num_updates=5100, lr=2.20286e-05, gnorm=0.136, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6149
2023-08-08 19:57:28 - progress_bar.py[line:272] - INFO: epoch 001:   5118 / 8233 loss=5.127, loss_v1=0, loss_v2=0, nll_loss=3.895, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=14.88, wps=283.5, ups=0.84, wpb=339.4, bsz=48, num_updates=5110, lr=2.20092e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6161
2023-08-08 19:57:40 - progress_bar.py[line:272] - INFO: epoch 001:   5128 / 8233 loss=5.15, loss_v1=0, loss_v2=0, nll_loss=3.911, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=15.04, wps=284.2, ups=0.83, wpb=341.2, bsz=48, num_updates=5120, lr=2.19898e-05, gnorm=0.128, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6173
2023-08-08 19:57:52 - progress_bar.py[line:272] - INFO: epoch 001:   5138 / 8233 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=3.912, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=15.05, wps=285.4, ups=0.84, wpb=340.7, bsz=48, num_updates=5130, lr=2.19704e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6185
2023-08-08 19:58:04 - progress_bar.py[line:272] - INFO: epoch 001:   5148 / 8233 loss=5.169, loss_v1=0, loss_v2=0, nll_loss=3.938, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=15.32, wps=280.7, ups=0.83, wpb=339, bsz=48, num_updates=5140, lr=2.1951e-05, gnorm=0.136, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6197
2023-08-08 19:58:16 - progress_bar.py[line:272] - INFO: epoch 001:   5158 / 8233 loss=5.213, loss_v1=0, loss_v2=0, nll_loss=3.99, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=15.89, wps=279.8, ups=0.83, wpb=337.4, bsz=48, num_updates=5150, lr=2.19316e-05, gnorm=0.133, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6209
2023-08-08 19:58:28 - progress_bar.py[line:272] - INFO: epoch 001:   5168 / 8233 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=3.909, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=15.02, wps=280.7, ups=0.83, wpb=337, bsz=48, num_updates=5160, lr=2.19123e-05, gnorm=0.128, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6221
2023-08-08 19:58:40 - progress_bar.py[line:272] - INFO: epoch 001:   5178 / 8233 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=3.913, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=15.06, wps=280.5, ups=0.83, wpb=339.5, bsz=48, num_updates=5170, lr=2.18929e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6233
2023-08-08 19:58:52 - progress_bar.py[line:272] - INFO: epoch 001:   5188 / 8233 loss=5.181, loss_v1=0, loss_v2=0, nll_loss=3.946, ntokens=333.9, nsentences=48, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=15.42, wps=274.3, ups=0.82, wpb=333.9, bsz=48, num_updates=5180, lr=2.18735e-05, gnorm=0.137, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=6245
2023-08-08 19:59:04 - progress_bar.py[line:272] - INFO: epoch 001:   5198 / 8233 loss=5.187, loss_v1=0, loss_v2=0, nll_loss=3.957, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=15.53, wps=281.1, ups=0.83, wpb=338.6, bsz=48, num_updates=5190, lr=2.18541e-05, gnorm=0.132, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=6257
2023-08-08 19:59:16 - progress_bar.py[line:272] - INFO: epoch 001:   5208 / 8233 loss=5.184, loss_v1=0, loss_v2=0, nll_loss=3.964, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=15.6, wps=285.4, ups=0.84, wpb=340.9, bsz=48, num_updates=5200, lr=2.18347e-05, gnorm=0.137, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=6269
2023-08-08 19:59:28 - progress_bar.py[line:272] - INFO: epoch 001:   5218 / 8233 loss=5.121, loss_v1=0, loss_v2=0, nll_loss=3.887, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=14.8, wps=280.1, ups=0.83, wpb=337.4, bsz=48, num_updates=5210, lr=2.18154e-05, gnorm=0.129, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=6281
2023-08-08 19:59:40 - progress_bar.py[line:272] - INFO: epoch 001:   5228 / 8233 loss=5.108, loss_v1=0, loss_v2=0, nll_loss=3.876, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=14.68, wps=284.6, ups=0.84, wpb=340.2, bsz=48, num_updates=5220, lr=2.1796e-05, gnorm=0.133, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=6293
2023-08-08 19:59:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 19:59:54 - progress_bar.py[line:272] - INFO: epoch 001:   5239 / 8233 loss=5.107, loss_v1=0, loss_v2=0, nll_loss=3.868, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=14.6, wps=256.1, ups=0.76, wpb=338.7, bsz=48, num_updates=5230, lr=2.17766e-05, gnorm=0.131, clip=0, loss_scale=64, train_wall=13, gb_free=14.5, wall=6306
2023-08-08 20:00:06 - progress_bar.py[line:272] - INFO: epoch 001:   5249 / 8233 loss=5.13, loss_v1=0, loss_v2=0, nll_loss=3.894, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=14.87, wps=283.2, ups=0.83, wpb=340.6, bsz=48, num_updates=5240, lr=2.17572e-05, gnorm=0.135, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6318
2023-08-08 20:00:18 - progress_bar.py[line:272] - INFO: epoch 001:   5259 / 8233 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=3.879, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=14.71, wps=281.5, ups=0.83, wpb=337.3, bsz=48, num_updates=5250, lr=2.17378e-05, gnorm=0.129, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6330
2023-08-08 20:00:30 - progress_bar.py[line:272] - INFO: epoch 001:   5269 / 8233 loss=5.172, loss_v1=0, loss_v2=0, nll_loss=3.947, ntokens=333.6, nsentences=48, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=15.42, wps=273.9, ups=0.82, wpb=333.6, bsz=48, num_updates=5260, lr=2.17185e-05, gnorm=0.133, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6343
2023-08-08 20:00:42 - progress_bar.py[line:272] - INFO: epoch 001:   5279 / 8233 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=3.886, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=14.78, wps=278.8, ups=0.83, wpb=337.1, bsz=48, num_updates=5270, lr=2.16991e-05, gnorm=0.135, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6355
2023-08-08 20:00:54 - progress_bar.py[line:272] - INFO: epoch 001:   5289 / 8233 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=3.893, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=14.85, wps=281.1, ups=0.83, wpb=339.6, bsz=48, num_updates=5280, lr=2.16797e-05, gnorm=0.135, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6367
2023-08-08 20:01:06 - progress_bar.py[line:272] - INFO: epoch 001:   5299 / 8233 loss=5.136, loss_v1=0, loss_v2=0, nll_loss=3.895, ntokens=342.1, nsentences=48, sample_size=342.1, sample_size_v1=0, sample_size_v2=0, ppl=14.88, wps=285.5, ups=0.83, wpb=342.1, bsz=48, num_updates=5290, lr=2.16603e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6379
2023-08-08 20:01:18 - progress_bar.py[line:272] - INFO: epoch 001:   5309 / 8233 loss=5.096, loss_v1=0, loss_v2=0, nll_loss=3.853, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=14.45, wps=280.2, ups=0.83, wpb=337, bsz=48, num_updates=5300, lr=2.16409e-05, gnorm=0.13, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6391
2023-08-08 20:01:30 - progress_bar.py[line:272] - INFO: epoch 001:   5319 / 8233 loss=5.148, loss_v1=0, loss_v2=0, nll_loss=3.911, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=15.05, wps=277.1, ups=0.83, wpb=334.2, bsz=48, num_updates=5310, lr=2.16216e-05, gnorm=0.137, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6403
2023-08-08 20:01:42 - progress_bar.py[line:272] - INFO: epoch 001:   5329 / 8233 loss=5.118, loss_v1=0, loss_v2=0, nll_loss=3.884, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=14.76, wps=284.5, ups=0.84, wpb=339.6, bsz=48, num_updates=5320, lr=2.16022e-05, gnorm=0.137, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6415
2023-08-08 20:01:54 - progress_bar.py[line:272] - INFO: epoch 001:   5339 / 8233 loss=5.123, loss_v1=0, loss_v2=0, nll_loss=3.889, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=14.82, wps=277.4, ups=0.83, wpb=335.8, bsz=48, num_updates=5330, lr=2.15828e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6427
2023-08-08 20:02:06 - progress_bar.py[line:272] - INFO: epoch 001:   5349 / 8233 loss=5.112, loss_v1=0, loss_v2=0, nll_loss=3.881, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=14.74, wps=282.7, ups=0.83, wpb=338.6, bsz=48, num_updates=5340, lr=2.15634e-05, gnorm=0.128, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6439
2023-08-08 20:02:18 - progress_bar.py[line:272] - INFO: epoch 001:   5359 / 8233 loss=5.111, loss_v1=0, loss_v2=0, nll_loss=3.872, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=14.65, wps=283.2, ups=0.84, wpb=338.9, bsz=48, num_updates=5350, lr=2.1544e-05, gnorm=0.132, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6451
2023-08-08 20:02:30 - progress_bar.py[line:272] - INFO: epoch 001:   5369 / 8233 loss=5.098, loss_v1=0, loss_v2=0, nll_loss=3.854, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=14.46, wps=286, ups=0.84, wpb=341.7, bsz=48, num_updates=5360, lr=2.15246e-05, gnorm=0.135, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=6463
2023-08-08 20:02:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 20:02:43 - progress_bar.py[line:272] - INFO: epoch 001:   5380 / 8233 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=3.892, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=14.84, wps=256.4, ups=0.76, wpb=337, bsz=48, num_updates=5370, lr=2.15053e-05, gnorm=0.134, clip=0, loss_scale=32, train_wall=13, gb_free=14.5, wall=6476
2023-08-08 20:02:55 - progress_bar.py[line:272] - INFO: epoch 001:   5390 / 8233 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=3.918, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=15.11, wps=283.9, ups=0.84, wpb=339.5, bsz=48, num_updates=5380, lr=2.14859e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6488
2023-08-08 20:03:07 - progress_bar.py[line:272] - INFO: epoch 001:   5400 / 8233 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=3.838, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=14.3, wps=282.2, ups=0.83, wpb=341.3, bsz=48, num_updates=5390, lr=2.14665e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6500
2023-08-08 20:03:19 - progress_bar.py[line:272] - INFO: epoch 001:   5410 / 8233 loss=5.11, loss_v1=0, loss_v2=0, nll_loss=3.873, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=14.65, wps=282.2, ups=0.83, wpb=338.5, bsz=48, num_updates=5400, lr=2.14471e-05, gnorm=0.135, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6512
2023-08-08 20:03:31 - progress_bar.py[line:272] - INFO: epoch 001:   5420 / 8233 loss=5.117, loss_v1=0, loss_v2=0, nll_loss=3.883, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=14.75, wps=283.7, ups=0.84, wpb=339.7, bsz=48, num_updates=5410, lr=2.14277e-05, gnorm=0.135, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6524
2023-08-08 20:03:43 - progress_bar.py[line:272] - INFO: epoch 001:   5430 / 8233 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=3.842, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=14.34, wps=279.8, ups=0.83, wpb=336.5, bsz=48, num_updates=5420, lr=2.14084e-05, gnorm=0.135, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6536
2023-08-08 20:03:55 - progress_bar.py[line:272] - INFO: epoch 001:   5440 / 8233 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=3.86, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=14.52, wps=280.2, ups=0.83, wpb=338.3, bsz=48, num_updates=5430, lr=2.1389e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6548
2023-08-08 20:04:07 - progress_bar.py[line:272] - INFO: epoch 001:   5450 / 8233 loss=5.106, loss_v1=0, loss_v2=0, nll_loss=3.87, ntokens=330.7, nsentences=48, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=14.62, wps=271, ups=0.82, wpb=330.7, bsz=48, num_updates=5440, lr=2.13696e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6560
2023-08-08 20:04:19 - progress_bar.py[line:272] - INFO: epoch 001:   5460 / 8233 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=3.896, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=14.89, wps=281.6, ups=0.83, wpb=338.4, bsz=48, num_updates=5450, lr=2.13502e-05, gnorm=0.134, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6572
2023-08-08 20:04:32 - progress_bar.py[line:272] - INFO: epoch 001:   5470 / 8233 loss=5.118, loss_v1=0, loss_v2=0, nll_loss=3.875, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=14.67, wps=279.9, ups=0.83, wpb=338.1, bsz=48, num_updates=5460, lr=2.13308e-05, gnorm=0.135, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6584
2023-08-08 20:04:43 - progress_bar.py[line:272] - INFO: epoch 001:   5480 / 8233 loss=5.088, loss_v1=0, loss_v2=0, nll_loss=3.849, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=14.41, wps=284.3, ups=0.84, wpb=339.6, bsz=48, num_updates=5470, lr=2.13115e-05, gnorm=0.133, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6596
2023-08-08 20:04:56 - progress_bar.py[line:272] - INFO: epoch 001:   5490 / 8233 loss=5.097, loss_v1=0, loss_v2=0, nll_loss=3.851, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=14.43, wps=278.9, ups=0.83, wpb=337, bsz=48, num_updates=5480, lr=2.12921e-05, gnorm=0.134, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6608
2023-08-08 20:05:08 - progress_bar.py[line:272] - INFO: epoch 001:   5500 / 8233 loss=5.138, loss_v1=0, loss_v2=0, nll_loss=3.902, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=14.95, wps=283.8, ups=0.84, wpb=339.6, bsz=48, num_updates=5490, lr=2.12727e-05, gnorm=0.133, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6620
2023-08-08 20:05:20 - progress_bar.py[line:272] - INFO: epoch 001:   5510 / 8233 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=3.814, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=14.06, wps=280.1, ups=0.83, wpb=338.1, bsz=48, num_updates=5500, lr=2.12533e-05, gnorm=0.134, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6632
2023-08-08 20:05:32 - progress_bar.py[line:272] - INFO: epoch 001:   5520 / 8233 loss=5.053, loss_v1=0, loss_v2=0, nll_loss=3.8, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=13.93, wps=282.6, ups=0.83, wpb=339.9, bsz=48, num_updates=5510, lr=2.12339e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6645
2023-08-08 20:05:44 - progress_bar.py[line:272] - INFO: epoch 001:   5530 / 8233 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=3.799, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=13.92, wps=284.9, ups=0.84, wpb=340.5, bsz=48, num_updates=5520, lr=2.12145e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6656
2023-08-08 20:05:56 - progress_bar.py[line:272] - INFO: epoch 001:   5540 / 8233 loss=5.08, loss_v1=0, loss_v2=0, nll_loss=3.836, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=14.28, wps=283.4, ups=0.83, wpb=339.6, bsz=48, num_updates=5530, lr=2.11952e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6668
2023-08-08 20:06:08 - progress_bar.py[line:272] - INFO: epoch 001:   5550 / 8233 loss=5.113, loss_v1=0, loss_v2=0, nll_loss=3.866, ntokens=330.4, nsentences=48, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=14.58, wps=271.3, ups=0.82, wpb=330.4, bsz=48, num_updates=5540, lr=2.11758e-05, gnorm=0.14, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6681
2023-08-08 20:06:20 - progress_bar.py[line:272] - INFO: epoch 001:   5560 / 8233 loss=5.044, loss_v1=0, loss_v2=0, nll_loss=3.796, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=13.89, wps=282.4, ups=0.83, wpb=339.7, bsz=48, num_updates=5550, lr=2.11564e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6693
2023-08-08 20:06:32 - progress_bar.py[line:272] - INFO: epoch 001:   5570 / 8233 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=3.832, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=14.25, wps=278.7, ups=0.83, wpb=336.1, bsz=48, num_updates=5560, lr=2.1137e-05, gnorm=0.132, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6705
2023-08-08 20:06:44 - progress_bar.py[line:272] - INFO: epoch 001:   5580 / 8233 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=3.801, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=13.94, wps=286.3, ups=0.84, wpb=341.3, bsz=48, num_updates=5570, lr=2.11176e-05, gnorm=0.13, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6717
2023-08-08 20:06:56 - progress_bar.py[line:272] - INFO: epoch 001:   5590 / 8233 loss=5.063, loss_v1=0, loss_v2=0, nll_loss=3.81, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=14.02, wps=284.9, ups=0.83, wpb=341.3, bsz=48, num_updates=5580, lr=2.10983e-05, gnorm=0.13, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6729
2023-08-08 20:07:08 - progress_bar.py[line:272] - INFO: epoch 001:   5600 / 8233 loss=5.061, loss_v1=0, loss_v2=0, nll_loss=3.815, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=14.07, wps=284.1, ups=0.83, wpb=341, bsz=48, num_updates=5590, lr=2.10789e-05, gnorm=0.133, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6741
2023-08-08 20:07:20 - progress_bar.py[line:272] - INFO: epoch 001:   5610 / 8233 loss=5.075, loss_v1=0, loss_v2=0, nll_loss=3.825, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=14.17, wps=277.2, ups=0.83, wpb=335.4, bsz=48, num_updates=5600, lr=2.10595e-05, gnorm=0.135, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6753
2023-08-08 20:07:32 - progress_bar.py[line:272] - INFO: epoch 001:   5620 / 8233 loss=5.087, loss_v1=0, loss_v2=0, nll_loss=3.839, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=14.31, wps=284.1, ups=0.84, wpb=339.6, bsz=48, num_updates=5610, lr=2.10401e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6765
2023-08-08 20:07:44 - progress_bar.py[line:272] - INFO: epoch 001:   5630 / 8233 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=3.816, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=14.09, wps=280.9, ups=0.83, wpb=337.6, bsz=48, num_updates=5620, lr=2.10207e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6777
2023-08-08 20:07:56 - progress_bar.py[line:272] - INFO: epoch 001:   5640 / 8233 loss=5.057, loss_v1=0, loss_v2=0, nll_loss=3.804, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=13.97, wps=279.5, ups=0.83, wpb=335.9, bsz=48, num_updates=5630, lr=2.10014e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6789
2023-08-08 20:08:08 - progress_bar.py[line:272] - INFO: epoch 001:   5650 / 8233 loss=5.133, loss_v1=0, loss_v2=0, nll_loss=3.897, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=14.9, wps=282.9, ups=0.83, wpb=339.3, bsz=48, num_updates=5640, lr=2.0982e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6801
2023-08-08 20:08:20 - progress_bar.py[line:272] - INFO: epoch 001:   5660 / 8233 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=3.809, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=14.02, wps=281.1, ups=0.84, wpb=336.3, bsz=48, num_updates=5650, lr=2.09626e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6813
2023-08-08 20:08:32 - progress_bar.py[line:272] - INFO: epoch 001:   5670 / 8233 loss=5.058, loss_v1=0, loss_v2=0, nll_loss=3.81, ntokens=334.9, nsentences=48, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=14.02, wps=278.3, ups=0.83, wpb=334.9, bsz=48, num_updates=5660, lr=2.09432e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6825
2023-08-08 20:08:44 - progress_bar.py[line:272] - INFO: epoch 001:   5680 / 8233 loss=5.061, loss_v1=0, loss_v2=0, nll_loss=3.808, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=14.01, wps=282.8, ups=0.83, wpb=338.8, bsz=48, num_updates=5670, lr=2.09238e-05, gnorm=0.133, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6837
2023-08-08 20:08:56 - progress_bar.py[line:272] - INFO: epoch 001:   5690 / 8233 loss=5.078, loss_v1=0, loss_v2=0, nll_loss=3.829, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=14.21, wps=278.5, ups=0.83, wpb=336.1, bsz=48, num_updates=5680, lr=2.09045e-05, gnorm=0.132, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6849
2023-08-08 20:09:08 - progress_bar.py[line:272] - INFO: epoch 001:   5700 / 8233 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=3.8, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=13.93, wps=281.7, ups=0.83, wpb=337.8, bsz=48, num_updates=5690, lr=2.08851e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6861
2023-08-08 20:09:20 - progress_bar.py[line:272] - INFO: epoch 001:   5710 / 8233 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=3.84, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=14.32, wps=281.2, ups=0.83, wpb=338.8, bsz=48, num_updates=5700, lr=2.08657e-05, gnorm=0.137, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6873
2023-08-08 20:09:32 - progress_bar.py[line:272] - INFO: epoch 001:   5720 / 8233 loss=5.041, loss_v1=0, loss_v2=0, nll_loss=3.786, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=13.8, wps=281.4, ups=0.83, wpb=337.7, bsz=48, num_updates=5710, lr=2.08463e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6885
2023-08-08 20:09:44 - progress_bar.py[line:272] - INFO: epoch 001:   5730 / 8233 loss=5.057, loss_v1=0, loss_v2=0, nll_loss=3.808, ntokens=333.9, nsentences=48, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=14.01, wps=278, ups=0.83, wpb=333.9, bsz=48, num_updates=5720, lr=2.08269e-05, gnorm=0.133, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6897
2023-08-08 20:09:56 - progress_bar.py[line:272] - INFO: epoch 001:   5740 / 8233 loss=5.061, loss_v1=0, loss_v2=0, nll_loss=3.808, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=14.01, wps=284.2, ups=0.84, wpb=339.1, bsz=48, num_updates=5730, lr=2.08075e-05, gnorm=0.132, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6909
2023-08-08 20:10:08 - progress_bar.py[line:272] - INFO: epoch 001:   5750 / 8233 loss=5.007, loss_v1=0, loss_v2=0, nll_loss=3.747, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=13.43, wps=284.2, ups=0.84, wpb=340.1, bsz=48, num_updates=5740, lr=2.07882e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6921
2023-08-08 20:10:20 - progress_bar.py[line:272] - INFO: epoch 001:   5760 / 8233 loss=5.099, loss_v1=0, loss_v2=0, nll_loss=3.858, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=14.5, wps=280.9, ups=0.83, wpb=336.8, bsz=48, num_updates=5750, lr=2.07688e-05, gnorm=0.13, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6933
2023-08-08 20:10:32 - progress_bar.py[line:272] - INFO: epoch 001:   5770 / 8233 loss=5.037, loss_v1=0, loss_v2=0, nll_loss=3.786, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=13.8, wps=280.7, ups=0.83, wpb=338.6, bsz=48, num_updates=5760, lr=2.07494e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6945
2023-08-08 20:10:44 - progress_bar.py[line:272] - INFO: epoch 001:   5780 / 8233 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=3.798, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=13.91, wps=283.3, ups=0.84, wpb=339.1, bsz=48, num_updates=5770, lr=2.073e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6957
2023-08-08 20:10:56 - progress_bar.py[line:272] - INFO: epoch 001:   5790 / 8233 loss=5.018, loss_v1=0, loss_v2=0, nll_loss=3.76, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=13.55, wps=282.4, ups=0.83, wpb=339.4, bsz=48, num_updates=5780, lr=2.07106e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6969
2023-08-08 20:11:08 - progress_bar.py[line:272] - INFO: epoch 001:   5800 / 8233 loss=5.037, loss_v1=0, loss_v2=0, nll_loss=3.786, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=13.79, wps=282.6, ups=0.84, wpb=337.7, bsz=48, num_updates=5790, lr=2.06913e-05, gnorm=0.132, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6981
2023-08-08 20:11:20 - progress_bar.py[line:272] - INFO: epoch 001:   5810 / 8233 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=3.792, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=13.86, wps=283.7, ups=0.84, wpb=339.6, bsz=48, num_updates=5800, lr=2.06719e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=6993
2023-08-08 20:11:32 - progress_bar.py[line:272] - INFO: epoch 001:   5820 / 8233 loss=4.998, loss_v1=0, loss_v2=0, nll_loss=3.736, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=13.32, wps=277.9, ups=0.83, wpb=335.5, bsz=48, num_updates=5810, lr=2.06525e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7005
2023-08-08 20:11:44 - progress_bar.py[line:272] - INFO: epoch 001:   5830 / 8233 loss=5.032, loss_v1=0, loss_v2=0, nll_loss=3.779, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=13.73, wps=284.7, ups=0.84, wpb=340.7, bsz=48, num_updates=5820, lr=2.06331e-05, gnorm=0.136, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7017
2023-08-08 20:11:56 - progress_bar.py[line:272] - INFO: epoch 001:   5840 / 8233 loss=5.033, loss_v1=0, loss_v2=0, nll_loss=3.782, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=13.75, wps=282.7, ups=0.83, wpb=339.7, bsz=48, num_updates=5830, lr=2.06137e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7029
2023-08-08 20:12:08 - progress_bar.py[line:272] - INFO: epoch 001:   5850 / 8233 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=3.815, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=14.07, wps=280.4, ups=0.83, wpb=337.4, bsz=48, num_updates=5840, lr=2.05944e-05, gnorm=0.134, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7041
2023-08-08 20:12:20 - progress_bar.py[line:272] - INFO: epoch 001:   5860 / 8233 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=3.797, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=13.9, wps=282.8, ups=0.84, wpb=338.6, bsz=48, num_updates=5850, lr=2.0575e-05, gnorm=0.13, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7053
2023-08-08 20:12:32 - progress_bar.py[line:272] - INFO: epoch 001:   5870 / 8233 loss=4.997, loss_v1=0, loss_v2=0, nll_loss=3.738, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=13.34, wps=285.1, ups=0.84, wpb=341.2, bsz=48, num_updates=5860, lr=2.05556e-05, gnorm=0.124, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7065
2023-08-08 20:12:44 - progress_bar.py[line:272] - INFO: epoch 001:   5880 / 8233 loss=5.029, loss_v1=0, loss_v2=0, nll_loss=3.776, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=13.7, wps=284, ups=0.84, wpb=339.9, bsz=48, num_updates=5870, lr=2.05362e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7077
2023-08-08 20:12:56 - progress_bar.py[line:272] - INFO: epoch 001:   5890 / 8233 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=3.795, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=13.88, wps=279, ups=0.83, wpb=336.9, bsz=48, num_updates=5880, lr=2.05168e-05, gnorm=0.132, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7089
2023-08-08 20:13:08 - progress_bar.py[line:272] - INFO: epoch 001:   5900 / 8233 loss=5.028, loss_v1=0, loss_v2=0, nll_loss=3.778, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=13.71, wps=281.8, ups=0.83, wpb=338.3, bsz=48, num_updates=5890, lr=2.04974e-05, gnorm=0.132, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7101
2023-08-08 20:13:20 - progress_bar.py[line:272] - INFO: epoch 001:   5910 / 8233 loss=5.005, loss_v1=0, loss_v2=0, nll_loss=3.743, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=13.39, wps=280.6, ups=0.83, wpb=338.5, bsz=48, num_updates=5900, lr=2.04781e-05, gnorm=0.13, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7113
2023-08-08 20:13:32 - progress_bar.py[line:272] - INFO: epoch 001:   5920 / 8233 loss=5.056, loss_v1=0, loss_v2=0, nll_loss=3.805, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=13.97, wps=278.7, ups=0.83, wpb=335.4, bsz=48, num_updates=5910, lr=2.04587e-05, gnorm=0.128, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7125
2023-08-08 20:13:44 - progress_bar.py[line:272] - INFO: epoch 001:   5930 / 8233 loss=5.017, loss_v1=0, loss_v2=0, nll_loss=3.76, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=13.54, wps=282.1, ups=0.84, wpb=337.2, bsz=48, num_updates=5920, lr=2.04393e-05, gnorm=0.131, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7137
2023-08-08 20:13:56 - progress_bar.py[line:272] - INFO: epoch 001:   5940 / 8233 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=3.777, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=13.71, wps=276.5, ups=0.83, wpb=334.5, bsz=48, num_updates=5930, lr=2.04199e-05, gnorm=0.13, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7149
2023-08-08 20:14:08 - progress_bar.py[line:272] - INFO: epoch 001:   5950 / 8233 loss=4.988, loss_v1=0, loss_v2=0, nll_loss=3.728, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=13.25, wps=284.3, ups=0.83, wpb=341.1, bsz=48, num_updates=5940, lr=2.04005e-05, gnorm=0.123, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7161
2023-08-08 20:14:20 - progress_bar.py[line:272] - INFO: epoch 001:   5960 / 8233 loss=5.005, loss_v1=0, loss_v2=0, nll_loss=3.754, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=13.49, wps=282.4, ups=0.83, wpb=338.7, bsz=48, num_updates=5950, lr=2.03812e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7173
2023-08-08 20:14:32 - progress_bar.py[line:272] - INFO: epoch 001:   5970 / 8233 loss=4.996, loss_v1=0, loss_v2=0, nll_loss=3.735, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=13.32, wps=286.7, ups=0.84, wpb=341.1, bsz=48, num_updates=5960, lr=2.03618e-05, gnorm=0.126, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7185
2023-08-08 20:14:44 - progress_bar.py[line:272] - INFO: epoch 001:   5980 / 8233 loss=5.016, loss_v1=0, loss_v2=0, nll_loss=3.756, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=13.51, wps=278, ups=0.83, wpb=335.1, bsz=48, num_updates=5970, lr=2.03424e-05, gnorm=0.13, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7197
2023-08-08 20:14:56 - progress_bar.py[line:272] - INFO: epoch 001:   5990 / 8233 loss=5.002, loss_v1=0, loss_v2=0, nll_loss=3.741, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=13.37, wps=284, ups=0.84, wpb=339.9, bsz=48, num_updates=5980, lr=2.0323e-05, gnorm=0.128, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7209
2023-08-08 20:15:08 - progress_bar.py[line:272] - INFO: epoch 001:   6000 / 8233 loss=5.016, loss_v1=0, loss_v2=0, nll_loss=3.758, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=13.53, wps=283.5, ups=0.83, wpb=340, bsz=48, num_updates=5990, lr=2.03036e-05, gnorm=0.134, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7221
2023-08-08 20:15:20 - progress_bar.py[line:272] - INFO: epoch 001:   6010 / 8233 loss=5.019, loss_v1=0, loss_v2=0, nll_loss=3.759, ntokens=342.1, nsentences=48, sample_size=342.1, sample_size_v1=0, sample_size_v2=0, ppl=13.53, wps=286.2, ups=0.84, wpb=342.1, bsz=48, num_updates=6000, lr=2.02843e-05, gnorm=0.126, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7233
2023-08-08 20:15:32 - progress_bar.py[line:272] - INFO: epoch 001:   6020 / 8233 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=3.705, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=13.04, wps=281.9, ups=0.83, wpb=338.1, bsz=48, num_updates=6010, lr=2.02649e-05, gnorm=0.123, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7245
2023-08-08 20:15:44 - progress_bar.py[line:272] - INFO: epoch 001:   6030 / 8233 loss=5.014, loss_v1=0, loss_v2=0, nll_loss=3.758, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=13.53, wps=285, ups=0.84, wpb=339.6, bsz=48, num_updates=6020, lr=2.02455e-05, gnorm=0.128, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7257
2023-08-08 20:15:56 - progress_bar.py[line:272] - INFO: epoch 001:   6040 / 8233 loss=5.05, loss_v1=0, loss_v2=0, nll_loss=3.797, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=13.9, wps=281.6, ups=0.83, wpb=338.7, bsz=48, num_updates=6030, lr=2.02261e-05, gnorm=0.131, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7269
2023-08-08 20:15:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 20:16:09 - progress_bar.py[line:272] - INFO: epoch 001:   6051 / 8233 loss=5.016, loss_v1=0, loss_v2=0, nll_loss=3.757, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=13.52, wps=258.8, ups=0.76, wpb=340.3, bsz=48, num_updates=6040, lr=2.02067e-05, gnorm=0.132, clip=0, loss_scale=32, train_wall=13, gb_free=14.5, wall=7282
2023-08-08 20:16:21 - progress_bar.py[line:272] - INFO: epoch 001:   6061 / 8233 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=3.736, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=13.32, wps=279.4, ups=0.83, wpb=336.1, bsz=48, num_updates=6050, lr=2.01874e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7294
2023-08-08 20:16:33 - progress_bar.py[line:272] - INFO: epoch 001:   6071 / 8233 loss=5.014, loss_v1=0, loss_v2=0, nll_loss=3.758, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=13.53, wps=276.3, ups=0.82, wpb=335.6, bsz=48, num_updates=6060, lr=2.0168e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7306
2023-08-08 20:16:45 - progress_bar.py[line:272] - INFO: epoch 001:   6081 / 8233 loss=4.957, loss_v1=0, loss_v2=0, nll_loss=3.687, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=12.88, wps=279.6, ups=0.83, wpb=335.8, bsz=48, num_updates=6070, lr=2.01486e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7318
2023-08-08 20:16:57 - progress_bar.py[line:272] - INFO: epoch 001:   6091 / 8233 loss=4.956, loss_v1=0, loss_v2=0, nll_loss=3.692, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=12.93, wps=285.8, ups=0.84, wpb=340.3, bsz=48, num_updates=6080, lr=2.01292e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7330
2023-08-08 20:17:09 - progress_bar.py[line:272] - INFO: epoch 001:   6101 / 8233 loss=5.007, loss_v1=0, loss_v2=0, nll_loss=3.751, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=13.47, wps=284.2, ups=0.83, wpb=340.7, bsz=48, num_updates=6090, lr=2.01098e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7342
2023-08-08 20:17:21 - progress_bar.py[line:272] - INFO: epoch 001:   6111 / 8233 loss=5.037, loss_v1=0, loss_v2=0, nll_loss=3.784, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=13.78, wps=280.9, ups=0.83, wpb=338.6, bsz=48, num_updates=6100, lr=2.00904e-05, gnorm=0.137, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7354
2023-08-08 20:17:33 - progress_bar.py[line:272] - INFO: epoch 001:   6121 / 8233 loss=5.025, loss_v1=0, loss_v2=0, nll_loss=3.776, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=13.7, wps=279.7, ups=0.83, wpb=337.9, bsz=48, num_updates=6110, lr=2.00711e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7366
2023-08-08 20:17:45 - progress_bar.py[line:272] - INFO: epoch 001:   6131 / 8233 loss=4.984, loss_v1=0, loss_v2=0, nll_loss=3.727, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=13.24, wps=281.2, ups=0.83, wpb=339.3, bsz=48, num_updates=6120, lr=2.00517e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7378
2023-08-08 20:17:57 - progress_bar.py[line:272] - INFO: epoch 001:   6141 / 8233 loss=5, loss_v1=0, loss_v2=0, nll_loss=3.741, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=13.37, wps=279.6, ups=0.83, wpb=336.7, bsz=48, num_updates=6130, lr=2.00323e-05, gnorm=0.13, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7390
2023-08-08 20:18:09 - progress_bar.py[line:272] - INFO: epoch 001:   6151 / 8233 loss=4.949, loss_v1=0, loss_v2=0, nll_loss=3.68, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=12.82, wps=279.2, ups=0.83, wpb=335.8, bsz=48, num_updates=6140, lr=2.00129e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7402
2023-08-08 20:18:21 - progress_bar.py[line:272] - INFO: epoch 001:   6161 / 8233 loss=4.962, loss_v1=0, loss_v2=0, nll_loss=3.7, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=12.99, wps=285.4, ups=0.84, wpb=340.5, bsz=48, num_updates=6150, lr=1.99935e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7414
2023-08-08 20:18:33 - progress_bar.py[line:272] - INFO: epoch 001:   6171 / 8233 loss=5.038, loss_v1=0, loss_v2=0, nll_loss=3.791, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=13.84, wps=281.1, ups=0.83, wpb=338.2, bsz=48, num_updates=6160, lr=1.99742e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7426
2023-08-08 20:18:45 - progress_bar.py[line:272] - INFO: epoch 001:   6181 / 8233 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=3.747, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=13.42, wps=285.8, ups=0.84, wpb=341.3, bsz=48, num_updates=6170, lr=1.99548e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7438
2023-08-08 20:18:57 - progress_bar.py[line:272] - INFO: epoch 001:   6191 / 8233 loss=4.993, loss_v1=0, loss_v2=0, nll_loss=3.731, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=13.28, wps=280.9, ups=0.83, wpb=337.8, bsz=48, num_updates=6180, lr=1.99354e-05, gnorm=0.13, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7450
2023-08-08 20:19:09 - progress_bar.py[line:272] - INFO: epoch 001:   6201 / 8233 loss=4.947, loss_v1=0, loss_v2=0, nll_loss=3.679, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=12.81, wps=279.9, ups=0.83, wpb=337.2, bsz=48, num_updates=6190, lr=1.9916e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7462
2023-08-08 20:19:21 - progress_bar.py[line:272] - INFO: epoch 001:   6211 / 8233 loss=5.001, loss_v1=0, loss_v2=0, nll_loss=3.735, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=13.32, wps=282.5, ups=0.83, wpb=338.4, bsz=48, num_updates=6200, lr=1.98966e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7474
2023-08-08 20:19:33 - progress_bar.py[line:272] - INFO: epoch 001:   6221 / 8233 loss=4.976, loss_v1=0, loss_v2=0, nll_loss=3.716, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=13.14, wps=283.2, ups=0.83, wpb=339.2, bsz=48, num_updates=6210, lr=1.98773e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7486
2023-08-08 20:19:45 - progress_bar.py[line:272] - INFO: epoch 001:   6231 / 8233 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=3.736, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=13.33, wps=279.3, ups=0.83, wpb=336.6, bsz=48, num_updates=6220, lr=1.98579e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7498
2023-08-08 20:19:58 - progress_bar.py[line:272] - INFO: epoch 001:   6241 / 8233 loss=4.951, loss_v1=0, loss_v2=0, nll_loss=3.688, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=12.89, wps=282, ups=0.83, wpb=338.7, bsz=48, num_updates=6230, lr=1.98385e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7510
2023-08-08 20:20:10 - progress_bar.py[line:272] - INFO: epoch 001:   6251 / 8233 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=3.729, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=13.26, wps=283.3, ups=0.83, wpb=340.5, bsz=48, num_updates=6240, lr=1.98191e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7522
2023-08-08 20:20:22 - progress_bar.py[line:272] - INFO: epoch 001:   6261 / 8233 loss=4.948, loss_v1=0, loss_v2=0, nll_loss=3.679, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=12.81, wps=284.7, ups=0.84, wpb=340.9, bsz=48, num_updates=6250, lr=1.97997e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7534
2023-08-08 20:20:33 - progress_bar.py[line:272] - INFO: epoch 001:   6271 / 8233 loss=4.979, loss_v1=0, loss_v2=0, nll_loss=3.721, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=13.19, wps=281.7, ups=0.84, wpb=337.2, bsz=48, num_updates=6260, lr=1.97803e-05, gnorm=0.132, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7546
2023-08-08 20:20:46 - progress_bar.py[line:272] - INFO: epoch 001:   6281 / 8233 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=3.711, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=13.09, wps=279.2, ups=0.83, wpb=337.2, bsz=48, num_updates=6270, lr=1.9761e-05, gnorm=0.13, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7558
2023-08-08 20:20:58 - progress_bar.py[line:272] - INFO: epoch 001:   6291 / 8233 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=3.763, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=13.58, wps=283.4, ups=0.83, wpb=339.7, bsz=48, num_updates=6280, lr=1.97416e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7570
2023-08-08 20:21:10 - progress_bar.py[line:272] - INFO: epoch 001:   6301 / 8233 loss=4.947, loss_v1=0, loss_v2=0, nll_loss=3.691, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=12.92, wps=284.9, ups=0.84, wpb=340.7, bsz=48, num_updates=6290, lr=1.97222e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7582
2023-08-08 20:21:21 - progress_bar.py[line:272] - INFO: epoch 001:   6311 / 8233 loss=4.938, loss_v1=0, loss_v2=0, nll_loss=3.673, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=12.75, wps=285.4, ups=0.84, wpb=341, bsz=48, num_updates=6300, lr=1.97028e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7594
2023-08-08 20:21:34 - progress_bar.py[line:272] - INFO: epoch 001:   6321 / 8233 loss=4.969, loss_v1=0, loss_v2=0, nll_loss=3.706, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=13.05, wps=281.6, ups=0.83, wpb=339.6, bsz=48, num_updates=6310, lr=1.96834e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7606
2023-08-08 20:21:46 - progress_bar.py[line:272] - INFO: epoch 001:   6331 / 8233 loss=4.988, loss_v1=0, loss_v2=0, nll_loss=3.724, ntokens=332.6, nsentences=48, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=13.22, wps=273.8, ups=0.82, wpb=332.6, bsz=48, num_updates=6320, lr=1.96641e-05, gnorm=0.134, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7619
2023-08-08 20:21:58 - progress_bar.py[line:272] - INFO: epoch 001:   6341 / 8233 loss=4.978, loss_v1=0, loss_v2=0, nll_loss=3.713, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=13.11, wps=281.4, ups=0.83, wpb=337.9, bsz=48, num_updates=6330, lr=1.96447e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7631
2023-08-08 20:22:10 - progress_bar.py[line:272] - INFO: epoch 001:   6351 / 8233 loss=5.001, loss_v1=0, loss_v2=0, nll_loss=3.737, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=13.33, wps=279.8, ups=0.83, wpb=337.3, bsz=48, num_updates=6340, lr=1.96253e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7643
2023-08-08 20:22:22 - progress_bar.py[line:272] - INFO: epoch 001:   6361 / 8233 loss=4.918, loss_v1=0, loss_v2=0, nll_loss=3.648, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=12.54, wps=281.1, ups=0.83, wpb=337.8, bsz=48, num_updates=6350, lr=1.96059e-05, gnorm=0.133, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7655
2023-08-08 20:22:34 - progress_bar.py[line:272] - INFO: epoch 001:   6371 / 8233 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=3.756, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=13.51, wps=284.6, ups=0.84, wpb=340.6, bsz=48, num_updates=6360, lr=1.95865e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7667
2023-08-08 20:22:46 - progress_bar.py[line:272] - INFO: epoch 001:   6381 / 8233 loss=4.919, loss_v1=0, loss_v2=0, nll_loss=3.647, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=12.53, wps=281.2, ups=0.83, wpb=337.5, bsz=48, num_updates=6370, lr=1.95672e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7679
2023-08-08 20:22:58 - progress_bar.py[line:272] - INFO: epoch 001:   6391 / 8233 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=3.722, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=13.2, wps=276.9, ups=0.83, wpb=334.5, bsz=48, num_updates=6380, lr=1.95478e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7691
2023-08-08 20:23:10 - progress_bar.py[line:272] - INFO: epoch 001:   6401 / 8233 loss=4.932, loss_v1=0, loss_v2=0, nll_loss=3.661, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=12.65, wps=286.5, ups=0.84, wpb=342.3, bsz=48, num_updates=6390, lr=1.95284e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7703
2023-08-08 20:23:22 - progress_bar.py[line:272] - INFO: epoch 001:   6411 / 8233 loss=4.967, loss_v1=0, loss_v2=0, nll_loss=3.707, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=13.06, wps=283.1, ups=0.83, wpb=339.6, bsz=48, num_updates=6400, lr=1.9509e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7715
2023-08-08 20:23:34 - progress_bar.py[line:272] - INFO: epoch 001:   6421 / 8233 loss=4.934, loss_v1=0, loss_v2=0, nll_loss=3.666, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=12.69, wps=281.5, ups=0.83, wpb=337.8, bsz=48, num_updates=6410, lr=1.94896e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7727
2023-08-08 20:23:46 - progress_bar.py[line:272] - INFO: epoch 001:   6431 / 8233 loss=4.926, loss_v1=0, loss_v2=0, nll_loss=3.668, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=12.71, wps=280.5, ups=0.84, wpb=335.8, bsz=48, num_updates=6420, lr=1.94703e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7739
2023-08-08 20:23:58 - progress_bar.py[line:272] - INFO: epoch 001:   6441 / 8233 loss=4.98, loss_v1=0, loss_v2=0, nll_loss=3.722, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=13.19, wps=281.3, ups=0.83, wpb=337.6, bsz=48, num_updates=6430, lr=1.94509e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7751
2023-08-08 20:24:10 - progress_bar.py[line:272] - INFO: epoch 001:   6451 / 8233 loss=4.993, loss_v1=0, loss_v2=0, nll_loss=3.739, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=13.35, wps=280.9, ups=0.83, wpb=338.9, bsz=48, num_updates=6440, lr=1.94315e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7763
2023-08-08 20:24:22 - progress_bar.py[line:272] - INFO: epoch 001:   6461 / 8233 loss=4.919, loss_v1=0, loss_v2=0, nll_loss=3.65, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=12.55, wps=281.4, ups=0.83, wpb=338.4, bsz=48, num_updates=6450, lr=1.94121e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7775
2023-08-08 20:24:34 - progress_bar.py[line:272] - INFO: epoch 001:   6471 / 8233 loss=4.964, loss_v1=0, loss_v2=0, nll_loss=3.704, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=13.03, wps=279.6, ups=0.83, wpb=336.4, bsz=48, num_updates=6460, lr=1.93927e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7787
2023-08-08 20:24:46 - progress_bar.py[line:272] - INFO: epoch 001:   6481 / 8233 loss=5.02, loss_v1=0, loss_v2=0, nll_loss=3.762, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=13.57, wps=280.8, ups=0.83, wpb=337.9, bsz=48, num_updates=6470, lr=1.93733e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7799
2023-08-08 20:24:58 - progress_bar.py[line:272] - INFO: epoch 001:   6491 / 8233 loss=5.006, loss_v1=0, loss_v2=0, nll_loss=3.75, ntokens=341.8, nsentences=48, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=13.46, wps=284.3, ups=0.83, wpb=341.8, bsz=48, num_updates=6480, lr=1.9354e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7811
2023-08-08 20:25:10 - progress_bar.py[line:272] - INFO: epoch 001:   6501 / 8233 loss=4.954, loss_v1=0, loss_v2=0, nll_loss=3.693, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=12.93, wps=284.9, ups=0.83, wpb=341.4, bsz=48, num_updates=6490, lr=1.93346e-05, gnorm=0.129, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7823
2023-08-08 20:25:22 - progress_bar.py[line:272] - INFO: epoch 001:   6511 / 8233 loss=4.969, loss_v1=0, loss_v2=0, nll_loss=3.714, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=13.13, wps=279.4, ups=0.83, wpb=336.2, bsz=48, num_updates=6500, lr=1.93152e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7835
2023-08-08 20:25:34 - progress_bar.py[line:272] - INFO: epoch 001:   6521 / 8233 loss=4.928, loss_v1=0, loss_v2=0, nll_loss=3.659, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=12.63, wps=284.2, ups=0.83, wpb=341.4, bsz=48, num_updates=6510, lr=1.92958e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7847
2023-08-08 20:25:46 - progress_bar.py[line:272] - INFO: epoch 001:   6531 / 8233 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=3.738, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=13.34, wps=279.7, ups=0.83, wpb=336.4, bsz=48, num_updates=6520, lr=1.92764e-05, gnorm=0.124, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7859
2023-08-08 20:25:58 - progress_bar.py[line:272] - INFO: epoch 001:   6541 / 8233 loss=4.928, loss_v1=0, loss_v2=0, nll_loss=3.656, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=12.61, wps=283.9, ups=0.84, wpb=339.3, bsz=48, num_updates=6530, lr=1.92571e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7871
2023-08-08 20:26:10 - progress_bar.py[line:272] - INFO: epoch 001:   6551 / 8233 loss=4.938, loss_v1=0, loss_v2=0, nll_loss=3.669, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=12.72, wps=284.9, ups=0.84, wpb=339.6, bsz=48, num_updates=6540, lr=1.92377e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=7883
2023-08-08 20:26:22 - progress_bar.py[line:272] - INFO: epoch 001:   6561 / 8233 loss=4.933, loss_v1=0, loss_v2=0, nll_loss=3.671, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=12.74, wps=282.3, ups=0.83, wpb=338.2, bsz=48, num_updates=6550, lr=1.92183e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7895
2023-08-08 20:26:34 - progress_bar.py[line:272] - INFO: epoch 001:   6571 / 8233 loss=4.942, loss_v1=0, loss_v2=0, nll_loss=3.676, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=12.79, wps=277.6, ups=0.83, wpb=335.1, bsz=48, num_updates=6560, lr=1.91989e-05, gnorm=0.127, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7907
2023-08-08 20:26:46 - progress_bar.py[line:272] - INFO: epoch 001:   6581 / 8233 loss=4.942, loss_v1=0, loss_v2=0, nll_loss=3.683, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=12.84, wps=280.8, ups=0.83, wpb=338.3, bsz=48, num_updates=6570, lr=1.91795e-05, gnorm=0.127, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7919
2023-08-08 20:26:58 - progress_bar.py[line:272] - INFO: epoch 001:   6591 / 8233 loss=4.98, loss_v1=0, loss_v2=0, nll_loss=3.716, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=13.14, wps=278.2, ups=0.83, wpb=337.2, bsz=48, num_updates=6580, lr=1.91602e-05, gnorm=0.13, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7931
2023-08-08 20:27:10 - progress_bar.py[line:272] - INFO: epoch 001:   6601 / 8233 loss=4.964, loss_v1=0, loss_v2=0, nll_loss=3.708, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=13.07, wps=276.7, ups=0.82, wpb=336.1, bsz=48, num_updates=6590, lr=1.91408e-05, gnorm=0.127, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7943
2023-08-08 20:27:22 - progress_bar.py[line:272] - INFO: epoch 001:   6611 / 8233 loss=4.967, loss_v1=0, loss_v2=0, nll_loss=3.699, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=12.99, wps=283.5, ups=0.83, wpb=340.2, bsz=48, num_updates=6600, lr=1.91214e-05, gnorm=0.127, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7955
2023-08-08 20:27:34 - progress_bar.py[line:272] - INFO: epoch 001:   6621 / 8233 loss=4.951, loss_v1=0, loss_v2=0, nll_loss=3.696, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=12.96, wps=275.7, ups=0.82, wpb=334.5, bsz=48, num_updates=6610, lr=1.9102e-05, gnorm=0.125, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7967
2023-08-08 20:27:46 - progress_bar.py[line:272] - INFO: epoch 001:   6631 / 8233 loss=4.96, loss_v1=0, loss_v2=0, nll_loss=3.701, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=13.01, wps=284.3, ups=0.84, wpb=340, bsz=48, num_updates=6620, lr=1.90826e-05, gnorm=0.129, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7979
2023-08-08 20:27:58 - progress_bar.py[line:272] - INFO: epoch 001:   6641 / 8233 loss=4.912, loss_v1=0, loss_v2=0, nll_loss=3.646, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=12.52, wps=284, ups=0.83, wpb=340.5, bsz=48, num_updates=6630, lr=1.90632e-05, gnorm=0.126, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=7991
2023-08-08 20:28:10 - progress_bar.py[line:272] - INFO: epoch 001:   6651 / 8233 loss=4.917, loss_v1=0, loss_v2=0, nll_loss=3.644, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=282.7, ups=0.84, wpb=338.3, bsz=48, num_updates=6640, lr=1.90439e-05, gnorm=0.13, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8003
2023-08-08 20:28:22 - progress_bar.py[line:272] - INFO: epoch 001:   6661 / 8233 loss=4.923, loss_v1=0, loss_v2=0, nll_loss=3.653, ntokens=333.8, nsentences=48, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=12.58, wps=276.3, ups=0.83, wpb=333.8, bsz=48, num_updates=6650, lr=1.90245e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8015
2023-08-08 20:28:34 - progress_bar.py[line:272] - INFO: epoch 001:   6671 / 8233 loss=4.953, loss_v1=0, loss_v2=0, nll_loss=3.691, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=12.92, wps=281.8, ups=0.83, wpb=339.7, bsz=48, num_updates=6660, lr=1.90051e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8027
2023-08-08 20:28:46 - progress_bar.py[line:272] - INFO: epoch 001:   6681 / 8233 loss=4.925, loss_v1=0, loss_v2=0, nll_loss=3.656, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=12.61, wps=280.3, ups=0.83, wpb=336.7, bsz=48, num_updates=6670, lr=1.89857e-05, gnorm=0.123, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8039
2023-08-08 20:28:58 - progress_bar.py[line:272] - INFO: epoch 001:   6691 / 8233 loss=4.864, loss_v1=0, loss_v2=0, nll_loss=3.587, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=12.02, wps=286.6, ups=0.84, wpb=341.2, bsz=48, num_updates=6680, lr=1.89663e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8051
2023-08-08 20:29:10 - progress_bar.py[line:272] - INFO: epoch 001:   6701 / 8233 loss=4.943, loss_v1=0, loss_v2=0, nll_loss=3.677, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=12.79, wps=277.9, ups=0.83, wpb=335.1, bsz=48, num_updates=6690, lr=1.8947e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8063
2023-08-08 20:29:22 - progress_bar.py[line:272] - INFO: epoch 001:   6711 / 8233 loss=4.947, loss_v1=0, loss_v2=0, nll_loss=3.681, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=12.83, wps=283.6, ups=0.83, wpb=340.1, bsz=48, num_updates=6700, lr=1.89276e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8075
2023-08-08 20:29:34 - progress_bar.py[line:272] - INFO: epoch 001:   6721 / 8233 loss=4.926, loss_v1=0, loss_v2=0, nll_loss=3.666, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=12.69, wps=281.1, ups=0.83, wpb=338.2, bsz=48, num_updates=6710, lr=1.89082e-05, gnorm=0.128, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8087
2023-08-08 20:29:46 - progress_bar.py[line:272] - INFO: epoch 001:   6731 / 8233 loss=4.861, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=283.7, ups=0.84, wpb=338.3, bsz=48, num_updates=6720, lr=1.88888e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8099
2023-08-08 20:29:58 - progress_bar.py[line:272] - INFO: epoch 001:   6741 / 8233 loss=4.943, loss_v1=0, loss_v2=0, nll_loss=3.673, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=12.75, wps=284.5, ups=0.84, wpb=339.7, bsz=48, num_updates=6730, lr=1.88694e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8111
2023-08-08 20:30:10 - progress_bar.py[line:272] - INFO: epoch 001:   6751 / 8233 loss=4.912, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=277.9, ups=0.83, wpb=335.6, bsz=48, num_updates=6740, lr=1.88501e-05, gnorm=0.129, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8123
2023-08-08 20:30:22 - progress_bar.py[line:272] - INFO: epoch 001:   6761 / 8233 loss=4.889, loss_v1=0, loss_v2=0, nll_loss=3.61, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=280.4, ups=0.83, wpb=337.5, bsz=48, num_updates=6750, lr=1.88307e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8135
2023-08-08 20:30:35 - progress_bar.py[line:272] - INFO: epoch 001:   6771 / 8233 loss=4.902, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=279.3, ups=0.83, wpb=337.4, bsz=48, num_updates=6760, lr=1.88113e-05, gnorm=0.125, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8147
2023-08-08 20:30:47 - progress_bar.py[line:272] - INFO: epoch 001:   6781 / 8233 loss=4.938, loss_v1=0, loss_v2=0, nll_loss=3.671, ntokens=342.9, nsentences=48, sample_size=342.9, sample_size_v1=0, sample_size_v2=0, ppl=12.74, wps=286.1, ups=0.83, wpb=342.9, bsz=48, num_updates=6770, lr=1.87919e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8159
2023-08-08 20:30:59 - progress_bar.py[line:272] - INFO: epoch 001:   6791 / 8233 loss=4.882, loss_v1=0, loss_v2=0, nll_loss=3.603, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=279.8, ups=0.83, wpb=337.8, bsz=48, num_updates=6780, lr=1.87725e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8172
2023-08-08 20:31:11 - progress_bar.py[line:272] - INFO: epoch 001:   6801 / 8233 loss=4.939, loss_v1=0, loss_v2=0, nll_loss=3.673, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=12.76, wps=280.6, ups=0.83, wpb=339, bsz=48, num_updates=6790, lr=1.87531e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8184
2023-08-08 20:31:23 - progress_bar.py[line:272] - INFO: epoch 001:   6811 / 8233 loss=4.843, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=11.79, wps=283.5, ups=0.83, wpb=341.1, bsz=48, num_updates=6800, lr=1.87338e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8196
2023-08-08 20:31:35 - progress_bar.py[line:272] - INFO: epoch 001:   6821 / 8233 loss=4.922, loss_v1=0, loss_v2=0, nll_loss=3.657, ntokens=333.5, nsentences=48, sample_size=333.5, sample_size_v1=0, sample_size_v2=0, ppl=12.62, wps=274, ups=0.82, wpb=333.5, bsz=48, num_updates=6810, lr=1.87144e-05, gnorm=0.123, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8208
2023-08-08 20:31:47 - progress_bar.py[line:272] - INFO: epoch 001:   6831 / 8233 loss=4.892, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=282.2, ups=0.83, wpb=338.7, bsz=48, num_updates=6820, lr=1.8695e-05, gnorm=0.123, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8220
2023-08-08 20:31:59 - progress_bar.py[line:272] - INFO: epoch 001:   6841 / 8233 loss=4.899, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=278.1, ups=0.83, wpb=336.9, bsz=48, num_updates=6830, lr=1.86756e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8232
2023-08-08 20:32:11 - progress_bar.py[line:272] - INFO: epoch 001:   6851 / 8233 loss=4.882, loss_v1=0, loss_v2=0, nll_loss=3.607, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=12.18, wps=283.4, ups=0.83, wpb=339.9, bsz=48, num_updates=6840, lr=1.86562e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8244
2023-08-08 20:32:23 - progress_bar.py[line:272] - INFO: epoch 001:   6861 / 8233 loss=4.971, loss_v1=0, loss_v2=0, nll_loss=3.714, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=13.12, wps=277.3, ups=0.82, wpb=336.5, bsz=48, num_updates=6850, lr=1.86369e-05, gnorm=0.133, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8256
2023-08-08 20:32:35 - progress_bar.py[line:272] - INFO: epoch 001:   6871 / 8233 loss=4.9, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=280.5, ups=0.83, wpb=337.8, bsz=48, num_updates=6860, lr=1.86175e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8268
2023-08-08 20:32:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 20:32:48 - progress_bar.py[line:272] - INFO: epoch 001:   6882 / 8233 loss=4.898, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=258.4, ups=0.76, wpb=340.6, bsz=48, num_updates=6870, lr=1.85981e-05, gnorm=0.124, clip=0, loss_scale=32, train_wall=13, gb_free=14.5, wall=8281
2023-08-08 20:33:00 - progress_bar.py[line:272] - INFO: epoch 001:   6892 / 8233 loss=4.911, loss_v1=0, loss_v2=0, nll_loss=3.64, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=12.46, wps=280.8, ups=0.83, wpb=336.7, bsz=48, num_updates=6880, lr=1.85787e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8293
2023-08-08 20:33:13 - progress_bar.py[line:272] - INFO: epoch 001:   6902 / 8233 loss=4.915, loss_v1=0, loss_v2=0, nll_loss=3.647, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=12.53, wps=278.7, ups=0.83, wpb=336.9, bsz=48, num_updates=6890, lr=1.85593e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8305
2023-08-08 20:33:25 - progress_bar.py[line:272] - INFO: epoch 001:   6912 / 8233 loss=4.84, loss_v1=0, loss_v2=0, nll_loss=3.557, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=11.77, wps=283.1, ups=0.83, wpb=341, bsz=48, num_updates=6900, lr=1.854e-05, gnorm=0.117, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8317
2023-08-08 20:33:37 - progress_bar.py[line:272] - INFO: epoch 001:   6922 / 8233 loss=4.925, loss_v1=0, loss_v2=0, nll_loss=3.654, ntokens=335, nsentences=48, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=12.59, wps=277.4, ups=0.83, wpb=335, bsz=48, num_updates=6910, lr=1.85206e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8330
2023-08-08 20:33:49 - progress_bar.py[line:272] - INFO: epoch 001:   6932 / 8233 loss=4.876, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=344.7, nsentences=48, sample_size=344.7, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=289.7, ups=0.84, wpb=344.7, bsz=48, num_updates=6920, lr=1.85012e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8341
2023-08-08 20:34:01 - progress_bar.py[line:272] - INFO: epoch 001:   6942 / 8233 loss=4.869, loss_v1=0, loss_v2=0, nll_loss=3.593, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=12.07, wps=278.3, ups=0.83, wpb=336.4, bsz=48, num_updates=6930, lr=1.84818e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8354
2023-08-08 20:34:13 - progress_bar.py[line:272] - INFO: epoch 001:   6952 / 8233 loss=4.904, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=278.7, ups=0.83, wpb=337, bsz=48, num_updates=6940, lr=1.84624e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8366
2023-08-08 20:34:25 - progress_bar.py[line:272] - INFO: epoch 001:   6962 / 8233 loss=4.925, loss_v1=0, loss_v2=0, nll_loss=3.654, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=12.59, wps=282.8, ups=0.83, wpb=339.8, bsz=48, num_updates=6950, lr=1.84431e-05, gnorm=0.131, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8378
2023-08-08 20:34:37 - progress_bar.py[line:272] - INFO: epoch 001:   6972 / 8233 loss=4.941, loss_v1=0, loss_v2=0, nll_loss=3.674, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=12.77, wps=277.3, ups=0.83, wpb=335.2, bsz=48, num_updates=6960, lr=1.84237e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8390
2023-08-08 20:34:49 - progress_bar.py[line:272] - INFO: epoch 001:   6982 / 8233 loss=4.869, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=283, ups=0.83, wpb=339.9, bsz=48, num_updates=6970, lr=1.84043e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8402
2023-08-08 20:35:01 - progress_bar.py[line:272] - INFO: epoch 001:   6992 / 8233 loss=4.92, loss_v1=0, loss_v2=0, nll_loss=3.647, ntokens=332.4, nsentences=48, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=12.53, wps=273.9, ups=0.82, wpb=332.4, bsz=48, num_updates=6980, lr=1.83849e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8414
2023-08-08 20:35:13 - progress_bar.py[line:272] - INFO: epoch 001:   7002 / 8233 loss=4.871, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=284.9, ups=0.84, wpb=340.9, bsz=48, num_updates=6990, lr=1.83655e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8426
2023-08-08 20:35:25 - progress_bar.py[line:272] - INFO: epoch 001:   7012 / 8233 loss=4.885, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=283.4, ups=0.83, wpb=339.4, bsz=48, num_updates=7000, lr=1.83461e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8438
2023-08-08 20:35:37 - progress_bar.py[line:272] - INFO: epoch 001:   7022 / 8233 loss=4.911, loss_v1=0, loss_v2=0, nll_loss=3.648, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=12.53, wps=280.8, ups=0.83, wpb=338.2, bsz=48, num_updates=7010, lr=1.83268e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8450
2023-08-08 20:35:49 - progress_bar.py[line:272] - INFO: epoch 001:   7032 / 8233 loss=4.942, loss_v1=0, loss_v2=0, nll_loss=3.682, ntokens=334.1, nsentences=48, sample_size=334.1, sample_size_v1=0, sample_size_v2=0, ppl=12.84, wps=276.1, ups=0.83, wpb=334.1, bsz=48, num_updates=7020, lr=1.83074e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8462
2023-08-08 20:36:01 - progress_bar.py[line:272] - INFO: epoch 001:   7042 / 8233 loss=4.92, loss_v1=0, loss_v2=0, nll_loss=3.655, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=12.59, wps=280.7, ups=0.83, wpb=337.8, bsz=48, num_updates=7030, lr=1.8288e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8474
2023-08-08 20:36:13 - progress_bar.py[line:272] - INFO: epoch 001:   7052 / 8233 loss=4.848, loss_v1=0, loss_v2=0, nll_loss=3.57, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=11.87, wps=279.8, ups=0.83, wpb=337.5, bsz=48, num_updates=7040, lr=1.82686e-05, gnorm=0.116, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8486
2023-08-08 20:36:25 - progress_bar.py[line:272] - INFO: epoch 001:   7062 / 8233 loss=4.891, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=281.6, ups=0.83, wpb=339.1, bsz=48, num_updates=7050, lr=1.82492e-05, gnorm=0.124, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8498
2023-08-08 20:36:37 - progress_bar.py[line:272] - INFO: epoch 001:   7072 / 8233 loss=4.837, loss_v1=0, loss_v2=0, nll_loss=3.556, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=279.6, ups=0.83, wpb=338.2, bsz=48, num_updates=7060, lr=1.82299e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8510
2023-08-08 20:36:49 - progress_bar.py[line:272] - INFO: epoch 001:   7082 / 8233 loss=4.895, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=282.6, ups=0.83, wpb=340, bsz=48, num_updates=7070, lr=1.82105e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8522
2023-08-08 20:37:01 - progress_bar.py[line:272] - INFO: epoch 001:   7092 / 8233 loss=4.891, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=281.9, ups=0.83, wpb=339.5, bsz=48, num_updates=7080, lr=1.81911e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8534
2023-08-08 20:37:13 - progress_bar.py[line:272] - INFO: epoch 001:   7102 / 8233 loss=4.919, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=282.5, ups=0.83, wpb=338.9, bsz=48, num_updates=7090, lr=1.81717e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8546
2023-08-08 20:37:25 - progress_bar.py[line:272] - INFO: epoch 001:   7112 / 8233 loss=4.882, loss_v1=0, loss_v2=0, nll_loss=3.612, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=280, ups=0.83, wpb=336.7, bsz=48, num_updates=7100, lr=1.81523e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8558
2023-08-08 20:37:37 - progress_bar.py[line:272] - INFO: epoch 001:   7122 / 8233 loss=4.887, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=282.7, ups=0.83, wpb=340.1, bsz=48, num_updates=7110, lr=1.8133e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8570
2023-08-08 20:37:49 - progress_bar.py[line:272] - INFO: epoch 001:   7132 / 8233 loss=4.873, loss_v1=0, loss_v2=0, nll_loss=3.595, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=279.9, ups=0.83, wpb=336.3, bsz=48, num_updates=7120, lr=1.81136e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8582
2023-08-08 20:38:02 - progress_bar.py[line:272] - INFO: epoch 001:   7142 / 8233 loss=4.86, loss_v1=0, loss_v2=0, nll_loss=3.588, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=12.03, wps=279.1, ups=0.83, wpb=335.9, bsz=48, num_updates=7130, lr=1.80942e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8594
2023-08-08 20:38:14 - progress_bar.py[line:272] - INFO: epoch 001:   7152 / 8233 loss=4.832, loss_v1=0, loss_v2=0, nll_loss=3.554, ntokens=341.8, nsentences=48, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=11.75, wps=285.1, ups=0.83, wpb=341.8, bsz=48, num_updates=7140, lr=1.80748e-05, gnorm=0.124, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8606
2023-08-08 20:38:25 - progress_bar.py[line:272] - INFO: epoch 001:   7162 / 8233 loss=4.867, loss_v1=0, loss_v2=0, nll_loss=3.583, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=11.98, wps=281.9, ups=0.84, wpb=336.9, bsz=48, num_updates=7150, lr=1.80554e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8618
2023-08-08 20:38:37 - progress_bar.py[line:272] - INFO: epoch 001:   7172 / 8233 loss=4.872, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=282, ups=0.83, wpb=338.3, bsz=48, num_updates=7160, lr=1.8036e-05, gnorm=0.115, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8630
2023-08-08 20:38:49 - progress_bar.py[line:272] - INFO: epoch 001:   7182 / 8233 loss=4.864, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=282.8, ups=0.83, wpb=339.3, bsz=48, num_updates=7170, lr=1.80167e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8642
2023-08-08 20:39:02 - progress_bar.py[line:272] - INFO: epoch 001:   7192 / 8233 loss=4.846, loss_v1=0, loss_v2=0, nll_loss=3.57, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=11.88, wps=276.7, ups=0.83, wpb=335.3, bsz=48, num_updates=7180, lr=1.79973e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8654
2023-08-08 20:39:14 - progress_bar.py[line:272] - INFO: epoch 001:   7202 / 8233 loss=4.857, loss_v1=0, loss_v2=0, nll_loss=3.58, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=11.96, wps=281.6, ups=0.83, wpb=338.2, bsz=48, num_updates=7190, lr=1.79779e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8666
2023-08-08 20:39:26 - progress_bar.py[line:272] - INFO: epoch 001:   7212 / 8233 loss=4.905, loss_v1=0, loss_v2=0, nll_loss=3.639, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=12.46, wps=277.5, ups=0.83, wpb=336, bsz=48, num_updates=7200, lr=1.79585e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8679
2023-08-08 20:39:38 - progress_bar.py[line:272] - INFO: epoch 001:   7222 / 8233 loss=4.898, loss_v1=0, loss_v2=0, nll_loss=3.632, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=283.2, ups=0.83, wpb=341.1, bsz=48, num_updates=7210, lr=1.79391e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8691
2023-08-08 20:39:50 - progress_bar.py[line:272] - INFO: epoch 001:   7232 / 8233 loss=4.876, loss_v1=0, loss_v2=0, nll_loss=3.606, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=12.18, wps=278.9, ups=0.83, wpb=336.9, bsz=48, num_updates=7220, lr=1.79198e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8703
2023-08-08 20:40:02 - progress_bar.py[line:272] - INFO: epoch 001:   7242 / 8233 loss=4.783, loss_v1=0, loss_v2=0, nll_loss=3.492, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=11.25, wps=285.2, ups=0.84, wpb=341.4, bsz=48, num_updates=7230, lr=1.79004e-05, gnorm=0.116, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8715
2023-08-08 20:40:14 - progress_bar.py[line:272] - INFO: epoch 001:   7252 / 8233 loss=4.859, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=331.8, nsentences=48, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=274.3, ups=0.83, wpb=331.8, bsz=48, num_updates=7240, lr=1.7881e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8727
2023-08-08 20:40:26 - progress_bar.py[line:272] - INFO: epoch 001:   7262 / 8233 loss=4.878, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=279.7, ups=0.83, wpb=336.4, bsz=48, num_updates=7250, lr=1.78616e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8739
2023-08-08 20:40:38 - progress_bar.py[line:272] - INFO: epoch 001:   7272 / 8233 loss=4.824, loss_v1=0, loss_v2=0, nll_loss=3.553, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.74, wps=282.9, ups=0.84, wpb=338, bsz=48, num_updates=7260, lr=1.78422e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8751
2023-08-08 20:40:50 - progress_bar.py[line:272] - INFO: epoch 001:   7282 / 8233 loss=4.847, loss_v1=0, loss_v2=0, nll_loss=3.569, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=11.87, wps=279.1, ups=0.83, wpb=337, bsz=48, num_updates=7270, lr=1.78229e-05, gnorm=0.128, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8763
2023-08-08 20:41:02 - progress_bar.py[line:272] - INFO: epoch 001:   7292 / 8233 loss=4.88, loss_v1=0, loss_v2=0, nll_loss=3.61, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=282.6, ups=0.84, wpb=337.7, bsz=48, num_updates=7280, lr=1.78035e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8775
2023-08-08 20:41:14 - progress_bar.py[line:272] - INFO: epoch 001:   7302 / 8233 loss=4.858, loss_v1=0, loss_v2=0, nll_loss=3.581, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=11.97, wps=285.1, ups=0.84, wpb=340.2, bsz=48, num_updates=7290, lr=1.77841e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8787
2023-08-08 20:41:26 - progress_bar.py[line:272] - INFO: epoch 001:   7312 / 8233 loss=4.884, loss_v1=0, loss_v2=0, nll_loss=3.615, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=12.25, wps=284.7, ups=0.84, wpb=340.8, bsz=48, num_updates=7300, lr=1.77647e-05, gnorm=0.12, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8799
2023-08-08 20:41:38 - progress_bar.py[line:272] - INFO: epoch 001:   7322 / 8233 loss=4.805, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=283.5, ups=0.83, wpb=340, bsz=48, num_updates=7310, lr=1.77453e-05, gnorm=0.114, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8811
2023-08-08 20:41:50 - progress_bar.py[line:272] - INFO: epoch 001:   7332 / 8233 loss=4.904, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=12.41, wps=284.3, ups=0.84, wpb=339.9, bsz=48, num_updates=7320, lr=1.7726e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8823
2023-08-08 20:42:02 - progress_bar.py[line:272] - INFO: epoch 001:   7342 / 8233 loss=4.892, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=277.6, ups=0.83, wpb=336.2, bsz=48, num_updates=7330, lr=1.77066e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8835
2023-08-08 20:42:14 - progress_bar.py[line:272] - INFO: epoch 001:   7352 / 8233 loss=4.868, loss_v1=0, loss_v2=0, nll_loss=3.596, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=278.9, ups=0.83, wpb=335.9, bsz=48, num_updates=7340, lr=1.76872e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8847
2023-08-08 20:42:26 - progress_bar.py[line:272] - INFO: epoch 001:   7362 / 8233 loss=4.82, loss_v1=0, loss_v2=0, nll_loss=3.542, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=11.65, wps=282.1, ups=0.83, wpb=338.2, bsz=48, num_updates=7350, lr=1.76678e-05, gnorm=0.117, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8859
2023-08-08 20:42:38 - progress_bar.py[line:272] - INFO: epoch 001:   7372 / 8233 loss=4.84, loss_v1=0, loss_v2=0, nll_loss=3.563, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=280.8, ups=0.84, wpb=335.8, bsz=48, num_updates=7360, lr=1.76484e-05, gnorm=0.126, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8871
2023-08-08 20:42:50 - progress_bar.py[line:272] - INFO: epoch 001:   7382 / 8233 loss=4.838, loss_v1=0, loss_v2=0, nll_loss=3.563, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=11.82, wps=286, ups=0.84, wpb=340.8, bsz=48, num_updates=7370, lr=1.7629e-05, gnorm=0.116, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8883
2023-08-08 20:43:02 - progress_bar.py[line:272] - INFO: epoch 001:   7392 / 8233 loss=4.86, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=280.7, ups=0.83, wpb=336.7, bsz=48, num_updates=7380, lr=1.76097e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8895
2023-08-08 20:43:14 - progress_bar.py[line:272] - INFO: epoch 001:   7402 / 8233 loss=4.856, loss_v1=0, loss_v2=0, nll_loss=3.574, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=11.91, wps=279.6, ups=0.83, wpb=338.1, bsz=48, num_updates=7390, lr=1.75903e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=8907
2023-08-08 20:43:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 20:43:27 - progress_bar.py[line:272] - INFO: epoch 001:   7413 / 8233 loss=4.85, loss_v1=0, loss_v2=0, nll_loss=3.572, ntokens=343.8, nsentences=48, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=11.89, wps=261.6, ups=0.76, wpb=343.8, bsz=48, num_updates=7400, lr=1.75709e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=13, gb_free=14.5, wall=8920
2023-08-08 20:43:39 - progress_bar.py[line:272] - INFO: epoch 001:   7423 / 8233 loss=4.835, loss_v1=0, loss_v2=0, nll_loss=3.558, ntokens=331.7, nsentences=48, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=11.78, wps=271.2, ups=0.82, wpb=331.7, bsz=48, num_updates=7410, lr=1.75515e-05, gnorm=0.124, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8932
2023-08-08 20:43:51 - progress_bar.py[line:272] - INFO: epoch 001:   7433 / 8233 loss=4.832, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=11.79, wps=277.9, ups=0.83, wpb=336.7, bsz=48, num_updates=7420, lr=1.75321e-05, gnorm=0.117, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8944
2023-08-08 20:44:03 - progress_bar.py[line:272] - INFO: epoch 001:   7443 / 8233 loss=4.829, loss_v1=0, loss_v2=0, nll_loss=3.544, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=11.67, wps=281.3, ups=0.83, wpb=337.1, bsz=48, num_updates=7430, lr=1.75128e-05, gnorm=0.125, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8956
2023-08-08 20:44:15 - progress_bar.py[line:272] - INFO: epoch 001:   7453 / 8233 loss=4.799, loss_v1=0, loss_v2=0, nll_loss=3.514, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=283.5, ups=0.83, wpb=340, bsz=48, num_updates=7440, lr=1.74934e-05, gnorm=0.114, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8968
2023-08-08 20:44:27 - progress_bar.py[line:272] - INFO: epoch 001:   7463 / 8233 loss=4.873, loss_v1=0, loss_v2=0, nll_loss=3.6, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=12.13, wps=277.6, ups=0.83, wpb=335.8, bsz=48, num_updates=7450, lr=1.7474e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8980
2023-08-08 20:44:40 - progress_bar.py[line:272] - INFO: epoch 001:   7473 / 8233 loss=4.829, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=281.4, ups=0.83, wpb=337.9, bsz=48, num_updates=7460, lr=1.74546e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=8992
2023-08-08 20:44:51 - progress_bar.py[line:272] - INFO: epoch 001:   7483 / 8233 loss=4.816, loss_v1=0, loss_v2=0, nll_loss=3.54, ntokens=342, nsentences=48, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=11.63, wps=288.2, ups=0.84, wpb=342, bsz=48, num_updates=7470, lr=1.74352e-05, gnorm=0.12, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9004
2023-08-08 20:45:03 - progress_bar.py[line:272] - INFO: epoch 001:   7493 / 8233 loss=4.848, loss_v1=0, loss_v2=0, nll_loss=3.569, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.87, wps=284.7, ups=0.84, wpb=340, bsz=48, num_updates=7480, lr=1.74159e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9016
2023-08-08 20:45:15 - progress_bar.py[line:272] - INFO: epoch 001:   7503 / 8233 loss=4.824, loss_v1=0, loss_v2=0, nll_loss=3.537, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=280.5, ups=0.83, wpb=337.3, bsz=48, num_updates=7490, lr=1.73965e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9028
2023-08-08 20:45:27 - progress_bar.py[line:272] - INFO: epoch 001:   7513 / 8233 loss=4.816, loss_v1=0, loss_v2=0, nll_loss=3.535, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=281.8, ups=0.83, wpb=339.3, bsz=48, num_updates=7500, lr=1.73771e-05, gnorm=0.12, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9040
2023-08-08 20:45:39 - progress_bar.py[line:272] - INFO: epoch 001:   7523 / 8233 loss=4.83, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=280.7, ups=0.83, wpb=337.7, bsz=48, num_updates=7510, lr=1.73577e-05, gnorm=0.116, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9052
2023-08-08 20:45:52 - progress_bar.py[line:272] - INFO: epoch 001:   7533 / 8233 loss=4.844, loss_v1=0, loss_v2=0, nll_loss=3.566, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=11.84, wps=278.3, ups=0.83, wpb=336.4, bsz=48, num_updates=7520, lr=1.73383e-05, gnorm=0.123, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9064
2023-08-08 20:46:04 - progress_bar.py[line:272] - INFO: epoch 001:   7543 / 8233 loss=4.888, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=334.4, nsentences=48, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=276.7, ups=0.83, wpb=334.4, bsz=48, num_updates=7530, lr=1.73189e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9076
2023-08-08 20:46:16 - progress_bar.py[line:272] - INFO: epoch 001:   7553 / 8233 loss=4.809, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=334.9, nsentences=48, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=11.57, wps=277.7, ups=0.83, wpb=334.9, bsz=48, num_updates=7540, lr=1.72996e-05, gnorm=0.116, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9089
2023-08-08 20:46:28 - progress_bar.py[line:272] - INFO: epoch 001:   7563 / 8233 loss=4.833, loss_v1=0, loss_v2=0, nll_loss=3.555, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=284.1, ups=0.83, wpb=340.4, bsz=48, num_updates=7550, lr=1.72802e-05, gnorm=0.115, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9101
2023-08-08 20:46:40 - progress_bar.py[line:272] - INFO: epoch 001:   7573 / 8233 loss=4.837, loss_v1=0, loss_v2=0, nll_loss=3.568, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=11.86, wps=282.9, ups=0.83, wpb=339.3, bsz=48, num_updates=7560, lr=1.72608e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9113
2023-08-08 20:46:52 - progress_bar.py[line:272] - INFO: epoch 001:   7583 / 8233 loss=4.822, loss_v1=0, loss_v2=0, nll_loss=3.545, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=11.67, wps=283.1, ups=0.83, wpb=340.1, bsz=48, num_updates=7570, lr=1.72414e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9125
2023-08-08 20:47:04 - progress_bar.py[line:272] - INFO: epoch 001:   7593 / 8233 loss=4.818, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=11.57, wps=284.1, ups=0.84, wpb=339.6, bsz=48, num_updates=7580, lr=1.7222e-05, gnorm=0.117, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9137
2023-08-08 20:47:16 - progress_bar.py[line:272] - INFO: epoch 001:   7603 / 8233 loss=4.829, loss_v1=0, loss_v2=0, nll_loss=3.548, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=281.1, ups=0.83, wpb=338.6, bsz=48, num_updates=7590, lr=1.72027e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9149
2023-08-08 20:47:28 - progress_bar.py[line:272] - INFO: epoch 001:   7613 / 8233 loss=4.807, loss_v1=0, loss_v2=0, nll_loss=3.525, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=282.7, ups=0.83, wpb=340.1, bsz=48, num_updates=7600, lr=1.71833e-05, gnorm=0.12, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9161
2023-08-08 20:47:40 - progress_bar.py[line:272] - INFO: epoch 001:   7623 / 8233 loss=4.846, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=284.8, ups=0.84, wpb=340.2, bsz=48, num_updates=7610, lr=1.71639e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9173
2023-08-08 20:47:52 - progress_bar.py[line:272] - INFO: epoch 001:   7633 / 8233 loss=4.81, loss_v1=0, loss_v2=0, nll_loss=3.529, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=279.9, ups=0.83, wpb=336.6, bsz=48, num_updates=7620, lr=1.71445e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9185
2023-08-08 20:48:04 - progress_bar.py[line:272] - INFO: epoch 001:   7643 / 8233 loss=4.838, loss_v1=0, loss_v2=0, nll_loss=3.556, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=279.9, ups=0.83, wpb=335.6, bsz=48, num_updates=7630, lr=1.71251e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9197
2023-08-08 20:48:16 - progress_bar.py[line:272] - INFO: epoch 001:   7653 / 8233 loss=4.849, loss_v1=0, loss_v2=0, nll_loss=3.572, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=11.89, wps=284.3, ups=0.83, wpb=341.2, bsz=48, num_updates=7640, lr=1.71058e-05, gnorm=0.124, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9209
2023-08-08 20:48:28 - progress_bar.py[line:272] - INFO: epoch 001:   7663 / 8233 loss=4.81, loss_v1=0, loss_v2=0, nll_loss=3.529, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=11.55, wps=283.7, ups=0.84, wpb=339.2, bsz=48, num_updates=7650, lr=1.70864e-05, gnorm=0.116, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9221
2023-08-08 20:48:40 - progress_bar.py[line:272] - INFO: epoch 001:   7673 / 8233 loss=4.783, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=334.6, nsentences=48, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=276.2, ups=0.83, wpb=334.6, bsz=48, num_updates=7660, lr=1.7067e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9233
2023-08-08 20:48:52 - progress_bar.py[line:272] - INFO: epoch 001:   7683 / 8233 loss=4.787, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=284.6, ups=0.83, wpb=342.3, bsz=48, num_updates=7670, lr=1.70476e-05, gnorm=0.115, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9245
2023-08-08 20:49:04 - progress_bar.py[line:272] - INFO: epoch 001:   7693 / 8233 loss=4.833, loss_v1=0, loss_v2=0, nll_loss=3.558, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=11.78, wps=277.7, ups=0.83, wpb=336.1, bsz=48, num_updates=7680, lr=1.70282e-05, gnorm=0.127, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9257
2023-08-08 20:49:16 - progress_bar.py[line:272] - INFO: epoch 001:   7703 / 8233 loss=4.809, loss_v1=0, loss_v2=0, nll_loss=3.517, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=279.4, ups=0.83, wpb=337.4, bsz=48, num_updates=7690, lr=1.70089e-05, gnorm=0.117, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9269
2023-08-08 20:49:28 - progress_bar.py[line:272] - INFO: epoch 001:   7713 / 8233 loss=4.834, loss_v1=0, loss_v2=0, nll_loss=3.563, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.82, wps=280.9, ups=0.83, wpb=338, bsz=48, num_updates=7700, lr=1.69895e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9281
2023-08-08 20:49:40 - progress_bar.py[line:272] - INFO: epoch 001:   7723 / 8233 loss=4.831, loss_v1=0, loss_v2=0, nll_loss=3.558, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=11.78, wps=281.6, ups=0.83, wpb=338.5, bsz=48, num_updates=7710, lr=1.69701e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9293
2023-08-08 20:49:52 - progress_bar.py[line:272] - INFO: epoch 001:   7733 / 8233 loss=4.811, loss_v1=0, loss_v2=0, nll_loss=3.528, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=283.2, ups=0.84, wpb=337.7, bsz=48, num_updates=7720, lr=1.69507e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9305
2023-08-08 20:50:04 - progress_bar.py[line:272] - INFO: epoch 001:   7743 / 8233 loss=4.846, loss_v1=0, loss_v2=0, nll_loss=3.574, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=11.91, wps=285.9, ups=0.84, wpb=339.6, bsz=48, num_updates=7730, lr=1.69313e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9317
2023-08-08 20:50:16 - progress_bar.py[line:272] - INFO: epoch 001:   7753 / 8233 loss=4.83, loss_v1=0, loss_v2=0, nll_loss=3.555, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=277.7, ups=0.83, wpb=335.5, bsz=48, num_updates=7740, lr=1.69119e-05, gnorm=0.12, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9329
2023-08-08 20:50:28 - progress_bar.py[line:272] - INFO: epoch 001:   7763 / 8233 loss=4.802, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=281.5, ups=0.83, wpb=340, bsz=48, num_updates=7750, lr=1.68926e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9341
2023-08-08 20:50:40 - progress_bar.py[line:272] - INFO: epoch 001:   7773 / 8233 loss=4.8, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=341.8, nsentences=48, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=286.8, ups=0.84, wpb=341.8, bsz=48, num_updates=7760, lr=1.68732e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9353
2023-08-08 20:50:52 - progress_bar.py[line:272] - INFO: epoch 001:   7783 / 8233 loss=4.836, loss_v1=0, loss_v2=0, nll_loss=3.553, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=11.74, wps=280.5, ups=0.83, wpb=336.3, bsz=48, num_updates=7770, lr=1.68538e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9365
2023-08-08 20:51:04 - progress_bar.py[line:272] - INFO: epoch 001:   7793 / 8233 loss=4.84, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=11.79, wps=281.7, ups=0.83, wpb=340.1, bsz=48, num_updates=7780, lr=1.68344e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9377
2023-08-08 20:51:16 - progress_bar.py[line:272] - INFO: epoch 001:   7803 / 8233 loss=4.805, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=283.5, ups=0.83, wpb=340.7, bsz=48, num_updates=7790, lr=1.6815e-05, gnorm=0.12, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9389
2023-08-08 20:51:28 - progress_bar.py[line:272] - INFO: epoch 001:   7813 / 8233 loss=4.832, loss_v1=0, loss_v2=0, nll_loss=3.55, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=11.71, wps=283.9, ups=0.83, wpb=341.3, bsz=48, num_updates=7800, lr=1.67957e-05, gnorm=0.122, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9401
2023-08-08 20:51:40 - progress_bar.py[line:272] - INFO: epoch 001:   7823 / 8233 loss=4.827, loss_v1=0, loss_v2=0, nll_loss=3.548, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=281.1, ups=0.84, wpb=336.1, bsz=48, num_updates=7810, lr=1.67763e-05, gnorm=0.116, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9413
2023-08-08 20:51:52 - progress_bar.py[line:272] - INFO: epoch 001:   7833 / 8233 loss=4.831, loss_v1=0, loss_v2=0, nll_loss=3.555, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=11.75, wps=282, ups=0.83, wpb=339.2, bsz=48, num_updates=7820, lr=1.67569e-05, gnorm=0.117, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9425
2023-08-08 20:52:04 - progress_bar.py[line:272] - INFO: epoch 001:   7843 / 8233 loss=4.806, loss_v1=0, loss_v2=0, nll_loss=3.532, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=11.57, wps=277.9, ups=0.83, wpb=335.3, bsz=48, num_updates=7830, lr=1.67375e-05, gnorm=0.12, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9437
2023-08-08 20:52:16 - progress_bar.py[line:272] - INFO: epoch 001:   7853 / 8233 loss=4.813, loss_v1=0, loss_v2=0, nll_loss=3.526, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=11.52, wps=279.9, ups=0.83, wpb=336.5, bsz=48, num_updates=7840, lr=1.67181e-05, gnorm=0.115, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9449
2023-08-08 20:52:28 - progress_bar.py[line:272] - INFO: epoch 001:   7863 / 8233 loss=4.856, loss_v1=0, loss_v2=0, nll_loss=3.57, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=11.88, wps=278.3, ups=0.83, wpb=336, bsz=48, num_updates=7850, lr=1.66988e-05, gnorm=0.121, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9461
2023-08-08 20:52:40 - progress_bar.py[line:272] - INFO: epoch 001:   7873 / 8233 loss=4.799, loss_v1=0, loss_v2=0, nll_loss=3.507, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=280.5, ups=0.83, wpb=338.5, bsz=48, num_updates=7860, lr=1.66794e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9473
2023-08-08 20:52:52 - progress_bar.py[line:272] - INFO: epoch 001:   7883 / 8233 loss=4.808, loss_v1=0, loss_v2=0, nll_loss=3.53, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=11.55, wps=285.6, ups=0.84, wpb=341.3, bsz=48, num_updates=7870, lr=1.666e-05, gnorm=0.119, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9485
2023-08-08 20:53:04 - progress_bar.py[line:272] - INFO: epoch 001:   7893 / 8233 loss=4.821, loss_v1=0, loss_v2=0, nll_loss=3.544, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=11.66, wps=275.8, ups=0.83, wpb=334.2, bsz=48, num_updates=7880, lr=1.66406e-05, gnorm=0.118, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9497
2023-08-08 20:53:16 - progress_bar.py[line:272] - INFO: epoch 001:   7903 / 8233 loss=4.787, loss_v1=0, loss_v2=0, nll_loss=3.499, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=283.7, ups=0.84, wpb=338, bsz=48, num_updates=7890, lr=1.66212e-05, gnorm=0.115, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9509
2023-08-08 20:53:28 - progress_bar.py[line:272] - INFO: epoch 001:   7913 / 8233 loss=4.793, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=285.6, ups=0.84, wpb=339.2, bsz=48, num_updates=7900, lr=1.66018e-05, gnorm=0.114, clip=0, loss_scale=32, train_wall=12, gb_free=14.5, wall=9521
2023-08-08 20:53:40 - progress_bar.py[line:272] - INFO: epoch 001:   7923 / 8233 loss=4.808, loss_v1=0, loss_v2=0, nll_loss=3.534, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=281.9, ups=0.83, wpb=338, bsz=48, num_updates=7910, lr=1.65825e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9533
2023-08-08 20:53:52 - progress_bar.py[line:272] - INFO: epoch 001:   7933 / 8233 loss=4.793, loss_v1=0, loss_v2=0, nll_loss=3.505, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=283, ups=0.84, wpb=337.9, bsz=48, num_updates=7920, lr=1.65631e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9545
2023-08-08 20:54:04 - progress_bar.py[line:272] - INFO: epoch 001:   7943 / 8233 loss=4.78, loss_v1=0, loss_v2=0, nll_loss=3.493, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=11.26, wps=280.6, ups=0.83, wpb=336.9, bsz=48, num_updates=7930, lr=1.65437e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9557
2023-08-08 20:54:16 - progress_bar.py[line:272] - INFO: epoch 001:   7953 / 8233 loss=4.808, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=284.6, ups=0.84, wpb=339.8, bsz=48, num_updates=7940, lr=1.65243e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9569
2023-08-08 20:54:28 - progress_bar.py[line:272] - INFO: epoch 001:   7963 / 8233 loss=4.804, loss_v1=0, loss_v2=0, nll_loss=3.522, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=11.49, wps=282.3, ups=0.83, wpb=339.8, bsz=48, num_updates=7950, lr=1.65049e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9581
2023-08-08 20:54:40 - progress_bar.py[line:272] - INFO: epoch 001:   7973 / 8233 loss=4.839, loss_v1=0, loss_v2=0, nll_loss=3.557, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=11.77, wps=280.2, ups=0.83, wpb=337.5, bsz=48, num_updates=7960, lr=1.64856e-05, gnorm=0.12, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9593
2023-08-08 20:54:52 - progress_bar.py[line:272] - INFO: epoch 001:   7983 / 8233 loss=4.788, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=284.4, ups=0.83, wpb=341.2, bsz=48, num_updates=7970, lr=1.64662e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9605
2023-08-08 20:55:04 - progress_bar.py[line:272] - INFO: epoch 001:   7993 / 8233 loss=4.794, loss_v1=0, loss_v2=0, nll_loss=3.512, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.41, wps=281.1, ups=0.83, wpb=338, bsz=48, num_updates=7980, lr=1.64468e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9617
2023-08-08 20:55:16 - progress_bar.py[line:272] - INFO: epoch 001:   8003 / 8233 loss=4.84, loss_v1=0, loss_v2=0, nll_loss=3.562, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=280.6, ups=0.83, wpb=337.5, bsz=48, num_updates=7990, lr=1.64274e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9629
2023-08-08 20:55:28 - progress_bar.py[line:272] - INFO: epoch 001:   8013 / 8233 loss=4.8, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=277.2, ups=0.83, wpb=335.4, bsz=48, num_updates=8000, lr=1.6408e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9641
2023-08-08 20:55:40 - progress_bar.py[line:272] - INFO: epoch 001:   8023 / 8233 loss=4.789, loss_v1=0, loss_v2=0, nll_loss=3.509, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=282.7, ups=0.83, wpb=339.5, bsz=48, num_updates=8010, lr=1.63887e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9653
2023-08-08 20:55:52 - progress_bar.py[line:272] - INFO: epoch 001:   8033 / 8233 loss=4.823, loss_v1=0, loss_v2=0, nll_loss=3.549, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=280.5, ups=0.83, wpb=337.7, bsz=48, num_updates=8020, lr=1.63693e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9665
2023-08-08 20:56:04 - progress_bar.py[line:272] - INFO: epoch 001:   8043 / 8233 loss=4.815, loss_v1=0, loss_v2=0, nll_loss=3.539, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=278.3, ups=0.83, wpb=335.9, bsz=48, num_updates=8030, lr=1.63499e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9677
2023-08-08 20:56:16 - progress_bar.py[line:272] - INFO: epoch 001:   8053 / 8233 loss=4.828, loss_v1=0, loss_v2=0, nll_loss=3.551, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=11.72, wps=277.9, ups=0.83, wpb=336.1, bsz=48, num_updates=8040, lr=1.63305e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9689
2023-08-08 20:56:29 - progress_bar.py[line:272] - INFO: epoch 001:   8063 / 8233 loss=4.823, loss_v1=0, loss_v2=0, nll_loss=3.545, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=11.67, wps=280.9, ups=0.83, wpb=337.5, bsz=48, num_updates=8050, lr=1.63111e-05, gnorm=0.12, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9701
2023-08-08 20:56:41 - progress_bar.py[line:272] - INFO: epoch 001:   8073 / 8233 loss=4.82, loss_v1=0, loss_v2=0, nll_loss=3.537, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=282.4, ups=0.83, wpb=339.7, bsz=48, num_updates=8060, lr=1.62918e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9713
2023-08-08 20:56:53 - progress_bar.py[line:272] - INFO: epoch 001:   8083 / 8233 loss=4.805, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=281.6, ups=0.83, wpb=337.4, bsz=48, num_updates=8070, lr=1.62724e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9725
2023-08-08 20:57:05 - progress_bar.py[line:272] - INFO: epoch 001:   8093 / 8233 loss=4.787, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=276.2, ups=0.82, wpb=335.3, bsz=48, num_updates=8080, lr=1.6253e-05, gnorm=0.12, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9738
2023-08-08 20:57:17 - progress_bar.py[line:272] - INFO: epoch 001:   8103 / 8233 loss=4.835, loss_v1=0, loss_v2=0, nll_loss=3.558, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=11.78, wps=280.5, ups=0.83, wpb=336.1, bsz=48, num_updates=8090, lr=1.62336e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9750
2023-08-08 20:57:29 - progress_bar.py[line:272] - INFO: epoch 001:   8113 / 8233 loss=4.777, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=282.7, ups=0.83, wpb=338.6, bsz=48, num_updates=8100, lr=1.62142e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9762
2023-08-08 20:57:41 - progress_bar.py[line:272] - INFO: epoch 001:   8123 / 8233 loss=4.783, loss_v1=0, loss_v2=0, nll_loss=3.492, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=11.25, wps=281.4, ups=0.83, wpb=337.7, bsz=48, num_updates=8110, lr=1.61948e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9774
2023-08-08 20:57:53 - progress_bar.py[line:272] - INFO: epoch 001:   8133 / 8233 loss=4.823, loss_v1=0, loss_v2=0, nll_loss=3.546, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=11.68, wps=284, ups=0.84, wpb=339.3, bsz=48, num_updates=8120, lr=1.61755e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9785
2023-08-08 20:58:05 - progress_bar.py[line:272] - INFO: epoch 001:   8143 / 8233 loss=4.833, loss_v1=0, loss_v2=0, nll_loss=3.561, ntokens=334.6, nsentences=48, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=276.5, ups=0.83, wpb=334.6, bsz=48, num_updates=8130, lr=1.61561e-05, gnorm=0.122, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9798
2023-08-08 20:58:17 - progress_bar.py[line:272] - INFO: epoch 001:   8153 / 8233 loss=4.759, loss_v1=0, loss_v2=0, nll_loss=3.474, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=11.11, wps=283.6, ups=0.84, wpb=339.5, bsz=48, num_updates=8140, lr=1.61367e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9810
2023-08-08 20:58:29 - progress_bar.py[line:272] - INFO: epoch 001:   8163 / 8233 loss=4.788, loss_v1=0, loss_v2=0, nll_loss=3.502, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=282.8, ups=0.83, wpb=339.4, bsz=48, num_updates=8150, lr=1.61173e-05, gnorm=0.12, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9822
2023-08-08 20:58:41 - progress_bar.py[line:272] - INFO: epoch 001:   8173 / 8233 loss=4.795, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=284.4, ups=0.84, wpb=340.4, bsz=48, num_updates=8160, lr=1.60979e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9834
2023-08-08 20:58:53 - progress_bar.py[line:272] - INFO: epoch 001:   8183 / 8233 loss=4.786, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=278.3, ups=0.83, wpb=335.4, bsz=48, num_updates=8170, lr=1.60786e-05, gnorm=0.12, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9846
2023-08-08 20:59:05 - progress_bar.py[line:272] - INFO: epoch 001:   8193 / 8233 loss=4.81, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=286.8, ups=0.84, wpb=341.1, bsz=48, num_updates=8180, lr=1.60592e-05, gnorm=0.119, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9857
2023-08-08 20:59:17 - progress_bar.py[line:272] - INFO: epoch 001:   8203 / 8233 loss=4.78, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=278.8, ups=0.83, wpb=336.1, bsz=48, num_updates=8190, lr=1.60398e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9870
2023-08-08 20:59:29 - progress_bar.py[line:272] - INFO: epoch 001:   8213 / 8233 loss=4.78, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=280.2, ups=0.83, wpb=337.2, bsz=48, num_updates=8200, lr=1.60204e-05, gnorm=0.119, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9882
2023-08-08 20:59:41 - progress_bar.py[line:272] - INFO: epoch 001:   8223 / 8233 loss=4.789, loss_v1=0, loss_v2=0, nll_loss=3.514, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=280.1, ups=0.83, wpb=337.9, bsz=48, num_updates=8210, lr=1.6001e-05, gnorm=0.119, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9894
2023-08-08 20:59:53 - progress_bar.py[line:272] - INFO: epoch 001:   8233 / 8233 loss=4.766, loss_v1=0, loss_v2=0, nll_loss=3.477, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=281.1, ups=0.83, wpb=339.3, bsz=48, num_updates=8220, lr=1.59817e-05, gnorm=0.123, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9906
2023-08-08 20:59:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8220 updates
2023-08-08 20:59:53 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt/checkpoint1.pt
2023-08-08 20:59:54 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt/checkpoint1.pt
2023-08-08 20:59:55 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt/checkpoint1.pt (epoch 1 @ 8220 updates, score None) (writing took 2.0703146199230105 seconds)
2023-08-08 20:59:55 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
2023-08-08 20:59:55 - progress_bar.py[line:282] - INFO: epoch 001 | loss 6.717 | loss_v1 0 | loss_v2 0 | nll_loss 5.682 | ntokens 338.262 | nsentences 47.999 | sample_size 338.262 | sample_size_v1 0 | sample_size_v2 0 | ppl 51.33 | wps 280.9 | ups 0.83 | wpb 338.3 | bsz 48 | num_updates 8220 | lr 1.59817e-05 | gnorm 0.168 | clip 0 | loss_scale 64 | train_wall 9878 | gb_free 14.5 | wall 9908
2023-08-08 20:59:55 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 row count 395175 total row count 395175
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-08-08 20:59:55 - trainer.py[line:703] - INFO: begin training epoch 2
2023-08-08 20:59:55 - train.py[line:305] - INFO: Start iterating over samples
2023-08-08 21:00:08 - progress_bar.py[line:272] - INFO: epoch 002:     10 / 8233 loss=4.807, loss_v1=0, loss_v2=0, nll_loss=3.528, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=11.53, wps=220.8, ups=0.66, wpb=334.5, bsz=48, num_updates=8230, lr=1.59623e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9921
2023-08-08 21:00:20 - progress_bar.py[line:272] - INFO: epoch 002:     20 / 8233 loss=4.855, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=284.8, ups=0.83, wpb=341.4, bsz=48, num_updates=8240, lr=1.59429e-05, gnorm=0.124, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9933
2023-08-08 21:00:32 - progress_bar.py[line:272] - INFO: epoch 002:     30 / 8233 loss=4.797, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=280.9, ups=0.83, wpb=338, bsz=48, num_updates=8250, lr=1.59235e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9945
2023-08-08 21:00:44 - progress_bar.py[line:272] - INFO: epoch 002:     40 / 8233 loss=4.801, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=279.9, ups=0.83, wpb=338, bsz=48, num_updates=8260, lr=1.59041e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9957
2023-08-08 21:00:56 - progress_bar.py[line:272] - INFO: epoch 002:     50 / 8233 loss=4.76, loss_v1=0, loss_v2=0, nll_loss=3.474, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=11.11, wps=277.5, ups=0.83, wpb=335.2, bsz=48, num_updates=8270, lr=1.58847e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9969
2023-08-08 21:01:08 - progress_bar.py[line:272] - INFO: epoch 002:     60 / 8233 loss=4.787, loss_v1=0, loss_v2=0, nll_loss=3.502, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=283.6, ups=0.83, wpb=340, bsz=48, num_updates=8280, lr=1.58654e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9981
2023-08-08 21:01:20 - progress_bar.py[line:272] - INFO: epoch 002:     70 / 8233 loss=4.778, loss_v1=0, loss_v2=0, nll_loss=3.494, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=11.27, wps=285.5, ups=0.84, wpb=339.7, bsz=48, num_updates=8290, lr=1.5846e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=9993
2023-08-08 21:01:32 - progress_bar.py[line:272] - INFO: epoch 002:     80 / 8233 loss=4.765, loss_v1=0, loss_v2=0, nll_loss=3.484, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=11.19, wps=283.1, ups=0.84, wpb=339, bsz=48, num_updates=8300, lr=1.58266e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10005
2023-08-08 21:01:44 - progress_bar.py[line:272] - INFO: epoch 002:     90 / 8233 loss=4.761, loss_v1=0, loss_v2=0, nll_loss=3.477, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=11.13, wps=277.9, ups=0.83, wpb=335.2, bsz=48, num_updates=8310, lr=1.58072e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10017
2023-08-08 21:01:56 - progress_bar.py[line:272] - INFO: epoch 002:    100 / 8233 loss=4.777, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=279.9, ups=0.83, wpb=337, bsz=48, num_updates=8320, lr=1.57878e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10029
2023-08-08 21:02:08 - progress_bar.py[line:272] - INFO: epoch 002:    110 / 8233 loss=4.757, loss_v1=0, loss_v2=0, nll_loss=3.478, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=279.5, ups=0.83, wpb=335.8, bsz=48, num_updates=8330, lr=1.57685e-05, gnorm=0.121, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10041
2023-08-08 21:02:20 - progress_bar.py[line:272] - INFO: epoch 002:    120 / 8233 loss=4.72, loss_v1=0, loss_v2=0, nll_loss=3.432, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=10.79, wps=281.6, ups=0.83, wpb=339.3, bsz=48, num_updates=8340, lr=1.57491e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10053
2023-08-08 21:02:32 - progress_bar.py[line:272] - INFO: epoch 002:    130 / 8233 loss=4.773, loss_v1=0, loss_v2=0, nll_loss=3.488, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=11.22, wps=280.6, ups=0.83, wpb=338.2, bsz=48, num_updates=8350, lr=1.57297e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10065
2023-08-08 21:02:44 - progress_bar.py[line:272] - INFO: epoch 002:    140 / 8233 loss=4.785, loss_v1=0, loss_v2=0, nll_loss=3.505, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=286.2, ups=0.84, wpb=342.3, bsz=48, num_updates=8360, lr=1.57103e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10077
2023-08-08 21:02:56 - progress_bar.py[line:272] - INFO: epoch 002:    150 / 8233 loss=4.772, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=283.2, ups=0.83, wpb=339.5, bsz=48, num_updates=8370, lr=1.56909e-05, gnorm=0.123, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10089
2023-08-08 21:03:08 - progress_bar.py[line:272] - INFO: epoch 002:    160 / 8233 loss=4.81, loss_v1=0, loss_v2=0, nll_loss=3.531, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=11.56, wps=277.5, ups=0.83, wpb=335.9, bsz=48, num_updates=8380, lr=1.56716e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10101
2023-08-08 21:03:20 - progress_bar.py[line:272] - INFO: epoch 002:    170 / 8233 loss=4.761, loss_v1=0, loss_v2=0, nll_loss=3.479, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=11.15, wps=280.4, ups=0.83, wpb=338.3, bsz=48, num_updates=8390, lr=1.56522e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10113
2023-08-08 21:03:32 - progress_bar.py[line:272] - INFO: epoch 002:    180 / 8233 loss=4.81, loss_v1=0, loss_v2=0, nll_loss=3.531, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=11.56, wps=279.1, ups=0.83, wpb=337.4, bsz=48, num_updates=8400, lr=1.56328e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10125
2023-08-08 21:03:44 - progress_bar.py[line:272] - INFO: epoch 002:    190 / 8233 loss=4.789, loss_v1=0, loss_v2=0, nll_loss=3.504, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=281.2, ups=0.83, wpb=337.3, bsz=48, num_updates=8410, lr=1.56134e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=10137
2023-08-08 21:03:56 - progress_bar.py[line:272] - INFO: epoch 002:    200 / 8233 loss=4.778, loss_v1=0, loss_v2=0, nll_loss=3.491, ntokens=343.3, nsentences=48, sample_size=343.3, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=288.1, ups=0.84, wpb=343.3, bsz=48, num_updates=8420, lr=1.5594e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10149
2023-08-08 21:04:08 - progress_bar.py[line:272] - INFO: epoch 002:    210 / 8233 loss=4.725, loss_v1=0, loss_v2=0, nll_loss=3.435, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.81, wps=279.6, ups=0.83, wpb=337.2, bsz=48, num_updates=8430, lr=1.55746e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10161
2023-08-08 21:04:21 - progress_bar.py[line:272] - INFO: epoch 002:    220 / 8233 loss=4.784, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=335.7, nsentences=48, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=278.2, ups=0.83, wpb=335.7, bsz=48, num_updates=8440, lr=1.55553e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10173
2023-08-08 21:04:33 - progress_bar.py[line:272] - INFO: epoch 002:    230 / 8233 loss=4.812, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=282.6, ups=0.83, wpb=339.4, bsz=48, num_updates=8450, lr=1.55359e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10185
2023-08-08 21:04:45 - progress_bar.py[line:272] - INFO: epoch 002:    240 / 8233 loss=4.761, loss_v1=0, loss_v2=0, nll_loss=3.48, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=11.16, wps=278.8, ups=0.83, wpb=337.3, bsz=48, num_updates=8460, lr=1.55165e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10198
2023-08-08 21:04:57 - progress_bar.py[line:272] - INFO: epoch 002:    250 / 8233 loss=4.769, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=11.23, wps=281.5, ups=0.83, wpb=338.9, bsz=48, num_updates=8470, lr=1.54971e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10210
2023-08-08 21:05:09 - progress_bar.py[line:272] - INFO: epoch 002:    260 / 8233 loss=4.734, loss_v1=0, loss_v2=0, nll_loss=3.444, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=10.88, wps=282.1, ups=0.83, wpb=338.2, bsz=48, num_updates=8480, lr=1.54777e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10222
2023-08-08 21:05:21 - progress_bar.py[line:272] - INFO: epoch 002:    270 / 8233 loss=4.767, loss_v1=0, loss_v2=0, nll_loss=3.482, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=11.17, wps=282.2, ups=0.83, wpb=338.8, bsz=48, num_updates=8490, lr=1.54584e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10234
2023-08-08 21:05:33 - progress_bar.py[line:272] - INFO: epoch 002:    280 / 8233 loss=4.785, loss_v1=0, loss_v2=0, nll_loss=3.509, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=281, ups=0.83, wpb=337, bsz=48, num_updates=8500, lr=1.5439e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10246
2023-08-08 21:05:45 - progress_bar.py[line:272] - INFO: epoch 002:    290 / 8233 loss=4.777, loss_v1=0, loss_v2=0, nll_loss=3.492, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=11.25, wps=279.1, ups=0.83, wpb=336.1, bsz=48, num_updates=8510, lr=1.54196e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10258
2023-08-08 21:05:57 - progress_bar.py[line:272] - INFO: epoch 002:    300 / 8233 loss=4.778, loss_v1=0, loss_v2=0, nll_loss=3.497, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=280.7, ups=0.83, wpb=338.8, bsz=48, num_updates=8520, lr=1.54002e-05, gnorm=0.118, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10270
2023-08-08 21:06:09 - progress_bar.py[line:272] - INFO: epoch 002:    310 / 8233 loss=4.782, loss_v1=0, loss_v2=0, nll_loss=3.504, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=281.8, ups=0.83, wpb=338.4, bsz=48, num_updates=8530, lr=1.53808e-05, gnorm=0.118, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10282
2023-08-08 21:06:21 - progress_bar.py[line:272] - INFO: epoch 002:    320 / 8233 loss=4.814, loss_v1=0, loss_v2=0, nll_loss=3.541, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=279.9, ups=0.83, wpb=337, bsz=48, num_updates=8540, lr=1.53615e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10294
2023-08-08 21:06:33 - progress_bar.py[line:272] - INFO: epoch 002:    330 / 8233 loss=4.805, loss_v1=0, loss_v2=0, nll_loss=3.526, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=11.52, wps=275.8, ups=0.82, wpb=334.5, bsz=48, num_updates=8550, lr=1.53421e-05, gnorm=0.122, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10306
2023-08-08 21:06:45 - progress_bar.py[line:272] - INFO: epoch 002:    340 / 8233 loss=4.719, loss_v1=0, loss_v2=0, nll_loss=3.429, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.77, wps=280.9, ups=0.83, wpb=337.2, bsz=48, num_updates=8560, lr=1.53227e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10318
2023-08-08 21:06:57 - progress_bar.py[line:272] - INFO: epoch 002:    350 / 8233 loss=4.783, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=280.7, ups=0.83, wpb=337.4, bsz=48, num_updates=8570, lr=1.53033e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10330
2023-08-08 21:07:09 - progress_bar.py[line:272] - INFO: epoch 002:    360 / 8233 loss=4.749, loss_v1=0, loss_v2=0, nll_loss=3.463, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=11.02, wps=276.1, ups=0.82, wpb=338.5, bsz=48, num_updates=8580, lr=1.52839e-05, gnorm=0.121, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10342
2023-08-08 21:07:22 - progress_bar.py[line:272] - INFO: epoch 002:    370 / 8233 loss=4.845, loss_v1=0, loss_v2=0, nll_loss=3.574, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=11.91, wps=274.1, ups=0.82, wpb=336, bsz=48, num_updates=8590, lr=1.52646e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10354
2023-08-08 21:07:34 - progress_bar.py[line:272] - INFO: epoch 002:    380 / 8233 loss=4.757, loss_v1=0, loss_v2=0, nll_loss=3.473, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=11.11, wps=282.7, ups=0.84, wpb=338.2, bsz=48, num_updates=8600, lr=1.52452e-05, gnorm=0.12, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10366
2023-08-08 21:07:46 - progress_bar.py[line:272] - INFO: epoch 002:    390 / 8233 loss=4.77, loss_v1=0, loss_v2=0, nll_loss=3.483, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=11.18, wps=280.8, ups=0.83, wpb=337.1, bsz=48, num_updates=8610, lr=1.52258e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10378
2023-08-08 21:07:58 - progress_bar.py[line:272] - INFO: epoch 002:    400 / 8233 loss=4.733, loss_v1=0, loss_v2=0, nll_loss=3.442, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=10.87, wps=279.4, ups=0.83, wpb=336.5, bsz=48, num_updates=8620, lr=1.52064e-05, gnorm=0.118, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10390
2023-08-08 21:08:09 - progress_bar.py[line:272] - INFO: epoch 002:    410 / 8233 loss=4.73, loss_v1=0, loss_v2=0, nll_loss=3.445, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=10.89, wps=283.7, ups=0.84, wpb=337.9, bsz=48, num_updates=8630, lr=1.5187e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10402
2023-08-08 21:08:22 - progress_bar.py[line:272] - INFO: epoch 002:    420 / 8233 loss=4.741, loss_v1=0, loss_v2=0, nll_loss=3.455, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=10.97, wps=280.8, ups=0.83, wpb=337.4, bsz=48, num_updates=8640, lr=1.51676e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10414
2023-08-08 21:08:34 - progress_bar.py[line:272] - INFO: epoch 002:    430 / 8233 loss=4.757, loss_v1=0, loss_v2=0, nll_loss=3.477, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.13, wps=279.6, ups=0.83, wpb=338, bsz=48, num_updates=8650, lr=1.51483e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10427
2023-08-08 21:08:46 - progress_bar.py[line:272] - INFO: epoch 002:    440 / 8233 loss=4.769, loss_v1=0, loss_v2=0, nll_loss=3.485, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.19, wps=283.8, ups=0.83, wpb=340, bsz=48, num_updates=8660, lr=1.51289e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10438
2023-08-08 21:08:58 - progress_bar.py[line:272] - INFO: epoch 002:    450 / 8233 loss=4.72, loss_v1=0, loss_v2=0, nll_loss=3.429, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=10.77, wps=275.8, ups=0.82, wpb=335.3, bsz=48, num_updates=8670, lr=1.51095e-05, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10451
2023-08-08 21:09:10 - progress_bar.py[line:272] - INFO: epoch 002:    460 / 8233 loss=4.712, loss_v1=0, loss_v2=0, nll_loss=3.428, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.77, wps=281.3, ups=0.83, wpb=337.2, bsz=48, num_updates=8680, lr=1.50901e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10463
2023-08-08 21:09:22 - progress_bar.py[line:272] - INFO: epoch 002:    470 / 8233 loss=4.752, loss_v1=0, loss_v2=0, nll_loss=3.459, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=11, wps=281.7, ups=0.83, wpb=338.3, bsz=48, num_updates=8690, lr=1.50707e-05, gnorm=0.118, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10475
2023-08-08 21:09:34 - progress_bar.py[line:272] - INFO: epoch 002:    480 / 8233 loss=4.702, loss_v1=0, loss_v2=0, nll_loss=3.406, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=10.6, wps=281.9, ups=0.83, wpb=337.9, bsz=48, num_updates=8700, lr=1.50514e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10487
2023-08-08 21:09:46 - progress_bar.py[line:272] - INFO: epoch 002:    490 / 8233 loss=4.765, loss_v1=0, loss_v2=0, nll_loss=3.485, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=11.2, wps=271.9, ups=0.81, wpb=336.8, bsz=48, num_updates=8710, lr=1.5032e-05, gnorm=0.121, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10499
2023-08-08 21:09:58 - progress_bar.py[line:272] - INFO: epoch 002:    500 / 8233 loss=4.775, loss_v1=0, loss_v2=0, nll_loss=3.496, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=281.7, ups=0.83, wpb=339.9, bsz=48, num_updates=8720, lr=1.50126e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10511
2023-08-08 21:10:10 - progress_bar.py[line:272] - INFO: epoch 002:    510 / 8233 loss=4.735, loss_v1=0, loss_v2=0, nll_loss=3.45, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=10.92, wps=286.2, ups=0.84, wpb=341.7, bsz=48, num_updates=8730, lr=1.49932e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10523
2023-08-08 21:10:22 - progress_bar.py[line:272] - INFO: epoch 002:    520 / 8233 loss=4.728, loss_v1=0, loss_v2=0, nll_loss=3.443, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=10.87, wps=282.2, ups=0.83, wpb=338.5, bsz=48, num_updates=8740, lr=1.49738e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10535
2023-08-08 21:10:34 - progress_bar.py[line:272] - INFO: epoch 002:    530 / 8233 loss=4.779, loss_v1=0, loss_v2=0, nll_loss=3.493, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=11.26, wps=280.6, ups=0.83, wpb=336.7, bsz=48, num_updates=8750, lr=1.49545e-05, gnorm=0.122, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10547
2023-08-08 21:10:46 - progress_bar.py[line:272] - INFO: epoch 002:    540 / 8233 loss=4.718, loss_v1=0, loss_v2=0, nll_loss=3.43, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=10.78, wps=282.2, ups=0.83, wpb=338.9, bsz=48, num_updates=8760, lr=1.49351e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10559
2023-08-08 21:10:58 - progress_bar.py[line:272] - INFO: epoch 002:    550 / 8233 loss=4.733, loss_v1=0, loss_v2=0, nll_loss=3.449, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=10.92, wps=284.2, ups=0.84, wpb=340.4, bsz=48, num_updates=8770, lr=1.49157e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10571
2023-08-08 21:11:10 - progress_bar.py[line:272] - INFO: epoch 002:    560 / 8233 loss=4.708, loss_v1=0, loss_v2=0, nll_loss=3.419, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=10.7, wps=279, ups=0.83, wpb=336.1, bsz=48, num_updates=8780, lr=1.48963e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10583
2023-08-08 21:11:22 - progress_bar.py[line:272] - INFO: epoch 002:    570 / 8233 loss=4.755, loss_v1=0, loss_v2=0, nll_loss=3.47, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=11.08, wps=285, ups=0.84, wpb=341.1, bsz=48, num_updates=8790, lr=1.48769e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10595
2023-08-08 21:11:34 - progress_bar.py[line:272] - INFO: epoch 002:    580 / 8233 loss=4.75, loss_v1=0, loss_v2=0, nll_loss=3.463, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=11.03, wps=280.9, ups=0.83, wpb=338.1, bsz=48, num_updates=8800, lr=1.48575e-05, gnorm=0.12, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10607
2023-08-08 21:11:46 - progress_bar.py[line:272] - INFO: epoch 002:    590 / 8233 loss=4.755, loss_v1=0, loss_v2=0, nll_loss=3.472, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.09, wps=282.4, ups=0.83, wpb=340, bsz=48, num_updates=8810, lr=1.48382e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10619
2023-08-08 21:11:58 - progress_bar.py[line:272] - INFO: epoch 002:    600 / 8233 loss=4.683, loss_v1=0, loss_v2=0, nll_loss=3.389, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=10.48, wps=276.4, ups=0.82, wpb=335.2, bsz=48, num_updates=8820, lr=1.48188e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10631
2023-08-08 21:12:10 - progress_bar.py[line:272] - INFO: epoch 002:    610 / 8233 loss=4.732, loss_v1=0, loss_v2=0, nll_loss=3.445, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=10.89, wps=280.8, ups=0.83, wpb=337.9, bsz=48, num_updates=8830, lr=1.47994e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10643
2023-08-08 21:12:22 - progress_bar.py[line:272] - INFO: epoch 002:    620 / 8233 loss=4.767, loss_v1=0, loss_v2=0, nll_loss=3.486, ntokens=342.2, nsentences=48, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=11.21, wps=286.2, ups=0.84, wpb=342.2, bsz=48, num_updates=8840, lr=1.478e-05, gnorm=0.12, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10655
2023-08-08 21:12:34 - progress_bar.py[line:272] - INFO: epoch 002:    630 / 8233 loss=4.775, loss_v1=0, loss_v2=0, nll_loss=3.494, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=11.27, wps=282.7, ups=0.83, wpb=339.4, bsz=48, num_updates=8850, lr=1.47606e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10667
2023-08-08 21:12:46 - progress_bar.py[line:272] - INFO: epoch 002:    640 / 8233 loss=4.768, loss_v1=0, loss_v2=0, nll_loss=3.481, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=11.16, wps=281.1, ups=0.83, wpb=338.2, bsz=48, num_updates=8860, lr=1.47413e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10679
2023-08-08 21:12:58 - progress_bar.py[line:272] - INFO: epoch 002:    650 / 8233 loss=4.748, loss_v1=0, loss_v2=0, nll_loss=3.469, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=11.07, wps=285.6, ups=0.84, wpb=340.2, bsz=48, num_updates=8870, lr=1.47219e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10691
2023-08-08 21:13:10 - progress_bar.py[line:272] - INFO: epoch 002:    660 / 8233 loss=4.743, loss_v1=0, loss_v2=0, nll_loss=3.459, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=11, wps=284.4, ups=0.84, wpb=339.9, bsz=48, num_updates=8880, lr=1.47025e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10703
2023-08-08 21:13:22 - progress_bar.py[line:272] - INFO: epoch 002:    670 / 8233 loss=4.772, loss_v1=0, loss_v2=0, nll_loss=3.491, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=11.25, wps=281.4, ups=0.83, wpb=338.1, bsz=48, num_updates=8890, lr=1.46831e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10715
2023-08-08 21:13:34 - progress_bar.py[line:272] - INFO: epoch 002:    680 / 8233 loss=4.75, loss_v1=0, loss_v2=0, nll_loss=3.465, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=11.04, wps=284.2, ups=0.84, wpb=340, bsz=48, num_updates=8900, lr=1.46637e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10727
2023-08-08 21:13:46 - progress_bar.py[line:272] - INFO: epoch 002:    690 / 8233 loss=4.756, loss_v1=0, loss_v2=0, nll_loss=3.463, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=11.03, wps=284.3, ups=0.84, wpb=337.8, bsz=48, num_updates=8910, lr=1.46444e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10739
2023-08-08 21:13:58 - progress_bar.py[line:272] - INFO: epoch 002:    700 / 8233 loss=4.704, loss_v1=0, loss_v2=0, nll_loss=3.412, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=10.65, wps=280.3, ups=0.84, wpb=335.5, bsz=48, num_updates=8920, lr=1.4625e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10751
2023-08-08 21:14:10 - progress_bar.py[line:272] - INFO: epoch 002:    710 / 8233 loss=4.746, loss_v1=0, loss_v2=0, nll_loss=3.463, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=11.03, wps=279.3, ups=0.83, wpb=335.9, bsz=48, num_updates=8930, lr=1.46056e-05, gnorm=0.115, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=10763
2023-08-08 21:14:22 - progress_bar.py[line:272] - INFO: epoch 002:    720 / 8233 loss=4.704, loss_v1=0, loss_v2=0, nll_loss=3.413, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=10.65, wps=284.8, ups=0.83, wpb=341.1, bsz=48, num_updates=8940, lr=1.45862e-05, gnorm=0.108, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=10775
2023-08-08 21:14:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-08-08 21:14:35 - progress_bar.py[line:272] - INFO: epoch 002:    731 / 8233 loss=4.757, loss_v1=0, loss_v2=0, nll_loss=3.471, ntokens=342.2, nsentences=48, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=11.09, wps=261.8, ups=0.77, wpb=342.2, bsz=48, num_updates=8950, lr=1.45668e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=13, gb_free=14.5, wall=10788
2023-08-08 21:14:47 - progress_bar.py[line:272] - INFO: epoch 002:    741 / 8233 loss=4.73, loss_v1=0, loss_v2=0, nll_loss=3.439, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=10.85, wps=285.5, ups=0.84, wpb=340.7, bsz=48, num_updates=8960, lr=1.45475e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10800
2023-08-08 21:14:59 - progress_bar.py[line:272] - INFO: epoch 002:    751 / 8233 loss=4.736, loss_v1=0, loss_v2=0, nll_loss=3.451, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=10.94, wps=279.9, ups=0.83, wpb=337, bsz=48, num_updates=8970, lr=1.45281e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10812
2023-08-08 21:15:11 - progress_bar.py[line:272] - INFO: epoch 002:    761 / 8233 loss=4.692, loss_v1=0, loss_v2=0, nll_loss=3.399, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=10.55, wps=283.9, ups=0.83, wpb=341.4, bsz=48, num_updates=8980, lr=1.45087e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10824
2023-08-08 21:15:23 - progress_bar.py[line:272] - INFO: epoch 002:    771 / 8233 loss=4.786, loss_v1=0, loss_v2=0, nll_loss=3.51, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=283.6, ups=0.84, wpb=339, bsz=48, num_updates=8990, lr=1.44893e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10836
2023-08-08 21:15:35 - progress_bar.py[line:272] - INFO: epoch 002:    781 / 8233 loss=4.718, loss_v1=0, loss_v2=0, nll_loss=3.437, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=10.83, wps=278.5, ups=0.83, wpb=336.9, bsz=48, num_updates=9000, lr=1.44699e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10848
2023-08-08 21:15:47 - progress_bar.py[line:272] - INFO: epoch 002:    791 / 8233 loss=4.699, loss_v1=0, loss_v2=0, nll_loss=3.405, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.59, wps=282.6, ups=0.83, wpb=338.7, bsz=48, num_updates=9010, lr=1.44505e-05, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10860
2023-08-08 21:15:59 - progress_bar.py[line:272] - INFO: epoch 002:    801 / 8233 loss=4.744, loss_v1=0, loss_v2=0, nll_loss=3.458, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=10.99, wps=283.9, ups=0.84, wpb=339.9, bsz=48, num_updates=9020, lr=1.44312e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10872
2023-08-08 21:16:11 - progress_bar.py[line:272] - INFO: epoch 002:    811 / 8233 loss=4.761, loss_v1=0, loss_v2=0, nll_loss=3.473, ntokens=332.6, nsentences=48, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=11.11, wps=274.2, ups=0.82, wpb=332.6, bsz=48, num_updates=9030, lr=1.44118e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10884
2023-08-08 21:16:23 - progress_bar.py[line:272] - INFO: epoch 002:    821 / 8233 loss=4.762, loss_v1=0, loss_v2=0, nll_loss=3.482, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=11.18, wps=280.7, ups=0.83, wpb=337.5, bsz=48, num_updates=9040, lr=1.43924e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10896
2023-08-08 21:16:35 - progress_bar.py[line:272] - INFO: epoch 002:    831 / 8233 loss=4.693, loss_v1=0, loss_v2=0, nll_loss=3.398, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=10.54, wps=279.8, ups=0.83, wpb=336.5, bsz=48, num_updates=9050, lr=1.4373e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10908
2023-08-08 21:16:47 - progress_bar.py[line:272] - INFO: epoch 002:    841 / 8233 loss=4.694, loss_v1=0, loss_v2=0, nll_loss=3.409, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=281, ups=0.83, wpb=338.2, bsz=48, num_updates=9060, lr=1.43536e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10920
2023-08-08 21:17:00 - progress_bar.py[line:272] - INFO: epoch 002:    851 / 8233 loss=4.723, loss_v1=0, loss_v2=0, nll_loss=3.44, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.85, wps=278.6, ups=0.83, wpb=336.4, bsz=48, num_updates=9070, lr=1.43343e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10932
2023-08-08 21:17:11 - progress_bar.py[line:272] - INFO: epoch 002:    861 / 8233 loss=4.758, loss_v1=0, loss_v2=0, nll_loss=3.478, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=285.9, ups=0.84, wpb=341.3, bsz=48, num_updates=9080, lr=1.43149e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10944
2023-08-08 21:17:23 - progress_bar.py[line:272] - INFO: epoch 002:    871 / 8233 loss=4.717, loss_v1=0, loss_v2=0, nll_loss=3.43, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=10.78, wps=286.3, ups=0.84, wpb=340.9, bsz=48, num_updates=9090, lr=1.42955e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10956
2023-08-08 21:17:35 - progress_bar.py[line:272] - INFO: epoch 002:    881 / 8233 loss=4.717, loss_v1=0, loss_v2=0, nll_loss=3.426, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.75, wps=280.5, ups=0.83, wpb=337.5, bsz=48, num_updates=9100, lr=1.42761e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10968
2023-08-08 21:17:47 - progress_bar.py[line:272] - INFO: epoch 002:    891 / 8233 loss=4.722, loss_v1=0, loss_v2=0, nll_loss=3.435, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=10.82, wps=283.2, ups=0.83, wpb=339.7, bsz=48, num_updates=9110, lr=1.42567e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10980
2023-08-08 21:17:59 - progress_bar.py[line:272] - INFO: epoch 002:    901 / 8233 loss=4.696, loss_v1=0, loss_v2=0, nll_loss=3.407, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=10.61, wps=278.6, ups=0.83, wpb=335.4, bsz=48, num_updates=9120, lr=1.42374e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=10992
2023-08-08 21:18:11 - progress_bar.py[line:272] - INFO: epoch 002:    911 / 8233 loss=4.738, loss_v1=0, loss_v2=0, nll_loss=3.452, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=10.94, wps=284.5, ups=0.84, wpb=339.4, bsz=48, num_updates=9130, lr=1.4218e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11004
2023-08-08 21:18:23 - progress_bar.py[line:272] - INFO: epoch 002:    921 / 8233 loss=4.724, loss_v1=0, loss_v2=0, nll_loss=3.437, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=10.83, wps=283.6, ups=0.84, wpb=338.8, bsz=48, num_updates=9140, lr=1.41986e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11016
2023-08-08 21:18:35 - progress_bar.py[line:272] - INFO: epoch 002:    931 / 8233 loss=4.711, loss_v1=0, loss_v2=0, nll_loss=3.421, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=10.71, wps=283.1, ups=0.84, wpb=338.1, bsz=48, num_updates=9150, lr=1.41792e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11028
2023-08-08 21:18:47 - progress_bar.py[line:272] - INFO: epoch 002:    941 / 8233 loss=4.731, loss_v1=0, loss_v2=0, nll_loss=3.441, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=10.86, wps=275.7, ups=0.83, wpb=334.2, bsz=48, num_updates=9160, lr=1.41598e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11040
2023-08-08 21:19:00 - progress_bar.py[line:272] - INFO: epoch 002:    951 / 8233 loss=4.708, loss_v1=0, loss_v2=0, nll_loss=3.414, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=10.66, wps=279, ups=0.83, wpb=337.3, bsz=48, num_updates=9170, lr=1.41404e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11052
2023-08-08 21:19:11 - progress_bar.py[line:272] - INFO: epoch 002:    961 / 8233 loss=4.724, loss_v1=0, loss_v2=0, nll_loss=3.433, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=10.8, wps=284.1, ups=0.84, wpb=339.4, bsz=48, num_updates=9180, lr=1.41211e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11064
2023-08-08 21:19:23 - progress_bar.py[line:272] - INFO: epoch 002:    971 / 8233 loss=4.699, loss_v1=0, loss_v2=0, nll_loss=3.405, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=10.59, wps=284, ups=0.84, wpb=338.4, bsz=48, num_updates=9190, lr=1.41017e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11076
2023-08-08 21:19:35 - progress_bar.py[line:272] - INFO: epoch 002:    981 / 8233 loss=4.691, loss_v1=0, loss_v2=0, nll_loss=3.396, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=10.53, wps=282.9, ups=0.83, wpb=338.9, bsz=48, num_updates=9200, lr=1.40823e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11088
2023-08-08 21:19:47 - progress_bar.py[line:272] - INFO: epoch 002:    991 / 8233 loss=4.741, loss_v1=0, loss_v2=0, nll_loss=3.454, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=10.96, wps=278.4, ups=0.83, wpb=336.7, bsz=48, num_updates=9210, lr=1.40629e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11100
2023-08-08 21:20:00 - progress_bar.py[line:272] - INFO: epoch 002:   1001 / 8233 loss=4.76, loss_v1=0, loss_v2=0, nll_loss=3.477, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=278.5, ups=0.83, wpb=336.5, bsz=48, num_updates=9220, lr=1.40435e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11112
2023-08-08 21:20:12 - progress_bar.py[line:272] - INFO: epoch 002:   1011 / 8233 loss=4.659, loss_v1=0, loss_v2=0, nll_loss=3.359, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=10.26, wps=280.4, ups=0.83, wpb=337.4, bsz=48, num_updates=9230, lr=1.40242e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11124
2023-08-08 21:20:24 - progress_bar.py[line:272] - INFO: epoch 002:   1021 / 8233 loss=4.728, loss_v1=0, loss_v2=0, nll_loss=3.447, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=10.91, wps=283.9, ups=0.83, wpb=340.6, bsz=48, num_updates=9240, lr=1.40048e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11136
2023-08-08 21:20:36 - progress_bar.py[line:272] - INFO: epoch 002:   1031 / 8233 loss=4.658, loss_v1=0, loss_v2=0, nll_loss=3.362, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=10.28, wps=284, ups=0.84, wpb=340.1, bsz=48, num_updates=9250, lr=1.39854e-05, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11148
2023-08-08 21:20:47 - progress_bar.py[line:272] - INFO: epoch 002:   1041 / 8233 loss=4.742, loss_v1=0, loss_v2=0, nll_loss=3.458, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=10.99, wps=282.8, ups=0.84, wpb=337.1, bsz=48, num_updates=9260, lr=1.3966e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11160
2023-08-08 21:20:59 - progress_bar.py[line:272] - INFO: epoch 002:   1051 / 8233 loss=4.72, loss_v1=0, loss_v2=0, nll_loss=3.426, ntokens=343.4, nsentences=48, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=10.75, wps=290.7, ups=0.85, wpb=343.4, bsz=48, num_updates=9270, lr=1.39466e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11172
2023-08-08 21:21:11 - progress_bar.py[line:272] - INFO: epoch 002:   1061 / 8233 loss=4.733, loss_v1=0, loss_v2=0, nll_loss=3.444, ntokens=341.6, nsentences=48, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=10.88, wps=285.3, ups=0.84, wpb=341.6, bsz=48, num_updates=9280, lr=1.39273e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11184
2023-08-08 21:21:23 - progress_bar.py[line:272] - INFO: epoch 002:   1071 / 8233 loss=4.747, loss_v1=0, loss_v2=0, nll_loss=3.464, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=11.04, wps=280.5, ups=0.83, wpb=338, bsz=48, num_updates=9290, lr=1.39079e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11196
2023-08-08 21:21:35 - progress_bar.py[line:272] - INFO: epoch 002:   1081 / 8233 loss=4.729, loss_v1=0, loss_v2=0, nll_loss=3.437, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=10.83, wps=282.7, ups=0.83, wpb=340.3, bsz=48, num_updates=9300, lr=1.38885e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11208
2023-08-08 21:21:47 - progress_bar.py[line:272] - INFO: epoch 002:   1091 / 8233 loss=4.727, loss_v1=0, loss_v2=0, nll_loss=3.438, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=10.84, wps=278.4, ups=0.83, wpb=335.2, bsz=48, num_updates=9310, lr=1.38691e-05, gnorm=0.119, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11220
2023-08-08 21:21:59 - progress_bar.py[line:272] - INFO: epoch 002:   1101 / 8233 loss=4.684, loss_v1=0, loss_v2=0, nll_loss=3.397, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=10.54, wps=286.9, ups=0.84, wpb=340.6, bsz=48, num_updates=9320, lr=1.38497e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11232
2023-08-08 21:22:11 - progress_bar.py[line:272] - INFO: epoch 002:   1111 / 8233 loss=4.652, loss_v1=0, loss_v2=0, nll_loss=3.359, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10.26, wps=286, ups=0.84, wpb=339, bsz=48, num_updates=9330, lr=1.38304e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11244
2023-08-08 21:22:23 - progress_bar.py[line:272] - INFO: epoch 002:   1121 / 8233 loss=4.703, loss_v1=0, loss_v2=0, nll_loss=3.408, ntokens=334.2, nsentences=48, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=277.5, ups=0.83, wpb=334.2, bsz=48, num_updates=9340, lr=1.3811e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11256
2023-08-08 21:22:35 - progress_bar.py[line:272] - INFO: epoch 002:   1131 / 8233 loss=4.693, loss_v1=0, loss_v2=0, nll_loss=3.404, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.58, wps=280.4, ups=0.83, wpb=337.2, bsz=48, num_updates=9350, lr=1.37916e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11268
2023-08-08 21:22:47 - progress_bar.py[line:272] - INFO: epoch 002:   1141 / 8233 loss=4.725, loss_v1=0, loss_v2=0, nll_loss=3.444, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=10.88, wps=279.4, ups=0.83, wpb=336.7, bsz=48, num_updates=9360, lr=1.37722e-05, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11280
2023-08-08 21:22:59 - progress_bar.py[line:272] - INFO: epoch 002:   1151 / 8233 loss=4.738, loss_v1=0, loss_v2=0, nll_loss=3.448, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=10.91, wps=284.2, ups=0.84, wpb=340.2, bsz=48, num_updates=9370, lr=1.37528e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11292
2023-08-08 21:23:11 - progress_bar.py[line:272] - INFO: epoch 002:   1161 / 8233 loss=4.698, loss_v1=0, loss_v2=0, nll_loss=3.404, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=10.58, wps=278.4, ups=0.83, wpb=336.7, bsz=48, num_updates=9380, lr=1.37334e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11304
2023-08-08 21:23:23 - progress_bar.py[line:272] - INFO: epoch 002:   1171 / 8233 loss=4.723, loss_v1=0, loss_v2=0, nll_loss=3.432, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=10.79, wps=284.3, ups=0.84, wpb=339.2, bsz=48, num_updates=9390, lr=1.37141e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11316
2023-08-08 21:23:35 - progress_bar.py[line:272] - INFO: epoch 002:   1181 / 8233 loss=4.68, loss_v1=0, loss_v2=0, nll_loss=3.384, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=10.44, wps=284.8, ups=0.84, wpb=340.7, bsz=48, num_updates=9400, lr=1.36947e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11328
2023-08-08 21:23:47 - progress_bar.py[line:272] - INFO: epoch 002:   1191 / 8233 loss=4.747, loss_v1=0, loss_v2=0, nll_loss=3.46, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=11, wps=286.3, ups=0.84, wpb=340.9, bsz=48, num_updates=9410, lr=1.36753e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11340
2023-08-08 21:23:59 - progress_bar.py[line:272] - INFO: epoch 002:   1201 / 8233 loss=4.735, loss_v1=0, loss_v2=0, nll_loss=3.449, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=10.92, wps=281.2, ups=0.84, wpb=334.7, bsz=48, num_updates=9420, lr=1.36559e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11352
2023-08-08 21:24:11 - progress_bar.py[line:272] - INFO: epoch 002:   1211 / 8233 loss=4.637, loss_v1=0, loss_v2=0, nll_loss=3.344, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=10.16, wps=285.2, ups=0.84, wpb=341.4, bsz=48, num_updates=9430, lr=1.36365e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11364
2023-08-08 21:24:23 - progress_bar.py[line:272] - INFO: epoch 002:   1221 / 8233 loss=4.728, loss_v1=0, loss_v2=0, nll_loss=3.436, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=10.82, wps=286.5, ups=0.84, wpb=340.4, bsz=48, num_updates=9440, lr=1.36172e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11376
2023-08-08 21:24:35 - progress_bar.py[line:272] - INFO: epoch 002:   1231 / 8233 loss=4.702, loss_v1=0, loss_v2=0, nll_loss=3.411, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10.63, wps=284.2, ups=0.84, wpb=339, bsz=48, num_updates=9450, lr=1.35978e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11388
2023-08-08 21:24:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-08-08 21:24:48 - progress_bar.py[line:272] - INFO: epoch 002:   1242 / 8233 loss=4.723, loss_v1=0, loss_v2=0, nll_loss=3.435, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=10.81, wps=256.2, ups=0.76, wpb=337.4, bsz=48, num_updates=9460, lr=1.35784e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=13, gb_free=14.5, wall=11401
2023-08-08 21:25:00 - progress_bar.py[line:272] - INFO: epoch 002:   1252 / 8233 loss=4.696, loss_v1=0, loss_v2=0, nll_loss=3.407, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=10.61, wps=281.5, ups=0.83, wpb=338.2, bsz=48, num_updates=9470, lr=1.3559e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11413
2023-08-08 21:25:12 - progress_bar.py[line:272] - INFO: epoch 002:   1262 / 8233 loss=4.728, loss_v1=0, loss_v2=0, nll_loss=3.438, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=10.84, wps=286.9, ups=0.84, wpb=340.9, bsz=48, num_updates=9480, lr=1.35396e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11425
2023-08-08 21:25:24 - progress_bar.py[line:272] - INFO: epoch 002:   1272 / 8233 loss=4.724, loss_v1=0, loss_v2=0, nll_loss=3.444, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.88, wps=281.5, ups=0.83, wpb=338.7, bsz=48, num_updates=9490, lr=1.35203e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11437
2023-08-08 21:25:36 - progress_bar.py[line:272] - INFO: epoch 002:   1282 / 8233 loss=4.735, loss_v1=0, loss_v2=0, nll_loss=3.451, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.94, wps=279.7, ups=0.83, wpb=337.5, bsz=48, num_updates=9500, lr=1.35009e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11449
2023-08-08 21:25:48 - progress_bar.py[line:272] - INFO: epoch 002:   1292 / 8233 loss=4.685, loss_v1=0, loss_v2=0, nll_loss=3.394, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=10.52, wps=281.2, ups=0.83, wpb=337.9, bsz=48, num_updates=9510, lr=1.34815e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11461
2023-08-08 21:26:00 - progress_bar.py[line:272] - INFO: epoch 002:   1302 / 8233 loss=4.708, loss_v1=0, loss_v2=0, nll_loss=3.424, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=10.73, wps=276.2, ups=0.82, wpb=335.1, bsz=48, num_updates=9520, lr=1.34621e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11473
2023-08-08 21:26:12 - progress_bar.py[line:272] - INFO: epoch 002:   1312 / 8233 loss=4.704, loss_v1=0, loss_v2=0, nll_loss=3.417, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.68, wps=285.4, ups=0.84, wpb=338.7, bsz=48, num_updates=9530, lr=1.34427e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11485
2023-08-08 21:26:24 - progress_bar.py[line:272] - INFO: epoch 002:   1322 / 8233 loss=4.728, loss_v1=0, loss_v2=0, nll_loss=3.442, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=10.87, wps=282.2, ups=0.83, wpb=339.1, bsz=48, num_updates=9540, lr=1.34233e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11497
2023-08-08 21:26:36 - progress_bar.py[line:272] - INFO: epoch 002:   1332 / 8233 loss=4.658, loss_v1=0, loss_v2=0, nll_loss=3.369, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=10.33, wps=282.5, ups=0.83, wpb=338.8, bsz=48, num_updates=9550, lr=1.3404e-05, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11509
2023-08-08 21:26:48 - progress_bar.py[line:272] - INFO: epoch 002:   1342 / 8233 loss=4.715, loss_v1=0, loss_v2=0, nll_loss=3.431, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=10.79, wps=275.4, ups=0.82, wpb=334.7, bsz=48, num_updates=9560, lr=1.33846e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11521
2023-08-08 21:27:00 - progress_bar.py[line:272] - INFO: epoch 002:   1352 / 8233 loss=4.697, loss_v1=0, loss_v2=0, nll_loss=3.407, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=10.61, wps=287.9, ups=0.85, wpb=339.8, bsz=48, num_updates=9570, lr=1.33652e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11533
2023-08-08 21:27:12 - progress_bar.py[line:272] - INFO: epoch 002:   1362 / 8233 loss=4.669, loss_v1=0, loss_v2=0, nll_loss=3.374, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=281.7, ups=0.84, wpb=336.8, bsz=48, num_updates=9580, lr=1.33458e-05, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11545
2023-08-08 21:27:24 - progress_bar.py[line:272] - INFO: epoch 002:   1372 / 8233 loss=4.653, loss_v1=0, loss_v2=0, nll_loss=3.361, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.27, wps=279.8, ups=0.83, wpb=338.7, bsz=48, num_updates=9590, lr=1.33264e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11557
2023-08-08 21:27:36 - progress_bar.py[line:272] - INFO: epoch 002:   1382 / 8233 loss=4.661, loss_v1=0, loss_v2=0, nll_loss=3.37, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=10.34, wps=284.3, ups=0.84, wpb=339.9, bsz=48, num_updates=9600, lr=1.33071e-05, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11569
2023-08-08 21:27:48 - progress_bar.py[line:272] - INFO: epoch 002:   1392 / 8233 loss=4.672, loss_v1=0, loss_v2=0, nll_loss=3.382, ntokens=343.1, nsentences=48, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=10.43, wps=287.8, ups=0.84, wpb=343.1, bsz=48, num_updates=9610, lr=1.32877e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11581
2023-08-08 21:28:00 - progress_bar.py[line:272] - INFO: epoch 002:   1402 / 8233 loss=4.682, loss_v1=0, loss_v2=0, nll_loss=3.392, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=10.5, wps=281.6, ups=0.83, wpb=339.2, bsz=48, num_updates=9620, lr=1.32683e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11593
2023-08-08 21:28:12 - progress_bar.py[line:272] - INFO: epoch 002:   1412 / 8233 loss=4.709, loss_v1=0, loss_v2=0, nll_loss=3.422, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=10.72, wps=283.4, ups=0.83, wpb=340, bsz=48, num_updates=9630, lr=1.32489e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11605
2023-08-08 21:28:24 - progress_bar.py[line:272] - INFO: epoch 002:   1422 / 8233 loss=4.71, loss_v1=0, loss_v2=0, nll_loss=3.422, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=10.72, wps=280.8, ups=0.83, wpb=338.2, bsz=48, num_updates=9640, lr=1.32295e-05, gnorm=0.118, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11617
2023-08-08 21:28:36 - progress_bar.py[line:272] - INFO: epoch 002:   1432 / 8233 loss=4.699, loss_v1=0, loss_v2=0, nll_loss=3.408, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=278.7, ups=0.83, wpb=336.6, bsz=48, num_updates=9650, lr=1.32102e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11629
2023-08-08 21:28:48 - progress_bar.py[line:272] - INFO: epoch 002:   1442 / 8233 loss=4.695, loss_v1=0, loss_v2=0, nll_loss=3.408, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=10.61, wps=277.9, ups=0.83, wpb=335.6, bsz=48, num_updates=9660, lr=1.31908e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11641
2023-08-08 21:29:00 - progress_bar.py[line:272] - INFO: epoch 002:   1452 / 8233 loss=4.681, loss_v1=0, loss_v2=0, nll_loss=3.391, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.49, wps=280.3, ups=0.83, wpb=337.2, bsz=48, num_updates=9670, lr=1.31714e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11653
2023-08-08 21:29:12 - progress_bar.py[line:272] - INFO: epoch 002:   1462 / 8233 loss=4.653, loss_v1=0, loss_v2=0, nll_loss=3.358, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=10.25, wps=280.6, ups=0.83, wpb=337.6, bsz=48, num_updates=9680, lr=1.3152e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11665
2023-08-08 21:29:24 - progress_bar.py[line:272] - INFO: epoch 002:   1472 / 8233 loss=4.697, loss_v1=0, loss_v2=0, nll_loss=3.409, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=284.4, ups=0.83, wpb=340.9, bsz=48, num_updates=9690, lr=1.31326e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11677
2023-08-08 21:29:36 - progress_bar.py[line:272] - INFO: epoch 002:   1482 / 8233 loss=4.68, loss_v1=0, loss_v2=0, nll_loss=3.385, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=10.44, wps=284.3, ups=0.84, wpb=340.1, bsz=48, num_updates=9700, lr=1.31133e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11689
2023-08-08 21:29:48 - progress_bar.py[line:272] - INFO: epoch 002:   1492 / 8233 loss=4.729, loss_v1=0, loss_v2=0, nll_loss=3.448, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=10.91, wps=279.5, ups=0.83, wpb=338.3, bsz=48, num_updates=9710, lr=1.30939e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11701
2023-08-08 21:30:00 - progress_bar.py[line:272] - INFO: epoch 002:   1502 / 8233 loss=4.693, loss_v1=0, loss_v2=0, nll_loss=3.403, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=10.58, wps=276.5, ups=0.82, wpb=335.3, bsz=48, num_updates=9720, lr=1.30745e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11713
2023-08-08 21:30:13 - progress_bar.py[line:272] - INFO: epoch 002:   1512 / 8233 loss=4.671, loss_v1=0, loss_v2=0, nll_loss=3.378, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=10.4, wps=278.9, ups=0.83, wpb=335.8, bsz=48, num_updates=9730, lr=1.30551e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11725
2023-08-08 21:30:25 - progress_bar.py[line:272] - INFO: epoch 002:   1522 / 8233 loss=4.681, loss_v1=0, loss_v2=0, nll_loss=3.388, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=10.47, wps=280.5, ups=0.83, wpb=336.8, bsz=48, num_updates=9740, lr=1.30357e-05, gnorm=0.118, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11737
2023-08-08 21:30:37 - progress_bar.py[line:272] - INFO: epoch 002:   1532 / 8233 loss=4.719, loss_v1=0, loss_v2=0, nll_loss=3.443, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=10.87, wps=282.1, ups=0.83, wpb=339.7, bsz=48, num_updates=9750, lr=1.30163e-05, gnorm=0.116, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11749
2023-08-08 21:30:49 - progress_bar.py[line:272] - INFO: epoch 002:   1542 / 8233 loss=4.66, loss_v1=0, loss_v2=0, nll_loss=3.362, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=10.28, wps=281.1, ups=0.83, wpb=338.3, bsz=48, num_updates=9760, lr=1.2997e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11762
2023-08-08 21:31:01 - progress_bar.py[line:272] - INFO: epoch 002:   1552 / 8233 loss=4.692, loss_v1=0, loss_v2=0, nll_loss=3.398, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.54, wps=278.5, ups=0.83, wpb=336.4, bsz=48, num_updates=9770, lr=1.29776e-05, gnorm=0.115, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11774
2023-08-08 21:31:13 - progress_bar.py[line:272] - INFO: epoch 002:   1562 / 8233 loss=4.713, loss_v1=0, loss_v2=0, nll_loss=3.427, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.75, wps=282, ups=0.83, wpb=338.7, bsz=48, num_updates=9780, lr=1.29582e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11786
2023-08-08 21:31:25 - progress_bar.py[line:272] - INFO: epoch 002:   1572 / 8233 loss=4.686, loss_v1=0, loss_v2=0, nll_loss=3.398, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=10.54, wps=282.8, ups=0.83, wpb=340.1, bsz=48, num_updates=9790, lr=1.29388e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11798
2023-08-08 21:31:37 - progress_bar.py[line:272] - INFO: epoch 002:   1582 / 8233 loss=4.674, loss_v1=0, loss_v2=0, nll_loss=3.38, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=10.41, wps=280.7, ups=0.83, wpb=337.7, bsz=48, num_updates=9800, lr=1.29194e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11810
2023-08-08 21:31:49 - progress_bar.py[line:272] - INFO: epoch 002:   1592 / 8233 loss=4.678, loss_v1=0, loss_v2=0, nll_loss=3.389, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=10.48, wps=281, ups=0.83, wpb=338.6, bsz=48, num_updates=9810, lr=1.29001e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11822
2023-08-08 21:32:01 - progress_bar.py[line:272] - INFO: epoch 002:   1602 / 8233 loss=4.691, loss_v1=0, loss_v2=0, nll_loss=3.396, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=10.53, wps=281.6, ups=0.83, wpb=337.9, bsz=48, num_updates=9820, lr=1.28807e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11834
2023-08-08 21:32:13 - progress_bar.py[line:272] - INFO: epoch 002:   1612 / 8233 loss=4.691, loss_v1=0, loss_v2=0, nll_loss=3.399, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=10.55, wps=285.5, ups=0.84, wpb=340.7, bsz=48, num_updates=9830, lr=1.28613e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11846
2023-08-08 21:32:25 - progress_bar.py[line:272] - INFO: epoch 002:   1622 / 8233 loss=4.705, loss_v1=0, loss_v2=0, nll_loss=3.419, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=10.69, wps=279.7, ups=0.83, wpb=336.7, bsz=48, num_updates=9840, lr=1.28419e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11858
2023-08-08 21:32:37 - progress_bar.py[line:272] - INFO: epoch 002:   1632 / 8233 loss=4.734, loss_v1=0, loss_v2=0, nll_loss=3.454, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=10.96, wps=284.2, ups=0.84, wpb=339.4, bsz=48, num_updates=9850, lr=1.28225e-05, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11870
2023-08-08 21:32:49 - progress_bar.py[line:272] - INFO: epoch 002:   1642 / 8233 loss=4.719, loss_v1=0, loss_v2=0, nll_loss=3.439, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=10.84, wps=284.8, ups=0.83, wpb=341.2, bsz=48, num_updates=9860, lr=1.28032e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11882
2023-08-08 21:33:01 - progress_bar.py[line:272] - INFO: epoch 002:   1652 / 8233 loss=4.669, loss_v1=0, loss_v2=0, nll_loss=3.374, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=285.4, ups=0.84, wpb=340.8, bsz=48, num_updates=9870, lr=1.27838e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11894
2023-08-08 21:33:13 - progress_bar.py[line:272] - INFO: epoch 002:   1662 / 8233 loss=4.713, loss_v1=0, loss_v2=0, nll_loss=3.426, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=10.75, wps=282.9, ups=0.83, wpb=339.1, bsz=48, num_updates=9880, lr=1.27644e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11906
2023-08-08 21:33:25 - progress_bar.py[line:272] - INFO: epoch 002:   1672 / 8233 loss=4.652, loss_v1=0, loss_v2=0, nll_loss=3.357, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=10.25, wps=286.3, ups=0.84, wpb=340.2, bsz=48, num_updates=9890, lr=1.2745e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11917
2023-08-08 21:33:37 - progress_bar.py[line:272] - INFO: epoch 002:   1682 / 8233 loss=4.702, loss_v1=0, loss_v2=0, nll_loss=3.413, ntokens=335.7, nsentences=48, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=10.65, wps=278.5, ups=0.83, wpb=335.7, bsz=48, num_updates=9900, lr=1.27256e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11930
2023-08-08 21:33:49 - progress_bar.py[line:272] - INFO: epoch 002:   1692 / 8233 loss=4.67, loss_v1=0, loss_v2=0, nll_loss=3.377, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=10.39, wps=283.5, ups=0.83, wpb=340.7, bsz=48, num_updates=9910, lr=1.27062e-05, gnorm=0.117, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11942
2023-08-08 21:34:01 - progress_bar.py[line:272] - INFO: epoch 002:   1702 / 8233 loss=4.652, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=280.7, ups=0.83, wpb=337.2, bsz=48, num_updates=9920, lr=1.26869e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11954
2023-08-08 21:34:13 - progress_bar.py[line:272] - INFO: epoch 002:   1712 / 8233 loss=4.67, loss_v1=0, loss_v2=0, nll_loss=3.38, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=10.41, wps=276.9, ups=0.82, wpb=336.1, bsz=48, num_updates=9930, lr=1.26675e-05, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11966
2023-08-08 21:34:25 - progress_bar.py[line:272] - INFO: epoch 002:   1722 / 8233 loss=4.702, loss_v1=0, loss_v2=0, nll_loss=3.416, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=10.67, wps=278.2, ups=0.83, wpb=336.5, bsz=48, num_updates=9940, lr=1.26481e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11978
2023-08-08 21:34:37 - progress_bar.py[line:272] - INFO: epoch 002:   1732 / 8233 loss=4.64, loss_v1=0, loss_v2=0, nll_loss=3.343, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=10.15, wps=280.7, ups=0.83, wpb=337.6, bsz=48, num_updates=9950, lr=1.26287e-05, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=11990
2023-08-08 21:34:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 21:34:50 - progress_bar.py[line:272] - INFO: epoch 002:   1743 / 8233 loss=4.671, loss_v1=0, loss_v2=0, nll_loss=3.378, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10.4, wps=257.8, ups=0.76, wpb=339, bsz=48, num_updates=9960, lr=1.26093e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=13, gb_free=14.5, wall=12003
2023-08-08 21:35:02 - progress_bar.py[line:272] - INFO: epoch 002:   1753 / 8233 loss=4.627, loss_v1=0, loss_v2=0, nll_loss=3.332, ntokens=341.8, nsentences=48, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=10.07, wps=286.3, ups=0.84, wpb=341.8, bsz=48, num_updates=9970, lr=1.259e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12015
2023-08-08 21:35:14 - progress_bar.py[line:272] - INFO: epoch 002:   1763 / 8233 loss=4.67, loss_v1=0, loss_v2=0, nll_loss=3.379, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=10.41, wps=279.5, ups=0.83, wpb=337.1, bsz=48, num_updates=9980, lr=1.25706e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12027
2023-08-08 21:35:26 - progress_bar.py[line:272] - INFO: epoch 002:   1773 / 8233 loss=4.681, loss_v1=0, loss_v2=0, nll_loss=3.384, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=10.44, wps=284.5, ups=0.84, wpb=340.4, bsz=48, num_updates=9990, lr=1.25512e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12039
2023-08-08 21:35:38 - progress_bar.py[line:272] - INFO: epoch 002:   1783 / 8233 loss=4.681, loss_v1=0, loss_v2=0, nll_loss=3.392, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=10.5, wps=284.1, ups=0.83, wpb=340.7, bsz=48, num_updates=10000, lr=1.25318e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12051
2023-08-08 21:35:50 - progress_bar.py[line:272] - INFO: epoch 002:   1793 / 8233 loss=4.715, loss_v1=0, loss_v2=0, nll_loss=3.432, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=10.79, wps=283.6, ups=0.84, wpb=339.4, bsz=48, num_updates=10010, lr=1.25124e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12063
2023-08-08 21:36:02 - progress_bar.py[line:272] - INFO: epoch 002:   1803 / 8233 loss=4.708, loss_v1=0, loss_v2=0, nll_loss=3.417, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=10.68, wps=282.4, ups=0.83, wpb=338.5, bsz=48, num_updates=10020, lr=1.24931e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12075
2023-08-08 21:36:14 - progress_bar.py[line:272] - INFO: epoch 002:   1813 / 8233 loss=4.609, loss_v1=0, loss_v2=0, nll_loss=3.314, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=9.95, wps=279.2, ups=0.83, wpb=336.5, bsz=48, num_updates=10030, lr=1.24737e-05, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12087
2023-08-08 21:36:26 - progress_bar.py[line:272] - INFO: epoch 002:   1823 / 8233 loss=4.675, loss_v1=0, loss_v2=0, nll_loss=3.388, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=10.47, wps=282.3, ups=0.84, wpb=338.1, bsz=48, num_updates=10040, lr=1.24543e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12099
2023-08-08 21:36:38 - progress_bar.py[line:272] - INFO: epoch 002:   1833 / 8233 loss=4.687, loss_v1=0, loss_v2=0, nll_loss=3.399, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=10.55, wps=286.4, ups=0.84, wpb=341.3, bsz=48, num_updates=10050, lr=1.24349e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12111
2023-08-08 21:36:50 - progress_bar.py[line:272] - INFO: epoch 002:   1843 / 8233 loss=4.645, loss_v1=0, loss_v2=0, nll_loss=3.349, ntokens=341.7, nsentences=48, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=10.19, wps=285.1, ups=0.83, wpb=341.7, bsz=48, num_updates=10060, lr=1.24155e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12123
2023-08-08 21:37:02 - progress_bar.py[line:272] - INFO: epoch 002:   1853 / 8233 loss=4.696, loss_v1=0, loss_v2=0, nll_loss=3.411, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=10.63, wps=282.7, ups=0.83, wpb=340, bsz=48, num_updates=10070, lr=1.23961e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12135
2023-08-08 21:37:14 - progress_bar.py[line:272] - INFO: epoch 002:   1863 / 8233 loss=4.641, loss_v1=0, loss_v2=0, nll_loss=3.345, ntokens=341.9, nsentences=48, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=10.16, wps=286.1, ups=0.84, wpb=341.9, bsz=48, num_updates=10080, lr=1.23768e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12147
2023-08-08 21:37:26 - progress_bar.py[line:272] - INFO: epoch 002:   1873 / 8233 loss=4.661, loss_v1=0, loss_v2=0, nll_loss=3.363, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=10.29, wps=280.7, ups=0.83, wpb=338, bsz=48, num_updates=10090, lr=1.23574e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12159
2023-08-08 21:37:38 - progress_bar.py[line:272] - INFO: epoch 002:   1883 / 8233 loss=4.653, loss_v1=0, loss_v2=0, nll_loss=3.358, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=10.25, wps=282, ups=0.83, wpb=338.8, bsz=48, num_updates=10100, lr=1.2338e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12171
2023-08-08 21:37:50 - progress_bar.py[line:272] - INFO: epoch 002:   1893 / 8233 loss=4.66, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=10.3, wps=282.5, ups=0.83, wpb=338.9, bsz=48, num_updates=10110, lr=1.23186e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12183
2023-08-08 21:38:02 - progress_bar.py[line:272] - INFO: epoch 002:   1903 / 8233 loss=4.648, loss_v1=0, loss_v2=0, nll_loss=3.353, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=286, ups=0.84, wpb=340.6, bsz=48, num_updates=10120, lr=1.22992e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12195
2023-08-08 21:38:14 - progress_bar.py[line:272] - INFO: epoch 002:   1913 / 8233 loss=4.693, loss_v1=0, loss_v2=0, nll_loss=3.407, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=10.61, wps=280.9, ups=0.83, wpb=338, bsz=48, num_updates=10130, lr=1.22799e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12207
2023-08-08 21:38:26 - progress_bar.py[line:272] - INFO: epoch 002:   1923 / 8233 loss=4.67, loss_v1=0, loss_v2=0, nll_loss=3.374, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=284.7, ups=0.84, wpb=340.7, bsz=48, num_updates=10140, lr=1.22605e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12219
2023-08-08 21:38:38 - progress_bar.py[line:272] - INFO: epoch 002:   1933 / 8233 loss=4.671, loss_v1=0, loss_v2=0, nll_loss=3.381, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.42, wps=282.3, ups=0.83, wpb=338.7, bsz=48, num_updates=10150, lr=1.22411e-05, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12231
2023-08-08 21:38:50 - progress_bar.py[line:272] - INFO: epoch 002:   1943 / 8233 loss=4.626, loss_v1=0, loss_v2=0, nll_loss=3.333, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=10.08, wps=285.1, ups=0.84, wpb=341.2, bsz=48, num_updates=10160, lr=1.22217e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12243
2023-08-08 21:39:02 - progress_bar.py[line:272] - INFO: epoch 002:   1953 / 8233 loss=4.672, loss_v1=0, loss_v2=0, nll_loss=3.384, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=10.44, wps=282.6, ups=0.83, wpb=338.5, bsz=48, num_updates=10170, lr=1.22023e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12255
2023-08-08 21:39:14 - progress_bar.py[line:272] - INFO: epoch 002:   1963 / 8233 loss=4.712, loss_v1=0, loss_v2=0, nll_loss=3.426, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=10.75, wps=279.3, ups=0.83, wpb=336.7, bsz=48, num_updates=10180, lr=1.2183e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12267
2023-08-08 21:39:26 - progress_bar.py[line:272] - INFO: epoch 002:   1973 / 8233 loss=4.663, loss_v1=0, loss_v2=0, nll_loss=3.367, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=281.2, ups=0.83, wpb=338, bsz=48, num_updates=10190, lr=1.21636e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12279
2023-08-08 21:39:38 - progress_bar.py[line:272] - INFO: epoch 002:   1983 / 8233 loss=4.648, loss_v1=0, loss_v2=0, nll_loss=3.352, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=279.6, ups=0.83, wpb=337.5, bsz=48, num_updates=10200, lr=1.21442e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12291
2023-08-08 21:39:50 - progress_bar.py[line:272] - INFO: epoch 002:   1993 / 8233 loss=4.688, loss_v1=0, loss_v2=0, nll_loss=3.396, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=10.53, wps=279.4, ups=0.83, wpb=336.8, bsz=48, num_updates=10210, lr=1.21248e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12303
2023-08-08 21:40:02 - progress_bar.py[line:272] - INFO: epoch 002:   2003 / 8233 loss=4.672, loss_v1=0, loss_v2=0, nll_loss=3.384, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=10.44, wps=287.8, ups=0.84, wpb=341.1, bsz=48, num_updates=10220, lr=1.21054e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12315
2023-08-08 21:40:14 - progress_bar.py[line:272] - INFO: epoch 002:   2013 / 8233 loss=4.676, loss_v1=0, loss_v2=0, nll_loss=3.382, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=10.42, wps=278, ups=0.83, wpb=335.9, bsz=48, num_updates=10230, lr=1.20861e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12327
2023-08-08 21:40:26 - progress_bar.py[line:272] - INFO: epoch 002:   2023 / 8233 loss=4.688, loss_v1=0, loss_v2=0, nll_loss=3.399, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=10.55, wps=282.7, ups=0.84, wpb=338.1, bsz=48, num_updates=10240, lr=1.20667e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12339
2023-08-08 21:40:38 - progress_bar.py[line:272] - INFO: epoch 002:   2033 / 8233 loss=4.632, loss_v1=0, loss_v2=0, nll_loss=3.339, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=10.12, wps=282.4, ups=0.83, wpb=339.5, bsz=48, num_updates=10250, lr=1.20473e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12351
2023-08-08 21:40:50 - progress_bar.py[line:272] - INFO: epoch 002:   2043 / 8233 loss=4.643, loss_v1=0, loss_v2=0, nll_loss=3.343, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=10.15, wps=280.6, ups=0.83, wpb=336.1, bsz=48, num_updates=10260, lr=1.20279e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12363
2023-08-08 21:41:02 - progress_bar.py[line:272] - INFO: epoch 002:   2053 / 8233 loss=4.671, loss_v1=0, loss_v2=0, nll_loss=3.378, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=10.39, wps=283.6, ups=0.83, wpb=340.5, bsz=48, num_updates=10270, lr=1.20085e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12375
2023-08-08 21:41:14 - progress_bar.py[line:272] - INFO: epoch 002:   2063 / 8233 loss=4.655, loss_v1=0, loss_v2=0, nll_loss=3.363, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.29, wps=281.4, ups=0.83, wpb=337.5, bsz=48, num_updates=10280, lr=1.19891e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12387
2023-08-08 21:41:26 - progress_bar.py[line:272] - INFO: epoch 002:   2073 / 8233 loss=4.649, loss_v1=0, loss_v2=0, nll_loss=3.352, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=281.6, ups=0.83, wpb=338.6, bsz=48, num_updates=10290, lr=1.19698e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12399
2023-08-08 21:41:38 - progress_bar.py[line:272] - INFO: epoch 002:   2083 / 8233 loss=4.677, loss_v1=0, loss_v2=0, nll_loss=3.385, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=10.45, wps=280, ups=0.83, wpb=337.8, bsz=48, num_updates=10300, lr=1.19504e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12411
2023-08-08 21:41:50 - progress_bar.py[line:272] - INFO: epoch 002:   2093 / 8233 loss=4.681, loss_v1=0, loss_v2=0, nll_loss=3.393, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.51, wps=280.9, ups=0.83, wpb=337.5, bsz=48, num_updates=10310, lr=1.1931e-05, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12423
2023-08-08 21:42:02 - progress_bar.py[line:272] - INFO: epoch 002:   2103 / 8233 loss=4.668, loss_v1=0, loss_v2=0, nll_loss=3.379, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=10.4, wps=280.4, ups=0.83, wpb=338.3, bsz=48, num_updates=10320, lr=1.19116e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12435
2023-08-08 21:42:14 - progress_bar.py[line:272] - INFO: epoch 002:   2113 / 8233 loss=4.664, loss_v1=0, loss_v2=0, nll_loss=3.373, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=10.36, wps=282.9, ups=0.84, wpb=338.8, bsz=48, num_updates=10330, lr=1.18922e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12447
2023-08-08 21:42:26 - progress_bar.py[line:272] - INFO: epoch 002:   2123 / 8233 loss=4.636, loss_v1=0, loss_v2=0, nll_loss=3.339, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=10.12, wps=281.1, ups=0.83, wpb=338.5, bsz=48, num_updates=10340, lr=1.18729e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12459
2023-08-08 21:42:38 - progress_bar.py[line:272] - INFO: epoch 002:   2133 / 8233 loss=4.665, loss_v1=0, loss_v2=0, nll_loss=3.376, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=10.38, wps=282.1, ups=0.83, wpb=338.5, bsz=48, num_updates=10350, lr=1.18535e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12471
2023-08-08 21:42:50 - progress_bar.py[line:272] - INFO: epoch 002:   2143 / 8233 loss=4.635, loss_v1=0, loss_v2=0, nll_loss=3.339, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=10.12, wps=284.9, ups=0.83, wpb=341.2, bsz=48, num_updates=10360, lr=1.18341e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12483
2023-08-08 21:43:02 - progress_bar.py[line:272] - INFO: epoch 002:   2153 / 8233 loss=4.651, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=280.1, ups=0.83, wpb=337, bsz=48, num_updates=10370, lr=1.18147e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12495
2023-08-08 21:43:14 - progress_bar.py[line:272] - INFO: epoch 002:   2163 / 8233 loss=4.703, loss_v1=0, loss_v2=0, nll_loss=3.419, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=10.7, wps=279.6, ups=0.83, wpb=336.7, bsz=48, num_updates=10380, lr=1.17953e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12507
2023-08-08 21:43:26 - progress_bar.py[line:272] - INFO: epoch 002:   2173 / 8233 loss=4.599, loss_v1=0, loss_v2=0, nll_loss=3.294, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=282.3, ups=0.83, wpb=339.2, bsz=48, num_updates=10390, lr=1.1776e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12519
2023-08-08 21:43:38 - progress_bar.py[line:272] - INFO: epoch 002:   2183 / 8233 loss=4.617, loss_v1=0, loss_v2=0, nll_loss=3.322, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=10, wps=281.7, ups=0.83, wpb=339.2, bsz=48, num_updates=10400, lr=1.17566e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12531
2023-08-08 21:43:50 - progress_bar.py[line:272] - INFO: epoch 002:   2193 / 8233 loss=4.636, loss_v1=0, loss_v2=0, nll_loss=3.342, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=10.14, wps=279.3, ups=0.83, wpb=336.8, bsz=48, num_updates=10410, lr=1.17372e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12543
2023-08-08 21:44:02 - progress_bar.py[line:272] - INFO: epoch 002:   2203 / 8233 loss=4.678, loss_v1=0, loss_v2=0, nll_loss=3.391, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=10.49, wps=281.1, ups=0.83, wpb=338.9, bsz=48, num_updates=10420, lr=1.17178e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12555
2023-08-08 21:44:15 - progress_bar.py[line:272] - INFO: epoch 002:   2213 / 8233 loss=4.634, loss_v1=0, loss_v2=0, nll_loss=3.337, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=10.11, wps=280, ups=0.83, wpb=338, bsz=48, num_updates=10430, lr=1.16984e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12567
2023-08-08 21:44:27 - progress_bar.py[line:272] - INFO: epoch 002:   2223 / 8233 loss=4.706, loss_v1=0, loss_v2=0, nll_loss=3.424, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=10.73, wps=276.2, ups=0.82, wpb=336.2, bsz=48, num_updates=10440, lr=1.1679e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12580
2023-08-08 21:44:39 - progress_bar.py[line:272] - INFO: epoch 002:   2233 / 8233 loss=4.63, loss_v1=0, loss_v2=0, nll_loss=3.337, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=10.11, wps=281.7, ups=0.83, wpb=338.9, bsz=48, num_updates=10450, lr=1.16597e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12592
2023-08-08 21:44:51 - progress_bar.py[line:272] - INFO: epoch 002:   2243 / 8233 loss=4.671, loss_v1=0, loss_v2=0, nll_loss=3.375, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=281.7, ups=0.83, wpb=338.3, bsz=48, num_updates=10460, lr=1.16403e-05, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12604
2023-08-08 21:45:03 - progress_bar.py[line:272] - INFO: epoch 002:   2253 / 8233 loss=4.658, loss_v1=0, loss_v2=0, nll_loss=3.366, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=282.6, ups=0.83, wpb=338.6, bsz=48, num_updates=10470, lr=1.16209e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12616
2023-08-08 21:45:15 - progress_bar.py[line:272] - INFO: epoch 002:   2263 / 8233 loss=4.713, loss_v1=0, loss_v2=0, nll_loss=3.435, ntokens=341.6, nsentences=48, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=10.81, wps=286.2, ups=0.84, wpb=341.6, bsz=48, num_updates=10480, lr=1.16015e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12628
2023-08-08 21:45:27 - progress_bar.py[line:272] - INFO: epoch 002:   2273 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.322, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=10, wps=277.2, ups=0.82, wpb=336.5, bsz=48, num_updates=10490, lr=1.15821e-05, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12640
2023-08-08 21:45:39 - progress_bar.py[line:272] - INFO: epoch 002:   2283 / 8233 loss=4.662, loss_v1=0, loss_v2=0, nll_loss=3.366, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=280.3, ups=0.83, wpb=339, bsz=48, num_updates=10500, lr=1.15628e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12652
2023-08-08 21:45:51 - progress_bar.py[line:272] - INFO: epoch 002:   2293 / 8233 loss=4.643, loss_v1=0, loss_v2=0, nll_loss=3.353, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.22, wps=279.8, ups=0.83, wpb=337.5, bsz=48, num_updates=10510, lr=1.15434e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12664
2023-08-08 21:46:03 - progress_bar.py[line:272] - INFO: epoch 002:   2303 / 8233 loss=4.667, loss_v1=0, loss_v2=0, nll_loss=3.376, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=10.38, wps=279.7, ups=0.83, wpb=338.1, bsz=48, num_updates=10520, lr=1.1524e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12676
2023-08-08 21:46:15 - progress_bar.py[line:272] - INFO: epoch 002:   2313 / 8233 loss=4.629, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=280.1, ups=0.83, wpb=338.3, bsz=48, num_updates=10530, lr=1.15046e-05, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12688
2023-08-08 21:46:27 - progress_bar.py[line:272] - INFO: epoch 002:   2323 / 8233 loss=4.657, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=10.3, wps=281.7, ups=0.83, wpb=338.2, bsz=48, num_updates=10540, lr=1.14852e-05, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=12700
2023-08-08 21:46:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 21:46:41 - progress_bar.py[line:272] - INFO: epoch 002:   2334 / 8233 loss=4.659, loss_v1=0, loss_v2=0, nll_loss=3.37, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=10.34, wps=253.4, ups=0.75, wpb=337.3, bsz=48, num_updates=10550, lr=1.14659e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=13, gb_free=14.5, wall=12713
2023-08-08 21:46:52 - progress_bar.py[line:272] - INFO: epoch 002:   2344 / 8233 loss=4.643, loss_v1=0, loss_v2=0, nll_loss=3.348, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=10.18, wps=285, ups=0.83, wpb=341.3, bsz=48, num_updates=10560, lr=1.14465e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12725
2023-08-08 21:47:05 - progress_bar.py[line:272] - INFO: epoch 002:   2354 / 8233 loss=4.687, loss_v1=0, loss_v2=0, nll_loss=3.399, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=10.55, wps=276.4, ups=0.82, wpb=335.3, bsz=48, num_updates=10570, lr=1.14271e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12738
2023-08-08 21:47:17 - progress_bar.py[line:272] - INFO: epoch 002:   2364 / 8233 loss=4.655, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=341.4, nsentences=48, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=284.4, ups=0.83, wpb=341.4, bsz=48, num_updates=10580, lr=1.14077e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12750
2023-08-08 21:47:29 - progress_bar.py[line:272] - INFO: epoch 002:   2374 / 8233 loss=4.656, loss_v1=0, loss_v2=0, nll_loss=3.371, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=10.35, wps=280.3, ups=0.83, wpb=336.1, bsz=48, num_updates=10590, lr=1.13883e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12762
2023-08-08 21:47:41 - progress_bar.py[line:272] - INFO: epoch 002:   2384 / 8233 loss=4.648, loss_v1=0, loss_v2=0, nll_loss=3.352, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=281.2, ups=0.83, wpb=337.4, bsz=48, num_updates=10600, lr=1.1369e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12774
2023-08-08 21:47:53 - progress_bar.py[line:272] - INFO: epoch 002:   2394 / 8233 loss=4.641, loss_v1=0, loss_v2=0, nll_loss=3.351, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.2, wps=282.9, ups=0.84, wpb=338.7, bsz=48, num_updates=10610, lr=1.13496e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12785
2023-08-08 21:48:05 - progress_bar.py[line:272] - INFO: epoch 002:   2404 / 8233 loss=4.706, loss_v1=0, loss_v2=0, nll_loss=3.413, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=10.65, wps=284.2, ups=0.84, wpb=339.1, bsz=48, num_updates=10620, lr=1.13302e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12797
2023-08-08 21:48:17 - progress_bar.py[line:272] - INFO: epoch 002:   2414 / 8233 loss=4.661, loss_v1=0, loss_v2=0, nll_loss=3.368, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.32, wps=279.6, ups=0.83, wpb=337.5, bsz=48, num_updates=10630, lr=1.13108e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12810
2023-08-08 21:48:29 - progress_bar.py[line:272] - INFO: epoch 002:   2424 / 8233 loss=4.605, loss_v1=0, loss_v2=0, nll_loss=3.309, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.91, wps=283.4, ups=0.84, wpb=338.6, bsz=48, num_updates=10640, lr=1.12914e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12821
2023-08-08 21:48:41 - progress_bar.py[line:272] - INFO: epoch 002:   2434 / 8233 loss=4.61, loss_v1=0, loss_v2=0, nll_loss=3.314, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=9.95, wps=279.2, ups=0.83, wpb=337.6, bsz=48, num_updates=10650, lr=1.1272e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12834
2023-08-08 21:48:53 - progress_bar.py[line:272] - INFO: epoch 002:   2444 / 8233 loss=4.638, loss_v1=0, loss_v2=0, nll_loss=3.336, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=10.1, wps=278.8, ups=0.83, wpb=336.8, bsz=48, num_updates=10660, lr=1.12527e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12846
2023-08-08 21:49:05 - progress_bar.py[line:272] - INFO: epoch 002:   2454 / 8233 loss=4.65, loss_v1=0, loss_v2=0, nll_loss=3.355, ntokens=334.9, nsentences=48, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=10.23, wps=277.6, ups=0.83, wpb=334.9, bsz=48, num_updates=10670, lr=1.12333e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12858
2023-08-08 21:49:17 - progress_bar.py[line:272] - INFO: epoch 002:   2464 / 8233 loss=4.606, loss_v1=0, loss_v2=0, nll_loss=3.31, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=9.92, wps=280, ups=0.83, wpb=336.6, bsz=48, num_updates=10680, lr=1.12139e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12870
2023-08-08 21:49:29 - progress_bar.py[line:272] - INFO: epoch 002:   2474 / 8233 loss=4.625, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=281.5, ups=0.83, wpb=338.5, bsz=48, num_updates=10690, lr=1.11945e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12882
2023-08-08 21:49:41 - progress_bar.py[line:272] - INFO: epoch 002:   2484 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.299, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=279.1, ups=0.83, wpb=338.3, bsz=48, num_updates=10700, lr=1.11751e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12894
2023-08-08 21:49:53 - progress_bar.py[line:272] - INFO: epoch 002:   2494 / 8233 loss=4.63, loss_v1=0, loss_v2=0, nll_loss=3.338, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=10.11, wps=279, ups=0.83, wpb=336.9, bsz=48, num_updates=10710, lr=1.11558e-05, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12906
2023-08-08 21:50:05 - progress_bar.py[line:272] - INFO: epoch 002:   2504 / 8233 loss=4.638, loss_v1=0, loss_v2=0, nll_loss=3.344, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=10.15, wps=280, ups=0.83, wpb=337.9, bsz=48, num_updates=10720, lr=1.11364e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12918
2023-08-08 21:50:17 - progress_bar.py[line:272] - INFO: epoch 002:   2514 / 8233 loss=4.634, loss_v1=0, loss_v2=0, nll_loss=3.34, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=10.12, wps=280.4, ups=0.83, wpb=336.7, bsz=48, num_updates=10730, lr=1.1117e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12930
2023-08-08 21:50:29 - progress_bar.py[line:272] - INFO: epoch 002:   2524 / 8233 loss=4.629, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=280, ups=0.83, wpb=336.2, bsz=48, num_updates=10740, lr=1.10976e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12942
2023-08-08 21:50:41 - progress_bar.py[line:272] - INFO: epoch 002:   2534 / 8233 loss=4.621, loss_v1=0, loss_v2=0, nll_loss=3.331, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=278, ups=0.83, wpb=336.2, bsz=48, num_updates=10750, lr=1.10782e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12954
2023-08-08 21:50:53 - progress_bar.py[line:272] - INFO: epoch 002:   2544 / 8233 loss=4.667, loss_v1=0, loss_v2=0, nll_loss=3.378, ntokens=342, nsentences=48, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=10.39, wps=285.1, ups=0.83, wpb=342, bsz=48, num_updates=10760, lr=1.10589e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12966
2023-08-08 21:51:05 - progress_bar.py[line:272] - INFO: epoch 002:   2554 / 8233 loss=4.635, loss_v1=0, loss_v2=0, nll_loss=3.342, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.14, wps=278.3, ups=0.83, wpb=336.4, bsz=48, num_updates=10770, lr=1.10395e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12978
2023-08-08 21:51:17 - progress_bar.py[line:272] - INFO: epoch 002:   2564 / 8233 loss=4.623, loss_v1=0, loss_v2=0, nll_loss=3.325, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=10.02, wps=282.3, ups=0.83, wpb=339.4, bsz=48, num_updates=10780, lr=1.10201e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=12990
2023-08-08 21:51:29 - progress_bar.py[line:272] - INFO: epoch 002:   2574 / 8233 loss=4.645, loss_v1=0, loss_v2=0, nll_loss=3.352, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=280.5, ups=0.83, wpb=337.8, bsz=48, num_updates=10790, lr=1.10007e-05, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13002
2023-08-08 21:51:41 - progress_bar.py[line:272] - INFO: epoch 002:   2584 / 8233 loss=4.628, loss_v1=0, loss_v2=0, nll_loss=3.338, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=10.11, wps=287.5, ups=0.84, wpb=340.3, bsz=48, num_updates=10800, lr=1.09813e-05, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13014
2023-08-08 21:51:53 - progress_bar.py[line:272] - INFO: epoch 002:   2594 / 8233 loss=4.702, loss_v1=0, loss_v2=0, nll_loss=3.418, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=10.69, wps=279.8, ups=0.83, wpb=336.6, bsz=48, num_updates=10810, lr=1.09619e-05, gnorm=0.117, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13026
2023-08-08 21:52:05 - progress_bar.py[line:272] - INFO: epoch 002:   2604 / 8233 loss=4.628, loss_v1=0, loss_v2=0, nll_loss=3.331, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=284.2, ups=0.84, wpb=340.2, bsz=48, num_updates=10820, lr=1.09426e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13038
2023-08-08 21:52:17 - progress_bar.py[line:272] - INFO: epoch 002:   2614 / 8233 loss=4.607, loss_v1=0, loss_v2=0, nll_loss=3.309, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=9.91, wps=279, ups=0.83, wpb=336.3, bsz=48, num_updates=10830, lr=1.09232e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13050
2023-08-08 21:52:29 - progress_bar.py[line:272] - INFO: epoch 002:   2624 / 8233 loss=4.65, loss_v1=0, loss_v2=0, nll_loss=3.358, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10.25, wps=282, ups=0.83, wpb=339, bsz=48, num_updates=10840, lr=1.09038e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13062
2023-08-08 21:52:41 - progress_bar.py[line:272] - INFO: epoch 002:   2634 / 8233 loss=4.629, loss_v1=0, loss_v2=0, nll_loss=3.337, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.11, wps=278.8, ups=0.83, wpb=336.4, bsz=48, num_updates=10850, lr=1.08844e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13074
2023-08-08 21:52:53 - progress_bar.py[line:272] - INFO: epoch 002:   2644 / 8233 loss=4.591, loss_v1=0, loss_v2=0, nll_loss=3.294, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=284.3, ups=0.84, wpb=340.4, bsz=48, num_updates=10860, lr=1.0865e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13086
2023-08-08 21:53:05 - progress_bar.py[line:272] - INFO: epoch 002:   2654 / 8233 loss=4.652, loss_v1=0, loss_v2=0, nll_loss=3.352, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=280, ups=0.83, wpb=337.2, bsz=48, num_updates=10870, lr=1.08457e-05, gnorm=0.118, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13098
2023-08-08 21:53:17 - progress_bar.py[line:272] - INFO: epoch 002:   2664 / 8233 loss=4.654, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=280.5, ups=0.83, wpb=336.9, bsz=48, num_updates=10880, lr=1.08263e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13110
2023-08-08 21:53:29 - progress_bar.py[line:272] - INFO: epoch 002:   2674 / 8233 loss=4.66, loss_v1=0, loss_v2=0, nll_loss=3.367, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=10.32, wps=282.6, ups=0.83, wpb=338.8, bsz=48, num_updates=10890, lr=1.08069e-05, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13122
2023-08-08 21:53:41 - progress_bar.py[line:272] - INFO: epoch 002:   2684 / 8233 loss=4.614, loss_v1=0, loss_v2=0, nll_loss=3.321, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.99, wps=281.5, ups=0.83, wpb=338, bsz=48, num_updates=10900, lr=1.07875e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13134
2023-08-08 21:53:54 - progress_bar.py[line:272] - INFO: epoch 002:   2694 / 8233 loss=4.614, loss_v1=0, loss_v2=0, nll_loss=3.323, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=10, wps=279.9, ups=0.83, wpb=337.6, bsz=48, num_updates=10910, lr=1.07681e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13146
2023-08-08 21:54:06 - progress_bar.py[line:272] - INFO: epoch 002:   2704 / 8233 loss=4.648, loss_v1=0, loss_v2=0, nll_loss=3.355, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=10.23, wps=281.4, ups=0.83, wpb=339.1, bsz=48, num_updates=10920, lr=1.07488e-05, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13158
2023-08-08 21:54:17 - progress_bar.py[line:272] - INFO: epoch 002:   2714 / 8233 loss=4.655, loss_v1=0, loss_v2=0, nll_loss=3.366, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=286.4, ups=0.84, wpb=340.8, bsz=48, num_updates=10930, lr=1.07294e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13170
2023-08-08 21:54:30 - progress_bar.py[line:272] - INFO: epoch 002:   2724 / 8233 loss=4.658, loss_v1=0, loss_v2=0, nll_loss=3.367, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=10.32, wps=279.4, ups=0.83, wpb=336.5, bsz=48, num_updates=10940, lr=1.071e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13182
2023-08-08 21:54:42 - progress_bar.py[line:272] - INFO: epoch 002:   2734 / 8233 loss=4.616, loss_v1=0, loss_v2=0, nll_loss=3.317, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.97, wps=283, ups=0.83, wpb=340.4, bsz=48, num_updates=10950, lr=1.06906e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13194
2023-08-08 21:54:53 - progress_bar.py[line:272] - INFO: epoch 002:   2744 / 8233 loss=4.621, loss_v1=0, loss_v2=0, nll_loss=3.328, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=10.04, wps=285, ups=0.84, wpb=339.8, bsz=48, num_updates=10960, lr=1.06712e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13206
2023-08-08 21:55:05 - progress_bar.py[line:272] - INFO: epoch 002:   2754 / 8233 loss=4.67, loss_v1=0, loss_v2=0, nll_loss=3.382, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=10.42, wps=283.6, ups=0.83, wpb=340.1, bsz=48, num_updates=10970, lr=1.06519e-05, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13218
2023-08-08 21:55:18 - progress_bar.py[line:272] - INFO: epoch 002:   2764 / 8233 loss=4.664, loss_v1=0, loss_v2=0, nll_loss=3.375, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=278.6, ups=0.83, wpb=335.8, bsz=48, num_updates=10980, lr=1.06325e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13230
2023-08-08 21:55:30 - progress_bar.py[line:272] - INFO: epoch 002:   2774 / 8233 loss=4.629, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=282.1, ups=0.83, wpb=338.1, bsz=48, num_updates=10990, lr=1.06131e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13242
2023-08-08 21:55:42 - progress_bar.py[line:272] - INFO: epoch 002:   2784 / 8233 loss=4.614, loss_v1=0, loss_v2=0, nll_loss=3.319, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.98, wps=281.3, ups=0.83, wpb=338.4, bsz=48, num_updates=11000, lr=1.05937e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13254
2023-08-08 21:55:54 - progress_bar.py[line:272] - INFO: epoch 002:   2794 / 8233 loss=4.585, loss_v1=0, loss_v2=0, nll_loss=3.285, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=281.8, ups=0.83, wpb=338.9, bsz=48, num_updates=11010, lr=1.05743e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13266
2023-08-08 21:56:06 - progress_bar.py[line:272] - INFO: epoch 002:   2804 / 8233 loss=4.649, loss_v1=0, loss_v2=0, nll_loss=3.364, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=10.3, wps=279.1, ups=0.83, wpb=336.1, bsz=48, num_updates=11020, lr=1.05549e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13279
2023-08-08 21:56:18 - progress_bar.py[line:272] - INFO: epoch 002:   2814 / 8233 loss=4.635, loss_v1=0, loss_v2=0, nll_loss=3.342, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=10.14, wps=280.2, ups=0.83, wpb=337.4, bsz=48, num_updates=11030, lr=1.05356e-05, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13291
2023-08-08 21:56:30 - progress_bar.py[line:272] - INFO: epoch 002:   2824 / 8233 loss=4.653, loss_v1=0, loss_v2=0, nll_loss=3.37, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=10.34, wps=278.3, ups=0.83, wpb=335.5, bsz=48, num_updates=11040, lr=1.05162e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13303
2023-08-08 21:56:42 - progress_bar.py[line:272] - INFO: epoch 002:   2834 / 8233 loss=4.626, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=277.3, ups=0.83, wpb=336, bsz=48, num_updates=11050, lr=1.04968e-05, gnorm=0.115, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13315
2023-08-08 21:56:54 - progress_bar.py[line:272] - INFO: epoch 002:   2844 / 8233 loss=4.613, loss_v1=0, loss_v2=0, nll_loss=3.312, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.93, wps=282.4, ups=0.83, wpb=339.3, bsz=48, num_updates=11060, lr=1.04774e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=13327
2023-08-08 21:57:06 - progress_bar.py[line:272] - INFO: epoch 002:   2854 / 8233 loss=4.661, loss_v1=0, loss_v2=0, nll_loss=3.372, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=10.35, wps=276.7, ups=0.83, wpb=334.7, bsz=48, num_updates=11070, lr=1.0458e-05, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=13339
2023-08-08 21:57:18 - progress_bar.py[line:272] - INFO: epoch 002:   2864 / 8233 loss=4.619, loss_v1=0, loss_v2=0, nll_loss=3.323, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=10.01, wps=280.7, ups=0.83, wpb=337.1, bsz=48, num_updates=11080, lr=1.04387e-05, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=13351
2023-08-08 21:57:30 - progress_bar.py[line:272] - INFO: epoch 002:   2874 / 8233 loss=4.619, loss_v1=0, loss_v2=0, nll_loss=3.321, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=10, wps=278, ups=0.83, wpb=335.5, bsz=48, num_updates=11090, lr=1.04193e-05, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=13363
2023-08-08 21:57:42 - progress_bar.py[line:272] - INFO: epoch 002:   2884 / 8233 loss=4.64, loss_v1=0, loss_v2=0, nll_loss=3.344, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.15, wps=280.5, ups=0.83, wpb=336.4, bsz=48, num_updates=11100, lr=1.03999e-05, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=13375
2023-08-08 21:57:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 21:57:55 - progress_bar.py[line:272] - INFO: epoch 002:   2895 / 8233 loss=4.619, loss_v1=0, loss_v2=0, nll_loss=3.324, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.02, wps=255.9, ups=0.76, wpb=336.4, bsz=48, num_updates=11110, lr=1.03805e-05, gnorm=0.113, clip=0, loss_scale=64, train_wall=13, gb_free=14.5, wall=13388
2023-08-08 21:58:07 - progress_bar.py[line:272] - INFO: epoch 002:   2905 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.322, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=10, wps=282.9, ups=0.84, wpb=337.8, bsz=48, num_updates=11120, lr=1.03611e-05, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13400
2023-08-08 21:58:19 - progress_bar.py[line:272] - INFO: epoch 002:   2915 / 8233 loss=4.639, loss_v1=0, loss_v2=0, nll_loss=3.348, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=10.18, wps=282.9, ups=0.84, wpb=338.5, bsz=48, num_updates=11130, lr=1.03418e-05, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13412
2023-08-08 21:58:31 - progress_bar.py[line:272] - INFO: epoch 002:   2925 / 8233 loss=4.562, loss_v1=0, loss_v2=0, nll_loss=3.257, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=281.6, ups=0.83, wpb=338.5, bsz=48, num_updates=11140, lr=1.03224e-05, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13424
2023-08-08 21:58:43 - progress_bar.py[line:272] - INFO: epoch 002:   2935 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.324, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=10.02, wps=282.4, ups=0.83, wpb=338.6, bsz=48, num_updates=11150, lr=1.0303e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13436
2023-08-08 21:58:55 - progress_bar.py[line:272] - INFO: epoch 002:   2945 / 8233 loss=4.623, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=284.3, ups=0.83, wpb=340.8, bsz=48, num_updates=11160, lr=1.02836e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13448
2023-08-08 21:59:07 - progress_bar.py[line:272] - INFO: epoch 002:   2955 / 8233 loss=4.638, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=280.7, ups=0.83, wpb=337.3, bsz=48, num_updates=11170, lr=1.02642e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13460
2023-08-08 21:59:19 - progress_bar.py[line:272] - INFO: epoch 002:   2965 / 8233 loss=4.626, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=10.05, wps=283.5, ups=0.83, wpb=339.7, bsz=48, num_updates=11180, lr=1.02448e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13472
2023-08-08 21:59:31 - progress_bar.py[line:272] - INFO: epoch 002:   2975 / 8233 loss=4.636, loss_v1=0, loss_v2=0, nll_loss=3.345, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=10.16, wps=285.5, ups=0.84, wpb=340.9, bsz=48, num_updates=11190, lr=1.02255e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13484
2023-08-08 21:59:43 - progress_bar.py[line:272] - INFO: epoch 002:   2985 / 8233 loss=4.617, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=281.9, ups=0.83, wpb=338.5, bsz=48, num_updates=11200, lr=1.02061e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13496
2023-08-08 21:59:55 - progress_bar.py[line:272] - INFO: epoch 002:   2995 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.297, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.83, wps=280.5, ups=0.83, wpb=337.5, bsz=48, num_updates=11210, lr=1.01867e-05, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13508
2023-08-08 22:00:07 - progress_bar.py[line:272] - INFO: epoch 002:   3005 / 8233 loss=4.59, loss_v1=0, loss_v2=0, nll_loss=3.292, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=281.2, ups=0.83, wpb=338.9, bsz=48, num_updates=11220, lr=1.01673e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13520
2023-08-08 22:00:19 - progress_bar.py[line:272] - INFO: epoch 002:   3015 / 8233 loss=4.662, loss_v1=0, loss_v2=0, nll_loss=3.371, ntokens=334, nsentences=48, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=10.34, wps=275.3, ups=0.82, wpb=334, bsz=48, num_updates=11230, lr=1.01479e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13532
2023-08-08 22:00:31 - progress_bar.py[line:272] - INFO: epoch 002:   3025 / 8233 loss=4.647, loss_v1=0, loss_v2=0, nll_loss=3.357, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=283.6, ups=0.84, wpb=339, bsz=48, num_updates=11240, lr=1.01286e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13544
2023-08-08 22:00:43 - progress_bar.py[line:272] - INFO: epoch 002:   3035 / 8233 loss=4.645, loss_v1=0, loss_v2=0, nll_loss=3.358, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=10.26, wps=284.1, ups=0.84, wpb=339.8, bsz=48, num_updates=11250, lr=1.01092e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13556
2023-08-08 22:00:55 - progress_bar.py[line:272] - INFO: epoch 002:   3045 / 8233 loss=4.63, loss_v1=0, loss_v2=0, nll_loss=3.34, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=10.13, wps=279.6, ups=0.83, wpb=337.2, bsz=48, num_updates=11260, lr=1.00898e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13568
2023-08-08 22:01:07 - progress_bar.py[line:272] - INFO: epoch 002:   3055 / 8233 loss=4.662, loss_v1=0, loss_v2=0, nll_loss=3.369, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=10.33, wps=281, ups=0.83, wpb=337.1, bsz=48, num_updates=11270, lr=1.00704e-05, gnorm=0.116, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13580
2023-08-08 22:01:19 - progress_bar.py[line:272] - INFO: epoch 002:   3065 / 8233 loss=4.658, loss_v1=0, loss_v2=0, nll_loss=3.374, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=280.2, ups=0.83, wpb=336.8, bsz=48, num_updates=11280, lr=1.0051e-05, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13592
2023-08-08 22:01:31 - progress_bar.py[line:272] - INFO: epoch 002:   3075 / 8233 loss=4.595, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=281.8, ups=0.83, wpb=338.4, bsz=48, num_updates=11290, lr=1.00317e-05, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13604
2023-08-08 22:01:43 - progress_bar.py[line:272] - INFO: epoch 002:   3085 / 8233 loss=4.596, loss_v1=0, loss_v2=0, nll_loss=3.301, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=9.86, wps=279.1, ups=0.83, wpb=336.4, bsz=48, num_updates=11300, lr=1.00123e-05, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13616
2023-08-08 22:01:55 - progress_bar.py[line:272] - INFO: epoch 002:   3095 / 8233 loss=4.578, loss_v1=0, loss_v2=0, nll_loss=3.28, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.72, wps=284.8, ups=0.84, wpb=340.9, bsz=48, num_updates=11310, lr=9.99289e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13628
2023-08-08 22:02:07 - progress_bar.py[line:272] - INFO: epoch 002:   3105 / 8233 loss=4.615, loss_v1=0, loss_v2=0, nll_loss=3.325, ntokens=344.8, nsentences=48, sample_size=344.8, sample_size_v1=0, sample_size_v2=0, ppl=10.02, wps=291, ups=0.84, wpb=344.8, bsz=48, num_updates=11320, lr=9.97351e-06, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13640
2023-08-08 22:02:19 - progress_bar.py[line:272] - INFO: epoch 002:   3115 / 8233 loss=4.575, loss_v1=0, loss_v2=0, nll_loss=3.272, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=279.5, ups=0.83, wpb=337.7, bsz=48, num_updates=11330, lr=9.95413e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13652
2023-08-08 22:02:31 - progress_bar.py[line:272] - INFO: epoch 002:   3125 / 8233 loss=4.611, loss_v1=0, loss_v2=0, nll_loss=3.317, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.97, wps=284.2, ups=0.83, wpb=340.4, bsz=48, num_updates=11340, lr=9.93475e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13664
2023-08-08 22:02:43 - progress_bar.py[line:272] - INFO: epoch 002:   3135 / 8233 loss=4.64, loss_v1=0, loss_v2=0, nll_loss=3.35, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=10.2, wps=281.9, ups=0.83, wpb=338.6, bsz=48, num_updates=11350, lr=9.91537e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13676
2023-08-08 22:02:55 - progress_bar.py[line:272] - INFO: epoch 002:   3145 / 8233 loss=4.642, loss_v1=0, loss_v2=0, nll_loss=3.347, ntokens=333.5, nsentences=48, sample_size=333.5, sample_size_v1=0, sample_size_v2=0, ppl=10.18, wps=275, ups=0.82, wpb=333.5, bsz=48, num_updates=11360, lr=9.89599e-06, gnorm=0.113, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13688
2023-08-08 22:03:07 - progress_bar.py[line:272] - INFO: epoch 002:   3155 / 8233 loss=4.607, loss_v1=0, loss_v2=0, nll_loss=3.307, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=9.9, wps=281.2, ups=0.83, wpb=337.6, bsz=48, num_updates=11370, lr=9.87661e-06, gnorm=0.119, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13700
2023-08-08 22:03:19 - progress_bar.py[line:272] - INFO: epoch 002:   3165 / 8233 loss=4.642, loss_v1=0, loss_v2=0, nll_loss=3.345, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=10.16, wps=284.7, ups=0.84, wpb=340.2, bsz=48, num_updates=11380, lr=9.85723e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13712
2023-08-08 22:03:31 - progress_bar.py[line:272] - INFO: epoch 002:   3175 / 8233 loss=4.642, loss_v1=0, loss_v2=0, nll_loss=3.352, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=281.5, ups=0.83, wpb=338.1, bsz=48, num_updates=11390, lr=9.83784e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13724
2023-08-08 22:03:43 - progress_bar.py[line:272] - INFO: epoch 002:   3185 / 8233 loss=4.602, loss_v1=0, loss_v2=0, nll_loss=3.312, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=9.93, wps=280.6, ups=0.83, wpb=337.3, bsz=48, num_updates=11400, lr=9.81846e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13736
2023-08-08 22:03:55 - progress_bar.py[line:272] - INFO: epoch 002:   3195 / 8233 loss=4.592, loss_v1=0, loss_v2=0, nll_loss=3.296, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=281.3, ups=0.83, wpb=339, bsz=48, num_updates=11410, lr=9.79908e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13748
2023-08-08 22:04:07 - progress_bar.py[line:272] - INFO: epoch 002:   3205 / 8233 loss=4.648, loss_v1=0, loss_v2=0, nll_loss=3.358, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=10.25, wps=281.7, ups=0.83, wpb=338.3, bsz=48, num_updates=11420, lr=9.7797e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13760
2023-08-08 22:04:19 - progress_bar.py[line:272] - INFO: epoch 002:   3215 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.3, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=285.6, ups=0.84, wpb=340.3, bsz=48, num_updates=11430, lr=9.76032e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13772
2023-08-08 22:04:31 - progress_bar.py[line:272] - INFO: epoch 002:   3225 / 8233 loss=4.641, loss_v1=0, loss_v2=0, nll_loss=3.351, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=281.4, ups=0.83, wpb=338.4, bsz=48, num_updates=11440, lr=9.74094e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13784
2023-08-08 22:04:43 - progress_bar.py[line:272] - INFO: epoch 002:   3235 / 8233 loss=4.617, loss_v1=0, loss_v2=0, nll_loss=3.323, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=10.01, wps=280.8, ups=0.83, wpb=337.4, bsz=48, num_updates=11450, lr=9.72156e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13796
2023-08-08 22:04:55 - progress_bar.py[line:272] - INFO: epoch 002:   3245 / 8233 loss=4.602, loss_v1=0, loss_v2=0, nll_loss=3.308, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=9.9, wps=282.3, ups=0.84, wpb=338.1, bsz=48, num_updates=11460, lr=9.70218e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13808
2023-08-08 22:05:07 - progress_bar.py[line:272] - INFO: epoch 002:   3255 / 8233 loss=4.633, loss_v1=0, loss_v2=0, nll_loss=3.353, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=10.22, wps=280, ups=0.83, wpb=337.6, bsz=48, num_updates=11470, lr=9.6828e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13820
2023-08-08 22:05:20 - progress_bar.py[line:272] - INFO: epoch 002:   3265 / 8233 loss=4.602, loss_v1=0, loss_v2=0, nll_loss=3.304, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.88, wps=280.7, ups=0.83, wpb=338.4, bsz=48, num_updates=11480, lr=9.66341e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13832
2023-08-08 22:05:32 - progress_bar.py[line:272] - INFO: epoch 002:   3275 / 8233 loss=4.68, loss_v1=0, loss_v2=0, nll_loss=3.39, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=10.48, wps=278.4, ups=0.83, wpb=335.8, bsz=48, num_updates=11490, lr=9.64403e-06, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13844
2023-08-08 22:05:44 - progress_bar.py[line:272] - INFO: epoch 002:   3285 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=282.9, ups=0.83, wpb=338.9, bsz=48, num_updates=11500, lr=9.62465e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13856
2023-08-08 22:05:56 - progress_bar.py[line:272] - INFO: epoch 002:   3295 / 8233 loss=4.583, loss_v1=0, loss_v2=0, nll_loss=3.292, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.79, wps=279.2, ups=0.83, wpb=337.5, bsz=48, num_updates=11510, lr=9.60527e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13869
2023-08-08 22:06:08 - progress_bar.py[line:272] - INFO: epoch 002:   3305 / 8233 loss=4.592, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=335.7, nsentences=48, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=278.4, ups=0.83, wpb=335.7, bsz=48, num_updates=11520, lr=9.58589e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13881
2023-08-08 22:06:20 - progress_bar.py[line:272] - INFO: epoch 002:   3315 / 8233 loss=4.604, loss_v1=0, loss_v2=0, nll_loss=3.309, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=9.91, wps=284.8, ups=0.84, wpb=340, bsz=48, num_updates=11530, lr=9.56651e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13893
2023-08-08 22:06:32 - progress_bar.py[line:272] - INFO: epoch 002:   3325 / 8233 loss=4.637, loss_v1=0, loss_v2=0, nll_loss=3.343, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=10.14, wps=285.8, ups=0.84, wpb=341.3, bsz=48, num_updates=11540, lr=9.54713e-06, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13904
2023-08-08 22:06:44 - progress_bar.py[line:272] - INFO: epoch 002:   3335 / 8233 loss=4.677, loss_v1=0, loss_v2=0, nll_loss=3.39, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=10.48, wps=280.8, ups=0.83, wpb=336.9, bsz=48, num_updates=11550, lr=9.52775e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13916
2023-08-08 22:06:56 - progress_bar.py[line:272] - INFO: epoch 002:   3345 / 8233 loss=4.604, loss_v1=0, loss_v2=0, nll_loss=3.31, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.92, wps=283.6, ups=0.83, wpb=339.9, bsz=48, num_updates=11560, lr=9.50837e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13928
2023-08-08 22:07:08 - progress_bar.py[line:272] - INFO: epoch 002:   3355 / 8233 loss=4.65, loss_v1=0, loss_v2=0, nll_loss=3.358, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=10.26, wps=280.5, ups=0.83, wpb=336.3, bsz=48, num_updates=11570, lr=9.48899e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13940
2023-08-08 22:07:20 - progress_bar.py[line:272] - INFO: epoch 002:   3365 / 8233 loss=4.583, loss_v1=0, loss_v2=0, nll_loss=3.284, ntokens=342.1, nsentences=48, sample_size=342.1, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=285.1, ups=0.83, wpb=342.1, bsz=48, num_updates=11580, lr=9.4696e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13952
2023-08-08 22:07:32 - progress_bar.py[line:272] - INFO: epoch 002:   3375 / 8233 loss=4.642, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=283.6, ups=0.83, wpb=341.1, bsz=48, num_updates=11590, lr=9.45022e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13965
2023-08-08 22:07:44 - progress_bar.py[line:272] - INFO: epoch 002:   3385 / 8233 loss=4.592, loss_v1=0, loss_v2=0, nll_loss=3.292, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=283.2, ups=0.83, wpb=339.2, bsz=48, num_updates=11600, lr=9.43084e-06, gnorm=0.114, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13976
2023-08-08 22:07:56 - progress_bar.py[line:272] - INFO: epoch 002:   3395 / 8233 loss=4.631, loss_v1=0, loss_v2=0, nll_loss=3.336, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=10.1, wps=280.1, ups=0.83, wpb=337.5, bsz=48, num_updates=11610, lr=9.41146e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=13989
2023-08-08 22:08:08 - progress_bar.py[line:272] - INFO: epoch 002:   3405 / 8233 loss=4.628, loss_v1=0, loss_v2=0, nll_loss=3.333, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=10.08, wps=282, ups=0.83, wpb=338.7, bsz=48, num_updates=11620, lr=9.39208e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14001
2023-08-08 22:08:20 - progress_bar.py[line:272] - INFO: epoch 002:   3415 / 8233 loss=4.636, loss_v1=0, loss_v2=0, nll_loss=3.35, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=10.19, wps=284.2, ups=0.84, wpb=340.4, bsz=48, num_updates=11630, lr=9.3727e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14013
2023-08-08 22:08:32 - progress_bar.py[line:272] - INFO: epoch 002:   3425 / 8233 loss=4.634, loss_v1=0, loss_v2=0, nll_loss=3.343, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=10.15, wps=284.3, ups=0.84, wpb=339.9, bsz=48, num_updates=11640, lr=9.35332e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14024
2023-08-08 22:08:44 - progress_bar.py[line:272] - INFO: epoch 002:   3435 / 8233 loss=4.608, loss_v1=0, loss_v2=0, nll_loss=3.306, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=9.89, wps=282.5, ups=0.83, wpb=339.6, bsz=48, num_updates=11650, lr=9.33394e-06, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14037
2023-08-08 22:08:56 - progress_bar.py[line:272] - INFO: epoch 002:   3445 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.329, ntokens=333.9, nsentences=48, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=10.05, wps=275.4, ups=0.82, wpb=333.9, bsz=48, num_updates=11660, lr=9.31456e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14049
2023-08-08 22:09:08 - progress_bar.py[line:272] - INFO: epoch 002:   3455 / 8233 loss=4.626, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=280.5, ups=0.83, wpb=338, bsz=48, num_updates=11670, lr=9.29517e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14061
2023-08-08 22:09:20 - progress_bar.py[line:272] - INFO: epoch 002:   3465 / 8233 loss=4.629, loss_v1=0, loss_v2=0, nll_loss=3.338, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10.11, wps=285.9, ups=0.84, wpb=339, bsz=48, num_updates=11680, lr=9.27579e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14073
2023-08-08 22:09:32 - progress_bar.py[line:272] - INFO: epoch 002:   3475 / 8233 loss=4.58, loss_v1=0, loss_v2=0, nll_loss=3.279, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=281.5, ups=0.83, wpb=338.7, bsz=48, num_updates=11690, lr=9.25641e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14085
2023-08-08 22:09:44 - progress_bar.py[line:272] - INFO: epoch 002:   3485 / 8233 loss=4.642, loss_v1=0, loss_v2=0, nll_loss=3.355, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=10.23, wps=278.2, ups=0.83, wpb=335.6, bsz=48, num_updates=11700, lr=9.23703e-06, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14097
2023-08-08 22:09:56 - progress_bar.py[line:272] - INFO: epoch 002:   3495 / 8233 loss=4.579, loss_v1=0, loss_v2=0, nll_loss=3.279, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=283.2, ups=0.83, wpb=339.7, bsz=48, num_updates=11710, lr=9.21765e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14109
2023-08-08 22:10:08 - progress_bar.py[line:272] - INFO: epoch 002:   3505 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.298, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=281.5, ups=0.83, wpb=338.4, bsz=48, num_updates=11720, lr=9.19827e-06, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14121
2023-08-08 22:10:20 - progress_bar.py[line:272] - INFO: epoch 002:   3515 / 8233 loss=4.648, loss_v1=0, loss_v2=0, nll_loss=3.361, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=10.27, wps=277.5, ups=0.83, wpb=335.8, bsz=48, num_updates=11730, lr=9.17889e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14133
2023-08-08 22:10:32 - progress_bar.py[line:272] - INFO: epoch 002:   3525 / 8233 loss=4.645, loss_v1=0, loss_v2=0, nll_loss=3.353, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=10.22, wps=283.9, ups=0.83, wpb=340.5, bsz=48, num_updates=11740, lr=9.15951e-06, gnorm=0.113, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14145
2023-08-08 22:10:44 - progress_bar.py[line:272] - INFO: epoch 002:   3535 / 8233 loss=4.636, loss_v1=0, loss_v2=0, nll_loss=3.349, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.19, wps=279.5, ups=0.83, wpb=336.4, bsz=48, num_updates=11750, lr=9.14013e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14157
2023-08-08 22:10:56 - progress_bar.py[line:272] - INFO: epoch 002:   3545 / 8233 loss=4.612, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=284.7, ups=0.84, wpb=340.4, bsz=48, num_updates=11760, lr=9.12074e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14169
2023-08-08 22:11:08 - progress_bar.py[line:272] - INFO: epoch 002:   3555 / 8233 loss=4.635, loss_v1=0, loss_v2=0, nll_loss=3.342, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=10.14, wps=282.1, ups=0.83, wpb=338.3, bsz=48, num_updates=11770, lr=9.10136e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14181
2023-08-08 22:11:20 - progress_bar.py[line:272] - INFO: epoch 002:   3565 / 8233 loss=4.605, loss_v1=0, loss_v2=0, nll_loss=3.307, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.89, wps=285.3, ups=0.84, wpb=340.5, bsz=48, num_updates=11780, lr=9.08198e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14193
2023-08-08 22:11:32 - progress_bar.py[line:272] - INFO: epoch 002:   3575 / 8233 loss=4.614, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=332.4, nsentences=48, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=275.2, ups=0.83, wpb=332.4, bsz=48, num_updates=11790, lr=9.0626e-06, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14205
2023-08-08 22:11:44 - progress_bar.py[line:272] - INFO: epoch 002:   3585 / 8233 loss=4.61, loss_v1=0, loss_v2=0, nll_loss=3.312, ntokens=334.4, nsentences=48, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=9.93, wps=276.5, ups=0.83, wpb=334.4, bsz=48, num_updates=11800, lr=9.04322e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14217
2023-08-08 22:11:56 - progress_bar.py[line:272] - INFO: epoch 002:   3595 / 8233 loss=4.594, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=283.2, ups=0.83, wpb=339.6, bsz=48, num_updates=11810, lr=9.02384e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14229
2023-08-08 22:12:08 - progress_bar.py[line:272] - INFO: epoch 002:   3605 / 8233 loss=4.601, loss_v1=0, loss_v2=0, nll_loss=3.31, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.92, wps=283.7, ups=0.84, wpb=339.5, bsz=48, num_updates=11820, lr=9.00446e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14241
2023-08-08 22:12:20 - progress_bar.py[line:272] - INFO: epoch 002:   3615 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=287.2, ups=0.84, wpb=340.5, bsz=48, num_updates=11830, lr=8.98508e-06, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14253
2023-08-08 22:12:32 - progress_bar.py[line:272] - INFO: epoch 002:   3625 / 8233 loss=4.652, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=284.8, ups=0.84, wpb=340.2, bsz=48, num_updates=11840, lr=8.9657e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14265
2023-08-08 22:12:44 - progress_bar.py[line:272] - INFO: epoch 002:   3635 / 8233 loss=4.576, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=284.6, ups=0.84, wpb=339.3, bsz=48, num_updates=11850, lr=8.94631e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14277
2023-08-08 22:12:56 - progress_bar.py[line:272] - INFO: epoch 002:   3645 / 8233 loss=4.626, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=278.8, ups=0.83, wpb=335.5, bsz=48, num_updates=11860, lr=8.92693e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14289
2023-08-08 22:13:08 - progress_bar.py[line:272] - INFO: epoch 002:   3655 / 8233 loss=4.621, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=281.9, ups=0.83, wpb=337.9, bsz=48, num_updates=11870, lr=8.90755e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14301
2023-08-08 22:13:20 - progress_bar.py[line:272] - INFO: epoch 002:   3665 / 8233 loss=4.629, loss_v1=0, loss_v2=0, nll_loss=3.336, ntokens=334.8, nsentences=48, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=10.1, wps=279, ups=0.83, wpb=334.8, bsz=48, num_updates=11880, lr=8.88817e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14313
2023-08-08 22:13:32 - progress_bar.py[line:272] - INFO: epoch 002:   3675 / 8233 loss=4.591, loss_v1=0, loss_v2=0, nll_loss=3.294, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=281.6, ups=0.83, wpb=337.2, bsz=48, num_updates=11890, lr=8.86879e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14325
2023-08-08 22:13:44 - progress_bar.py[line:272] - INFO: epoch 002:   3685 / 8233 loss=4.606, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=284.8, ups=0.83, wpb=341.1, bsz=48, num_updates=11900, lr=8.84941e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14337
2023-08-08 22:13:56 - progress_bar.py[line:272] - INFO: epoch 002:   3695 / 8233 loss=4.591, loss_v1=0, loss_v2=0, nll_loss=3.294, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=278.8, ups=0.82, wpb=338.6, bsz=48, num_updates=11910, lr=8.83003e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14349
2023-08-08 22:14:08 - progress_bar.py[line:272] - INFO: epoch 002:   3705 / 8233 loss=4.619, loss_v1=0, loss_v2=0, nll_loss=3.325, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=10.02, wps=281.8, ups=0.83, wpb=339.3, bsz=48, num_updates=11920, lr=8.81065e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14361
2023-08-08 22:14:20 - progress_bar.py[line:272] - INFO: epoch 002:   3715 / 8233 loss=4.595, loss_v1=0, loss_v2=0, nll_loss=3.299, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=283.4, ups=0.83, wpb=340.2, bsz=48, num_updates=11930, lr=8.79127e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14373
2023-08-08 22:14:32 - progress_bar.py[line:272] - INFO: epoch 002:   3725 / 8233 loss=4.656, loss_v1=0, loss_v2=0, nll_loss=3.369, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=10.33, wps=283.9, ups=0.83, wpb=340, bsz=48, num_updates=11940, lr=8.77188e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14385
2023-08-08 22:14:44 - progress_bar.py[line:272] - INFO: epoch 002:   3735 / 8233 loss=4.584, loss_v1=0, loss_v2=0, nll_loss=3.291, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=9.79, wps=282.8, ups=0.84, wpb=338.1, bsz=48, num_updates=11950, lr=8.7525e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14397
2023-08-08 22:14:56 - progress_bar.py[line:272] - INFO: epoch 002:   3745 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.3, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=278.9, ups=0.83, wpb=336.3, bsz=48, num_updates=11960, lr=8.73312e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14409
2023-08-08 22:15:08 - progress_bar.py[line:272] - INFO: epoch 002:   3755 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=280.3, ups=0.83, wpb=338.2, bsz=48, num_updates=11970, lr=8.71374e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14421
2023-08-08 22:15:20 - progress_bar.py[line:272] - INFO: epoch 002:   3765 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.334, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=10.08, wps=284.6, ups=0.84, wpb=340.5, bsz=48, num_updates=11980, lr=8.69436e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14433
2023-08-08 22:15:32 - progress_bar.py[line:272] - INFO: epoch 002:   3775 / 8233 loss=4.607, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=281.4, ups=0.83, wpb=338.8, bsz=48, num_updates=11990, lr=8.67498e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14445
2023-08-08 22:15:44 - progress_bar.py[line:272] - INFO: epoch 002:   3785 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.289, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=282.2, ups=0.83, wpb=340.5, bsz=48, num_updates=12000, lr=8.6556e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14457
2023-08-08 22:15:56 - progress_bar.py[line:272] - INFO: epoch 002:   3795 / 8233 loss=4.581, loss_v1=0, loss_v2=0, nll_loss=3.282, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=9.73, wps=278.1, ups=0.83, wpb=336.7, bsz=48, num_updates=12010, lr=8.63622e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14469
2023-08-08 22:16:08 - progress_bar.py[line:272] - INFO: epoch 002:   3805 / 8233 loss=4.624, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=333.9, nsentences=48, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=277.4, ups=0.83, wpb=333.9, bsz=48, num_updates=12020, lr=8.61684e-06, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14481
2023-08-08 22:16:20 - progress_bar.py[line:272] - INFO: epoch 002:   3815 / 8233 loss=4.614, loss_v1=0, loss_v2=0, nll_loss=3.323, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=10, wps=283.6, ups=0.84, wpb=339, bsz=48, num_updates=12030, lr=8.59745e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14493
2023-08-08 22:16:32 - progress_bar.py[line:272] - INFO: epoch 002:   3825 / 8233 loss=4.565, loss_v1=0, loss_v2=0, nll_loss=3.262, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.59, wps=283.2, ups=0.84, wpb=339, bsz=48, num_updates=12040, lr=8.57807e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14505
2023-08-08 22:16:44 - progress_bar.py[line:272] - INFO: epoch 002:   3835 / 8233 loss=4.625, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=284.4, ups=0.83, wpb=340.6, bsz=48, num_updates=12050, lr=8.55869e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14517
2023-08-08 22:16:56 - progress_bar.py[line:272] - INFO: epoch 002:   3845 / 8233 loss=4.599, loss_v1=0, loss_v2=0, nll_loss=3.302, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=9.86, wps=278.8, ups=0.83, wpb=336.5, bsz=48, num_updates=12060, lr=8.53931e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14529
2023-08-08 22:17:08 - progress_bar.py[line:272] - INFO: epoch 002:   3855 / 8233 loss=4.606, loss_v1=0, loss_v2=0, nll_loss=3.31, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.92, wps=284.3, ups=0.84, wpb=340.3, bsz=48, num_updates=12070, lr=8.51993e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14541
2023-08-08 22:17:20 - progress_bar.py[line:272] - INFO: epoch 002:   3865 / 8233 loss=4.608, loss_v1=0, loss_v2=0, nll_loss=3.317, ntokens=334.6, nsentences=48, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=276.8, ups=0.83, wpb=334.6, bsz=48, num_updates=12080, lr=8.50055e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14553
2023-08-08 22:17:32 - progress_bar.py[line:272] - INFO: epoch 002:   3875 / 8233 loss=4.625, loss_v1=0, loss_v2=0, nll_loss=3.329, ntokens=334, nsentences=48, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=10.05, wps=275.8, ups=0.83, wpb=334, bsz=48, num_updates=12090, lr=8.48117e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14565
2023-08-08 22:17:44 - progress_bar.py[line:272] - INFO: epoch 002:   3885 / 8233 loss=4.622, loss_v1=0, loss_v2=0, nll_loss=3.333, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=10.08, wps=277.8, ups=0.83, wpb=336.4, bsz=48, num_updates=12100, lr=8.46179e-06, gnorm=0.114, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14577
2023-08-08 22:17:57 - progress_bar.py[line:272] - INFO: epoch 002:   3895 / 8233 loss=4.62, loss_v1=0, loss_v2=0, nll_loss=3.327, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=277, ups=0.83, wpb=335.4, bsz=48, num_updates=12110, lr=8.44241e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14589
2023-08-08 22:18:09 - progress_bar.py[line:272] - INFO: epoch 002:   3905 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.287, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=283.7, ups=0.84, wpb=339.7, bsz=48, num_updates=12120, lr=8.42302e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14601
2023-08-08 22:18:21 - progress_bar.py[line:272] - INFO: epoch 002:   3915 / 8233 loss=4.602, loss_v1=0, loss_v2=0, nll_loss=3.3, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=282.6, ups=0.83, wpb=339.2, bsz=48, num_updates=12130, lr=8.40364e-06, gnorm=0.112, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14613
2023-08-08 22:18:32 - progress_bar.py[line:272] - INFO: epoch 002:   3925 / 8233 loss=4.596, loss_v1=0, loss_v2=0, nll_loss=3.303, ntokens=343, nsentences=48, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=9.87, wps=288.4, ups=0.84, wpb=343, bsz=48, num_updates=12140, lr=8.38426e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14625
2023-08-08 22:18:44 - progress_bar.py[line:272] - INFO: epoch 002:   3935 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.304, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.87, wps=285.3, ups=0.84, wpb=339.9, bsz=48, num_updates=12150, lr=8.36488e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14637
2023-08-08 22:18:56 - progress_bar.py[line:272] - INFO: epoch 002:   3945 / 8233 loss=4.617, loss_v1=0, loss_v2=0, nll_loss=3.328, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=10.04, wps=277.3, ups=0.82, wpb=336.2, bsz=48, num_updates=12160, lr=8.3455e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14649
2023-08-08 22:19:09 - progress_bar.py[line:272] - INFO: epoch 002:   3955 / 8233 loss=4.622, loss_v1=0, loss_v2=0, nll_loss=3.331, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=280.6, ups=0.83, wpb=337.3, bsz=48, num_updates=12170, lr=8.32612e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14661
2023-08-08 22:19:21 - progress_bar.py[line:272] - INFO: epoch 002:   3965 / 8233 loss=4.657, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=283.7, ups=0.83, wpb=340.1, bsz=48, num_updates=12180, lr=8.30674e-06, gnorm=0.112, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14673
2023-08-08 22:19:33 - progress_bar.py[line:272] - INFO: epoch 002:   3975 / 8233 loss=4.616, loss_v1=0, loss_v2=0, nll_loss=3.328, ntokens=335.7, nsentences=48, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=10.04, wps=278.2, ups=0.83, wpb=335.7, bsz=48, num_updates=12190, lr=8.28736e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14685
2023-08-08 22:19:45 - progress_bar.py[line:272] - INFO: epoch 002:   3985 / 8233 loss=4.584, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=278.3, ups=0.83, wpb=337, bsz=48, num_updates=12200, lr=8.26798e-06, gnorm=0.11, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14698
2023-08-08 22:19:57 - progress_bar.py[line:272] - INFO: epoch 002:   3995 / 8233 loss=4.611, loss_v1=0, loss_v2=0, nll_loss=3.317, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=279, ups=0.83, wpb=337, bsz=48, num_updates=12210, lr=8.24859e-06, gnorm=0.112, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14710
2023-08-08 22:20:09 - progress_bar.py[line:272] - INFO: epoch 002:   4005 / 8233 loss=4.586, loss_v1=0, loss_v2=0, nll_loss=3.294, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=279.8, ups=0.83, wpb=337.4, bsz=48, num_updates=12220, lr=8.22921e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14722
2023-08-08 22:20:21 - progress_bar.py[line:272] - INFO: epoch 002:   4015 / 8233 loss=4.611, loss_v1=0, loss_v2=0, nll_loss=3.319, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=9.98, wps=278.1, ups=0.82, wpb=338.2, bsz=48, num_updates=12230, lr=8.20983e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14734
2023-08-08 22:20:33 - progress_bar.py[line:272] - INFO: epoch 002:   4025 / 8233 loss=4.619, loss_v1=0, loss_v2=0, nll_loss=3.329, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=10.05, wps=286.3, ups=0.84, wpb=341, bsz=48, num_updates=12240, lr=8.19045e-06, gnorm=0.109, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14746
2023-08-08 22:20:45 - progress_bar.py[line:272] - INFO: epoch 002:   4035 / 8233 loss=4.582, loss_v1=0, loss_v2=0, nll_loss=3.287, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=281.8, ups=0.83, wpb=338, bsz=48, num_updates=12250, lr=8.17107e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=14758
2023-08-08 22:20:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-08-08 22:20:58 - progress_bar.py[line:272] - INFO: epoch 002:   4046 / 8233 loss=4.621, loss_v1=0, loss_v2=0, nll_loss=3.334, ntokens=334.3, nsentences=48, sample_size=334.3, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=252.6, ups=0.76, wpb=334.3, bsz=48, num_updates=12260, lr=8.15169e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=13, gb_free=14.5, wall=14771
2023-08-08 22:21:10 - progress_bar.py[line:272] - INFO: epoch 002:   4056 / 8233 loss=4.653, loss_v1=0, loss_v2=0, nll_loss=3.361, ntokens=335.7, nsentences=48, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=10.28, wps=277.9, ups=0.83, wpb=335.7, bsz=48, num_updates=12270, lr=8.13231e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14783
2023-08-08 22:21:22 - progress_bar.py[line:272] - INFO: epoch 002:   4066 / 8233 loss=4.604, loss_v1=0, loss_v2=0, nll_loss=3.311, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=9.92, wps=281.3, ups=0.83, wpb=337.6, bsz=48, num_updates=12280, lr=8.11293e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14795
2023-08-08 22:21:34 - progress_bar.py[line:272] - INFO: epoch 002:   4076 / 8233 loss=4.571, loss_v1=0, loss_v2=0, nll_loss=3.269, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=285, ups=0.84, wpb=340.9, bsz=48, num_updates=12290, lr=8.09355e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14807
2023-08-08 22:21:46 - progress_bar.py[line:272] - INFO: epoch 002:   4086 / 8233 loss=4.618, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=334.6, nsentences=48, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=276.4, ups=0.83, wpb=334.6, bsz=48, num_updates=12300, lr=8.07416e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14819
2023-08-08 22:21:58 - progress_bar.py[line:272] - INFO: epoch 002:   4096 / 8233 loss=4.59, loss_v1=0, loss_v2=0, nll_loss=3.291, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=9.79, wps=277.8, ups=0.83, wpb=335.3, bsz=48, num_updates=12310, lr=8.05478e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14831
2023-08-08 22:22:10 - progress_bar.py[line:272] - INFO: epoch 002:   4106 / 8233 loss=4.595, loss_v1=0, loss_v2=0, nll_loss=3.299, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=282, ups=0.83, wpb=338.7, bsz=48, num_updates=12320, lr=8.0354e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14843
2023-08-08 22:22:22 - progress_bar.py[line:272] - INFO: epoch 002:   4116 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.301, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=281.1, ups=0.83, wpb=337.9, bsz=48, num_updates=12330, lr=8.01602e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14855
2023-08-08 22:22:35 - progress_bar.py[line:272] - INFO: epoch 002:   4126 / 8233 loss=4.636, loss_v1=0, loss_v2=0, nll_loss=3.349, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=10.19, wps=277.7, ups=0.83, wpb=336.2, bsz=48, num_updates=12340, lr=7.99664e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14867
2023-08-08 22:22:47 - progress_bar.py[line:272] - INFO: epoch 002:   4136 / 8233 loss=4.602, loss_v1=0, loss_v2=0, nll_loss=3.313, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.94, wps=280.3, ups=0.83, wpb=338.7, bsz=48, num_updates=12350, lr=7.97726e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14880
2023-08-08 22:22:59 - progress_bar.py[line:272] - INFO: epoch 002:   4146 / 8233 loss=4.584, loss_v1=0, loss_v2=0, nll_loss=3.286, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=282.5, ups=0.83, wpb=338.6, bsz=48, num_updates=12360, lr=7.95788e-06, gnorm=0.111, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14891
2023-08-08 22:23:11 - progress_bar.py[line:272] - INFO: epoch 002:   4156 / 8233 loss=4.615, loss_v1=0, loss_v2=0, nll_loss=3.33, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=10.06, wps=285.1, ups=0.84, wpb=341.2, bsz=48, num_updates=12370, lr=7.9385e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14903
2023-08-08 22:23:22 - progress_bar.py[line:272] - INFO: epoch 002:   4166 / 8233 loss=4.619, loss_v1=0, loss_v2=0, nll_loss=3.328, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=10.04, wps=286.9, ups=0.84, wpb=341.1, bsz=48, num_updates=12380, lr=7.91912e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14915
2023-08-08 22:23:34 - progress_bar.py[line:272] - INFO: epoch 002:   4176 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.305, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.88, wps=283, ups=0.84, wpb=338.4, bsz=48, num_updates=12390, lr=7.89974e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14927
2023-08-08 22:23:46 - progress_bar.py[line:272] - INFO: epoch 002:   4186 / 8233 loss=4.579, loss_v1=0, loss_v2=0, nll_loss=3.283, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.73, wps=283.2, ups=0.83, wpb=339.4, bsz=48, num_updates=12400, lr=7.88035e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14939
2023-08-08 22:23:58 - progress_bar.py[line:272] - INFO: epoch 002:   4196 / 8233 loss=4.585, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=286.5, ups=0.84, wpb=340.7, bsz=48, num_updates=12410, lr=7.86097e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14951
2023-08-08 22:24:10 - progress_bar.py[line:272] - INFO: epoch 002:   4206 / 8233 loss=4.618, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=280.2, ups=0.83, wpb=336.9, bsz=48, num_updates=12420, lr=7.84159e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14963
2023-08-08 22:24:22 - progress_bar.py[line:272] - INFO: epoch 002:   4216 / 8233 loss=4.559, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=283.8, ups=0.83, wpb=340.3, bsz=48, num_updates=12430, lr=7.82221e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14975
2023-08-08 22:24:34 - progress_bar.py[line:272] - INFO: epoch 002:   4226 / 8233 loss=4.593, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=284.3, ups=0.84, wpb=340.3, bsz=48, num_updates=12440, lr=7.80283e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14987
2023-08-08 22:24:46 - progress_bar.py[line:272] - INFO: epoch 002:   4236 / 8233 loss=4.568, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=280.6, ups=0.83, wpb=336.2, bsz=48, num_updates=12450, lr=7.78345e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=14999
2023-08-08 22:24:58 - progress_bar.py[line:272] - INFO: epoch 002:   4246 / 8233 loss=4.606, loss_v1=0, loss_v2=0, nll_loss=3.312, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.93, wps=280.5, ups=0.83, wpb=338.3, bsz=48, num_updates=12460, lr=7.76407e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15011
2023-08-08 22:25:10 - progress_bar.py[line:272] - INFO: epoch 002:   4256 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.274, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=279.1, ups=0.83, wpb=336.5, bsz=48, num_updates=12470, lr=7.74469e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15023
2023-08-08 22:25:22 - progress_bar.py[line:272] - INFO: epoch 002:   4266 / 8233 loss=4.625, loss_v1=0, loss_v2=0, nll_loss=3.341, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=10.13, wps=284.9, ups=0.84, wpb=340.9, bsz=48, num_updates=12480, lr=7.72531e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15035
2023-08-08 22:25:34 - progress_bar.py[line:272] - INFO: epoch 002:   4276 / 8233 loss=4.591, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=342.1, nsentences=48, sample_size=342.1, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=285.1, ups=0.83, wpb=342.1, bsz=48, num_updates=12490, lr=7.70592e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15047
2023-08-08 22:25:46 - progress_bar.py[line:272] - INFO: epoch 002:   4286 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.299, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=278.7, ups=0.83, wpb=335.9, bsz=48, num_updates=12500, lr=7.68654e-06, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15059
2023-08-08 22:25:59 - progress_bar.py[line:272] - INFO: epoch 002:   4296 / 8233 loss=4.61, loss_v1=0, loss_v2=0, nll_loss=3.317, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=9.97, wps=278.2, ups=0.83, wpb=336.4, bsz=48, num_updates=12510, lr=7.66716e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15071
2023-08-08 22:26:11 - progress_bar.py[line:272] - INFO: epoch 002:   4306 / 8233 loss=4.595, loss_v1=0, loss_v2=0, nll_loss=3.297, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.83, wps=282.1, ups=0.83, wpb=338.7, bsz=48, num_updates=12520, lr=7.64778e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15083
2023-08-08 22:26:23 - progress_bar.py[line:272] - INFO: epoch 002:   4316 / 8233 loss=4.615, loss_v1=0, loss_v2=0, nll_loss=3.318, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.97, wps=281.4, ups=0.84, wpb=336.8, bsz=48, num_updates=12530, lr=7.6284e-06, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15095
2023-08-08 22:26:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 22:26:36 - progress_bar.py[line:272] - INFO: epoch 002:   4327 / 8233 loss=4.562, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=252.5, ups=0.75, wpb=336, bsz=48, num_updates=12540, lr=7.60902e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=13, gb_free=14.5, wall=15109
2023-08-08 22:26:48 - progress_bar.py[line:272] - INFO: epoch 002:   4337 / 8233 loss=4.623, loss_v1=0, loss_v2=0, nll_loss=3.336, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=10.1, wps=283.1, ups=0.83, wpb=339.4, bsz=48, num_updates=12550, lr=7.58964e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15121
2023-08-08 22:27:00 - progress_bar.py[line:272] - INFO: epoch 002:   4347 / 8233 loss=4.593, loss_v1=0, loss_v2=0, nll_loss=3.298, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=281.1, ups=0.83, wpb=337, bsz=48, num_updates=12560, lr=7.57026e-06, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15133
2023-08-08 22:27:12 - progress_bar.py[line:272] - INFO: epoch 002:   4357 / 8233 loss=4.632, loss_v1=0, loss_v2=0, nll_loss=3.341, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=10.14, wps=278.9, ups=0.83, wpb=337.1, bsz=48, num_updates=12570, lr=7.55088e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15145
2023-08-08 22:27:24 - progress_bar.py[line:272] - INFO: epoch 002:   4367 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.272, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=283, ups=0.83, wpb=339.1, bsz=48, num_updates=12580, lr=7.53149e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15157
2023-08-08 22:27:36 - progress_bar.py[line:272] - INFO: epoch 002:   4377 / 8233 loss=4.555, loss_v1=0, loss_v2=0, nll_loss=3.254, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=282.7, ups=0.83, wpb=339.4, bsz=48, num_updates=12590, lr=7.51211e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15169
2023-08-08 22:27:48 - progress_bar.py[line:272] - INFO: epoch 002:   4387 / 8233 loss=4.607, loss_v1=0, loss_v2=0, nll_loss=3.313, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.94, wps=282.9, ups=0.83, wpb=339.2, bsz=48, num_updates=12600, lr=7.49273e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15181
2023-08-08 22:28:00 - progress_bar.py[line:272] - INFO: epoch 002:   4397 / 8233 loss=4.566, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=286.9, ups=0.84, wpb=341.1, bsz=48, num_updates=12610, lr=7.47335e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15193
2023-08-08 22:28:12 - progress_bar.py[line:272] - INFO: epoch 002:   4407 / 8233 loss=4.544, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=286.2, ups=0.84, wpb=340.2, bsz=48, num_updates=12620, lr=7.45397e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15205
2023-08-08 22:28:24 - progress_bar.py[line:272] - INFO: epoch 002:   4417 / 8233 loss=4.616, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=278.8, ups=0.83, wpb=335.1, bsz=48, num_updates=12630, lr=7.43459e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15217
2023-08-08 22:28:36 - progress_bar.py[line:272] - INFO: epoch 002:   4427 / 8233 loss=4.602, loss_v1=0, loss_v2=0, nll_loss=3.307, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.9, wps=284.2, ups=0.84, wpb=339.9, bsz=48, num_updates=12640, lr=7.41521e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15229
2023-08-08 22:28:48 - progress_bar.py[line:272] - INFO: epoch 002:   4437 / 8233 loss=4.597, loss_v1=0, loss_v2=0, nll_loss=3.3, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=285.1, ups=0.84, wpb=340.7, bsz=48, num_updates=12650, lr=7.39583e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15240
2023-08-08 22:29:00 - progress_bar.py[line:272] - INFO: epoch 002:   4447 / 8233 loss=4.578, loss_v1=0, loss_v2=0, nll_loss=3.285, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=283.1, ups=0.83, wpb=339.1, bsz=48, num_updates=12660, lr=7.37645e-06, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15252
2023-08-08 22:29:12 - progress_bar.py[line:272] - INFO: epoch 002:   4457 / 8233 loss=4.538, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=284.4, ups=0.84, wpb=339.6, bsz=48, num_updates=12670, lr=7.35706e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15264
2023-08-08 22:29:24 - progress_bar.py[line:272] - INFO: epoch 002:   4467 / 8233 loss=4.585, loss_v1=0, loss_v2=0, nll_loss=3.292, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=280.5, ups=0.83, wpb=337.6, bsz=48, num_updates=12680, lr=7.33768e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15276
2023-08-08 22:29:36 - progress_bar.py[line:272] - INFO: epoch 002:   4477 / 8233 loss=4.6, loss_v1=0, loss_v2=0, nll_loss=3.311, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=9.93, wps=280, ups=0.83, wpb=337.6, bsz=48, num_updates=12690, lr=7.3183e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15289
2023-08-08 22:29:48 - progress_bar.py[line:272] - INFO: epoch 002:   4487 / 8233 loss=4.596, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=281.5, ups=0.83, wpb=338.4, bsz=48, num_updates=12700, lr=7.29892e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15301
2023-08-08 22:30:00 - progress_bar.py[line:272] - INFO: epoch 002:   4497 / 8233 loss=4.601, loss_v1=0, loss_v2=0, nll_loss=3.306, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.89, wps=282.7, ups=0.84, wpb=337.7, bsz=48, num_updates=12710, lr=7.27954e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15312
2023-08-08 22:30:12 - progress_bar.py[line:272] - INFO: epoch 002:   4507 / 8233 loss=4.608, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=284.1, ups=0.84, wpb=339.2, bsz=48, num_updates=12720, lr=7.26016e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15324
2023-08-08 22:30:24 - progress_bar.py[line:272] - INFO: epoch 002:   4517 / 8233 loss=4.55, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=280.4, ups=0.83, wpb=337.7, bsz=48, num_updates=12730, lr=7.24078e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15336
2023-08-08 22:30:36 - progress_bar.py[line:272] - INFO: epoch 002:   4527 / 8233 loss=4.596, loss_v1=0, loss_v2=0, nll_loss=3.3, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=283.3, ups=0.83, wpb=340.3, bsz=48, num_updates=12740, lr=7.2214e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15348
2023-08-08 22:30:48 - progress_bar.py[line:272] - INFO: epoch 002:   4537 / 8233 loss=4.616, loss_v1=0, loss_v2=0, nll_loss=3.317, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.97, wps=280.6, ups=0.83, wpb=337.1, bsz=48, num_updates=12750, lr=7.20202e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15361
2023-08-08 22:31:00 - progress_bar.py[line:272] - INFO: epoch 002:   4547 / 8233 loss=4.616, loss_v1=0, loss_v2=0, nll_loss=3.324, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=10.01, wps=283, ups=0.83, wpb=339.3, bsz=48, num_updates=12760, lr=7.18263e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15373
2023-08-08 22:31:12 - progress_bar.py[line:272] - INFO: epoch 002:   4557 / 8233 loss=4.588, loss_v1=0, loss_v2=0, nll_loss=3.301, ntokens=333.8, nsentences=48, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=9.86, wps=277.2, ups=0.83, wpb=333.8, bsz=48, num_updates=12770, lr=7.16325e-06, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15385
2023-08-08 22:31:24 - progress_bar.py[line:272] - INFO: epoch 002:   4567 / 8233 loss=4.6, loss_v1=0, loss_v2=0, nll_loss=3.307, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.9, wps=281, ups=0.83, wpb=338, bsz=48, num_updates=12780, lr=7.14387e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15397
2023-08-08 22:31:36 - progress_bar.py[line:272] - INFO: epoch 002:   4577 / 8233 loss=4.571, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=284.3, ups=0.84, wpb=339, bsz=48, num_updates=12790, lr=7.12449e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15409
2023-08-08 22:31:48 - progress_bar.py[line:272] - INFO: epoch 002:   4587 / 8233 loss=4.598, loss_v1=0, loss_v2=0, nll_loss=3.304, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=9.88, wps=285.4, ups=0.84, wpb=340.7, bsz=48, num_updates=12800, lr=7.10511e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15420
2023-08-08 22:31:59 - progress_bar.py[line:272] - INFO: epoch 002:   4597 / 8233 loss=4.596, loss_v1=0, loss_v2=0, nll_loss=3.308, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=9.91, wps=283.2, ups=0.84, wpb=338.1, bsz=48, num_updates=12810, lr=7.08573e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15432
2023-08-08 22:32:11 - progress_bar.py[line:272] - INFO: epoch 002:   4607 / 8233 loss=4.58, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=283.6, ups=0.84, wpb=338.9, bsz=48, num_updates=12820, lr=7.06635e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15444
2023-08-08 22:32:23 - progress_bar.py[line:272] - INFO: epoch 002:   4617 / 8233 loss=4.562, loss_v1=0, loss_v2=0, nll_loss=3.258, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=285.7, ups=0.84, wpb=341.3, bsz=48, num_updates=12830, lr=7.04697e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15456
2023-08-08 22:32:35 - progress_bar.py[line:272] - INFO: epoch 002:   4627 / 8233 loss=4.636, loss_v1=0, loss_v2=0, nll_loss=3.354, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=10.22, wps=283.9, ups=0.84, wpb=339.5, bsz=48, num_updates=12840, lr=7.02759e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15468
2023-08-08 22:32:47 - progress_bar.py[line:272] - INFO: epoch 002:   4637 / 8233 loss=4.61, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=279.7, ups=0.83, wpb=337.3, bsz=48, num_updates=12850, lr=7.0082e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15480
2023-08-08 22:32:59 - progress_bar.py[line:272] - INFO: epoch 002:   4647 / 8233 loss=4.583, loss_v1=0, loss_v2=0, nll_loss=3.281, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.72, wps=283.1, ups=0.83, wpb=340.5, bsz=48, num_updates=12860, lr=6.98882e-06, gnorm=0.112, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15492
2023-08-08 22:33:11 - progress_bar.py[line:272] - INFO: epoch 002:   4657 / 8233 loss=4.546, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=284.2, ups=0.84, wpb=340, bsz=48, num_updates=12870, lr=6.96944e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15504
2023-08-08 22:33:23 - progress_bar.py[line:272] - INFO: epoch 002:   4667 / 8233 loss=4.608, loss_v1=0, loss_v2=0, nll_loss=3.319, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.98, wps=283.8, ups=0.83, wpb=340.5, bsz=48, num_updates=12880, lr=6.95006e-06, gnorm=0.11, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15516
2023-08-08 22:33:35 - progress_bar.py[line:272] - INFO: epoch 002:   4677 / 8233 loss=4.617, loss_v1=0, loss_v2=0, nll_loss=3.327, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=10.04, wps=279.1, ups=0.83, wpb=335.8, bsz=48, num_updates=12890, lr=6.93068e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15528
2023-08-08 22:33:47 - progress_bar.py[line:272] - INFO: epoch 002:   4687 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=282.4, ups=0.84, wpb=337.5, bsz=48, num_updates=12900, lr=6.9113e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15540
2023-08-08 22:33:59 - progress_bar.py[line:272] - INFO: epoch 002:   4697 / 8233 loss=4.608, loss_v1=0, loss_v2=0, nll_loss=3.319, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.98, wps=283.4, ups=0.84, wpb=339.2, bsz=48, num_updates=12910, lr=6.89192e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15552
2023-08-08 22:34:11 - progress_bar.py[line:272] - INFO: epoch 002:   4707 / 8233 loss=4.544, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=280.6, ups=0.83, wpb=337.5, bsz=48, num_updates=12920, lr=6.87254e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15564
2023-08-08 22:34:23 - progress_bar.py[line:272] - INFO: epoch 002:   4717 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.69, wps=284.2, ups=0.83, wpb=340.4, bsz=48, num_updates=12930, lr=6.85316e-06, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15576
2023-08-08 22:34:36 - progress_bar.py[line:272] - INFO: epoch 002:   4727 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.288, ntokens=331.2, nsentences=48, sample_size=331.2, sample_size_v1=0, sample_size_v2=0, ppl=9.77, wps=272.6, ups=0.82, wpb=331.2, bsz=48, num_updates=12940, lr=6.83377e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15588
2023-08-08 22:34:48 - progress_bar.py[line:272] - INFO: epoch 002:   4737 / 8233 loss=4.599, loss_v1=0, loss_v2=0, nll_loss=3.306, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.89, wps=280.5, ups=0.83, wpb=337.2, bsz=48, num_updates=12950, lr=6.81439e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15600
2023-08-08 22:35:00 - progress_bar.py[line:272] - INFO: epoch 002:   4747 / 8233 loss=4.597, loss_v1=0, loss_v2=0, nll_loss=3.304, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.88, wps=283.2, ups=0.84, wpb=338.7, bsz=48, num_updates=12960, lr=6.79501e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15612
2023-08-08 22:35:11 - progress_bar.py[line:272] - INFO: epoch 002:   4757 / 8233 loss=4.586, loss_v1=0, loss_v2=0, nll_loss=3.284, ntokens=341.9, nsentences=48, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=287.7, ups=0.84, wpb=341.9, bsz=48, num_updates=12970, lr=6.77563e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15624
2023-08-08 22:35:23 - progress_bar.py[line:272] - INFO: epoch 002:   4767 / 8233 loss=4.594, loss_v1=0, loss_v2=0, nll_loss=3.299, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=281.5, ups=0.84, wpb=336.9, bsz=48, num_updates=12980, lr=6.75625e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15636
2023-08-08 22:35:35 - progress_bar.py[line:272] - INFO: epoch 002:   4777 / 8233 loss=4.612, loss_v1=0, loss_v2=0, nll_loss=3.319, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.98, wps=285.4, ups=0.84, wpb=340.4, bsz=48, num_updates=12990, lr=6.73687e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15648
2023-08-08 22:35:47 - progress_bar.py[line:272] - INFO: epoch 002:   4787 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.267, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=278, ups=0.83, wpb=336.8, bsz=48, num_updates=13000, lr=6.71749e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15660
2023-08-08 22:36:00 - progress_bar.py[line:272] - INFO: epoch 002:   4797 / 8233 loss=4.575, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=279.3, ups=0.83, wpb=336.8, bsz=48, num_updates=13010, lr=6.69811e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15672
2023-08-08 22:36:12 - progress_bar.py[line:272] - INFO: epoch 002:   4807 / 8233 loss=4.559, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=281.5, ups=0.83, wpb=339.2, bsz=48, num_updates=13020, lr=6.67873e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15684
2023-08-08 22:36:24 - progress_bar.py[line:272] - INFO: epoch 002:   4817 / 8233 loss=4.578, loss_v1=0, loss_v2=0, nll_loss=3.285, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=283.5, ups=0.84, wpb=338.5, bsz=48, num_updates=13030, lr=6.65934e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15696
2023-08-08 22:36:35 - progress_bar.py[line:272] - INFO: epoch 002:   4827 / 8233 loss=4.585, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=286.1, ups=0.84, wpb=340.3, bsz=48, num_updates=13040, lr=6.63996e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=15708
2023-08-08 22:36:47 - progress_bar.py[line:272] - INFO: epoch 002:   4837 / 8233 loss=4.56, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=281.7, ups=0.83, wpb=338.3, bsz=48, num_updates=13050, lr=6.62058e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15720
2023-08-08 22:36:59 - progress_bar.py[line:272] - INFO: epoch 002:   4847 / 8233 loss=4.595, loss_v1=0, loss_v2=0, nll_loss=3.3, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=278.1, ups=0.83, wpb=336, bsz=48, num_updates=13060, lr=6.6012e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15732
2023-08-08 22:37:12 - progress_bar.py[line:272] - INFO: epoch 002:   4857 / 8233 loss=4.549, loss_v1=0, loss_v2=0, nll_loss=3.246, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=280.7, ups=0.83, wpb=338, bsz=48, num_updates=13070, lr=6.58182e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15744
2023-08-08 22:37:24 - progress_bar.py[line:272] - INFO: epoch 002:   4867 / 8233 loss=4.59, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=282.9, ups=0.83, wpb=340.1, bsz=48, num_updates=13080, lr=6.56244e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15756
2023-08-08 22:37:35 - progress_bar.py[line:272] - INFO: epoch 002:   4877 / 8233 loss=4.567, loss_v1=0, loss_v2=0, nll_loss=3.265, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.61, wps=286.2, ups=0.84, wpb=339.9, bsz=48, num_updates=13090, lr=6.54306e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15768
2023-08-08 22:37:47 - progress_bar.py[line:272] - INFO: epoch 002:   4887 / 8233 loss=4.588, loss_v1=0, loss_v2=0, nll_loss=3.293, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=281.7, ups=0.83, wpb=338.3, bsz=48, num_updates=13100, lr=6.52368e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15780
2023-08-08 22:38:00 - progress_bar.py[line:272] - INFO: epoch 002:   4897 / 8233 loss=4.617, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=280.8, ups=0.83, wpb=338.6, bsz=48, num_updates=13110, lr=6.5043e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15792
2023-08-08 22:38:12 - progress_bar.py[line:272] - INFO: epoch 002:   4907 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=281.7, ups=0.83, wpb=338.3, bsz=48, num_updates=13120, lr=6.48492e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15804
2023-08-08 22:38:23 - progress_bar.py[line:272] - INFO: epoch 002:   4917 / 8233 loss=4.584, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=9.82, wps=283.3, ups=0.84, wpb=338.8, bsz=48, num_updates=13130, lr=6.46553e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15816
2023-08-08 22:38:35 - progress_bar.py[line:272] - INFO: epoch 002:   4927 / 8233 loss=4.59, loss_v1=0, loss_v2=0, nll_loss=3.298, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=285.1, ups=0.84, wpb=339.7, bsz=48, num_updates=13140, lr=6.44615e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15828
2023-08-08 22:38:47 - progress_bar.py[line:272] - INFO: epoch 002:   4937 / 8233 loss=4.573, loss_v1=0, loss_v2=0, nll_loss=3.281, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=9.72, wps=284.5, ups=0.84, wpb=338.2, bsz=48, num_updates=13150, lr=6.42677e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15840
2023-08-08 22:38:59 - progress_bar.py[line:272] - INFO: epoch 002:   4947 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=286.8, ups=0.84, wpb=340.5, bsz=48, num_updates=13160, lr=6.40739e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15852
2023-08-08 22:39:11 - progress_bar.py[line:272] - INFO: epoch 002:   4957 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=282.3, ups=0.84, wpb=337.7, bsz=48, num_updates=13170, lr=6.38801e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15864
2023-08-08 22:39:23 - progress_bar.py[line:272] - INFO: epoch 002:   4967 / 8233 loss=4.534, loss_v1=0, loss_v2=0, nll_loss=3.232, ntokens=342.6, nsentences=48, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=287.1, ups=0.84, wpb=342.6, bsz=48, num_updates=13180, lr=6.36863e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15876
2023-08-08 22:39:35 - progress_bar.py[line:272] - INFO: epoch 002:   4977 / 8233 loss=4.566, loss_v1=0, loss_v2=0, nll_loss=3.267, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=284, ups=0.83, wpb=340.9, bsz=48, num_updates=13190, lr=6.34925e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15888
2023-08-08 22:39:47 - progress_bar.py[line:272] - INFO: epoch 002:   4987 / 8233 loss=4.579, loss_v1=0, loss_v2=0, nll_loss=3.286, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=282.1, ups=0.83, wpb=339.1, bsz=48, num_updates=13200, lr=6.32987e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15900
2023-08-08 22:39:59 - progress_bar.py[line:272] - INFO: epoch 002:   4997 / 8233 loss=4.564, loss_v1=0, loss_v2=0, nll_loss=3.269, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=280.2, ups=0.83, wpb=337.4, bsz=48, num_updates=13210, lr=6.31049e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15912
2023-08-08 22:40:11 - progress_bar.py[line:272] - INFO: epoch 002:   5007 / 8233 loss=4.589, loss_v1=0, loss_v2=0, nll_loss=3.298, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=277.6, ups=0.83, wpb=335.2, bsz=48, num_updates=13220, lr=6.2911e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15924
2023-08-08 22:40:23 - progress_bar.py[line:272] - INFO: epoch 002:   5017 / 8233 loss=4.594, loss_v1=0, loss_v2=0, nll_loss=3.306, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.89, wps=281.2, ups=0.83, wpb=337.7, bsz=48, num_updates=13230, lr=6.27172e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15936
2023-08-08 22:40:35 - progress_bar.py[line:272] - INFO: epoch 002:   5027 / 8233 loss=4.582, loss_v1=0, loss_v2=0, nll_loss=3.292, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.79, wps=285, ups=0.84, wpb=338.5, bsz=48, num_updates=13240, lr=6.25234e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15948
2023-08-08 22:40:47 - progress_bar.py[line:272] - INFO: epoch 002:   5037 / 8233 loss=4.6, loss_v1=0, loss_v2=0, nll_loss=3.303, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.87, wps=282.5, ups=0.84, wpb=337.5, bsz=48, num_updates=13250, lr=6.23296e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15960
2023-08-08 22:40:59 - progress_bar.py[line:272] - INFO: epoch 002:   5047 / 8233 loss=4.551, loss_v1=0, loss_v2=0, nll_loss=3.249, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=279.9, ups=0.83, wpb=336.6, bsz=48, num_updates=13260, lr=6.21358e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15972
2023-08-08 22:41:11 - progress_bar.py[line:272] - INFO: epoch 002:   5057 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=283.9, ups=0.84, wpb=340, bsz=48, num_updates=13270, lr=6.1942e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15984
2023-08-08 22:41:23 - progress_bar.py[line:272] - INFO: epoch 002:   5067 / 8233 loss=4.549, loss_v1=0, loss_v2=0, nll_loss=3.253, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=278.5, ups=0.83, wpb=336.5, bsz=48, num_updates=13280, lr=6.17482e-06, gnorm=0.112, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=15996
2023-08-08 22:41:35 - progress_bar.py[line:272] - INFO: epoch 002:   5077 / 8233 loss=4.571, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=287.1, ups=0.84, wpb=340.5, bsz=48, num_updates=13290, lr=6.15544e-06, gnorm=0.1, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16008
2023-08-08 22:41:47 - progress_bar.py[line:272] - INFO: epoch 002:   5087 / 8233 loss=4.582, loss_v1=0, loss_v2=0, nll_loss=3.282, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.73, wps=282.1, ups=0.84, wpb=337.5, bsz=48, num_updates=13300, lr=6.13606e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16020
2023-08-08 22:41:59 - progress_bar.py[line:272] - INFO: epoch 002:   5097 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.293, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=277.9, ups=0.83, wpb=335.9, bsz=48, num_updates=13310, lr=6.11667e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16032
2023-08-08 22:42:11 - progress_bar.py[line:272] - INFO: epoch 002:   5107 / 8233 loss=4.564, loss_v1=0, loss_v2=0, nll_loss=3.266, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.62, wps=281.5, ups=0.83, wpb=338.3, bsz=48, num_updates=13320, lr=6.09729e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16044
2023-08-08 22:42:23 - progress_bar.py[line:272] - INFO: epoch 002:   5117 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=280.8, ups=0.83, wpb=337.1, bsz=48, num_updates=13330, lr=6.07791e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16056
2023-08-08 22:42:35 - progress_bar.py[line:272] - INFO: epoch 002:   5127 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.274, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=285.5, ups=0.84, wpb=341.3, bsz=48, num_updates=13340, lr=6.05853e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16068
2023-08-08 22:42:47 - progress_bar.py[line:272] - INFO: epoch 002:   5137 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.255, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=285.2, ups=0.84, wpb=341, bsz=48, num_updates=13350, lr=6.03915e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16080
2023-08-08 22:42:59 - progress_bar.py[line:272] - INFO: epoch 002:   5147 / 8233 loss=4.565, loss_v1=0, loss_v2=0, nll_loss=3.27, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=283.5, ups=0.84, wpb=339.4, bsz=48, num_updates=13360, lr=6.01977e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16092
2023-08-08 22:43:11 - progress_bar.py[line:272] - INFO: epoch 002:   5157 / 8233 loss=4.58, loss_v1=0, loss_v2=0, nll_loss=3.283, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=279.6, ups=0.83, wpb=337.4, bsz=48, num_updates=13370, lr=6.00039e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16104
2023-08-08 22:43:23 - progress_bar.py[line:272] - INFO: epoch 002:   5167 / 8233 loss=4.607, loss_v1=0, loss_v2=0, nll_loss=3.311, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.92, wps=282, ups=0.84, wpb=337.2, bsz=48, num_updates=13380, lr=5.98101e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16116
2023-08-08 22:43:35 - progress_bar.py[line:272] - INFO: epoch 002:   5177 / 8233 loss=4.527, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=281, ups=0.83, wpb=339.1, bsz=48, num_updates=13390, lr=5.96163e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16128
2023-08-08 22:43:47 - progress_bar.py[line:272] - INFO: epoch 002:   5187 / 8233 loss=4.581, loss_v1=0, loss_v2=0, nll_loss=3.284, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=276.4, ups=0.83, wpb=334.7, bsz=48, num_updates=13400, lr=5.94224e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16140
2023-08-08 22:43:59 - progress_bar.py[line:272] - INFO: epoch 002:   5197 / 8233 loss=4.595, loss_v1=0, loss_v2=0, nll_loss=3.3, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=280.5, ups=0.83, wpb=337.9, bsz=48, num_updates=13410, lr=5.92286e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16152
2023-08-08 22:44:11 - progress_bar.py[line:272] - INFO: epoch 002:   5207 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=284.8, ups=0.84, wpb=340.7, bsz=48, num_updates=13420, lr=5.90348e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16164
2023-08-08 22:44:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 22:44:24 - progress_bar.py[line:272] - INFO: epoch 002:   5218 / 8233 loss=4.616, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=254.8, ups=0.76, wpb=336.8, bsz=48, num_updates=13430, lr=5.8841e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=13, gb_free=14.5, wall=16177
2023-08-08 22:44:36 - progress_bar.py[line:272] - INFO: epoch 002:   5228 / 8233 loss=4.564, loss_v1=0, loss_v2=0, nll_loss=3.264, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=284.4, ups=0.84, wpb=340.3, bsz=48, num_updates=13440, lr=5.86472e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16189
2023-08-08 22:44:49 - progress_bar.py[line:272] - INFO: epoch 002:   5238 / 8233 loss=4.561, loss_v1=0, loss_v2=0, nll_loss=3.262, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.59, wps=278.9, ups=0.83, wpb=338, bsz=48, num_updates=13450, lr=5.84534e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16201
2023-08-08 22:45:00 - progress_bar.py[line:272] - INFO: epoch 002:   5248 / 8233 loss=4.525, loss_v1=0, loss_v2=0, nll_loss=3.226, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=284.9, ups=0.84, wpb=340, bsz=48, num_updates=13460, lr=5.82596e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16213
2023-08-08 22:45:12 - progress_bar.py[line:272] - INFO: epoch 002:   5258 / 8233 loss=4.548, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=283.4, ups=0.84, wpb=338.9, bsz=48, num_updates=13470, lr=5.80658e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16225
2023-08-08 22:45:25 - progress_bar.py[line:272] - INFO: epoch 002:   5268 / 8233 loss=4.583, loss_v1=0, loss_v2=0, nll_loss=3.286, ntokens=332.3, nsentences=48, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=273.6, ups=0.82, wpb=332.3, bsz=48, num_updates=13480, lr=5.7872e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16237
2023-08-08 22:45:37 - progress_bar.py[line:272] - INFO: epoch 002:   5278 / 8233 loss=4.545, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=279.6, ups=0.83, wpb=336.9, bsz=48, num_updates=13490, lr=5.76781e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16250
2023-08-08 22:45:49 - progress_bar.py[line:272] - INFO: epoch 002:   5288 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=280.9, ups=0.82, wpb=340.5, bsz=48, num_updates=13500, lr=5.74843e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16262
2023-08-08 22:46:01 - progress_bar.py[line:272] - INFO: epoch 002:   5298 / 8233 loss=4.552, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=341.5, nsentences=48, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=286.4, ups=0.84, wpb=341.5, bsz=48, num_updates=13510, lr=5.72905e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16274
2023-08-08 22:46:13 - progress_bar.py[line:272] - INFO: epoch 002:   5308 / 8233 loss=4.549, loss_v1=0, loss_v2=0, nll_loss=3.255, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=279, ups=0.83, wpb=337.3, bsz=48, num_updates=13520, lr=5.70967e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16286
2023-08-08 22:46:25 - progress_bar.py[line:272] - INFO: epoch 002:   5318 / 8233 loss=4.583, loss_v1=0, loss_v2=0, nll_loss=3.284, ntokens=334.4, nsentences=48, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=277.1, ups=0.83, wpb=334.4, bsz=48, num_updates=13530, lr=5.69029e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16298
2023-08-08 22:46:37 - progress_bar.py[line:272] - INFO: epoch 002:   5328 / 8233 loss=4.551, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=284.9, ups=0.84, wpb=340.1, bsz=48, num_updates=13540, lr=5.67091e-06, gnorm=0.101, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16310
2023-08-08 22:46:49 - progress_bar.py[line:272] - INFO: epoch 002:   5338 / 8233 loss=4.58, loss_v1=0, loss_v2=0, nll_loss=3.288, ntokens=334.9, nsentences=48, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=276.6, ups=0.83, wpb=334.9, bsz=48, num_updates=13550, lr=5.65153e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16322
2023-08-08 22:47:01 - progress_bar.py[line:272] - INFO: epoch 002:   5348 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.257, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=283.3, ups=0.84, wpb=339.2, bsz=48, num_updates=13560, lr=5.63215e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16334
2023-08-08 22:47:13 - progress_bar.py[line:272] - INFO: epoch 002:   5358 / 8233 loss=4.581, loss_v1=0, loss_v2=0, nll_loss=3.284, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=280.5, ups=0.83, wpb=337.8, bsz=48, num_updates=13570, lr=5.61277e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16346
2023-08-08 22:47:25 - progress_bar.py[line:272] - INFO: epoch 002:   5368 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=287.7, ups=0.84, wpb=342.3, bsz=48, num_updates=13580, lr=5.59338e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16358
2023-08-08 22:47:37 - progress_bar.py[line:272] - INFO: epoch 002:   5378 / 8233 loss=4.57, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=282.2, ups=0.83, wpb=338.2, bsz=48, num_updates=13590, lr=5.574e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16370
2023-08-08 22:47:49 - progress_bar.py[line:272] - INFO: epoch 002:   5388 / 8233 loss=4.622, loss_v1=0, loss_v2=0, nll_loss=3.332, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=10.07, wps=279.8, ups=0.83, wpb=337.3, bsz=48, num_updates=13600, lr=5.55462e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16382
2023-08-08 22:48:01 - progress_bar.py[line:272] - INFO: epoch 002:   5398 / 8233 loss=4.531, loss_v1=0, loss_v2=0, nll_loss=3.228, ntokens=341.5, nsentences=48, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=283.2, ups=0.83, wpb=341.5, bsz=48, num_updates=13610, lr=5.53524e-06, gnorm=0.1, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16394
2023-08-08 22:48:13 - progress_bar.py[line:272] - INFO: epoch 002:   5408 / 8233 loss=4.559, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=282.2, ups=0.83, wpb=338.9, bsz=48, num_updates=13620, lr=5.51586e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16406
2023-08-08 22:48:25 - progress_bar.py[line:272] - INFO: epoch 002:   5418 / 8233 loss=4.589, loss_v1=0, loss_v2=0, nll_loss=3.301, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=9.86, wps=283.1, ups=0.83, wpb=340, bsz=48, num_updates=13630, lr=5.49648e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16418
2023-08-08 22:48:37 - progress_bar.py[line:272] - INFO: epoch 002:   5428 / 8233 loss=4.588, loss_v1=0, loss_v2=0, nll_loss=3.301, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=9.86, wps=279.5, ups=0.83, wpb=336.6, bsz=48, num_updates=13640, lr=5.4771e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16430
2023-08-08 22:48:49 - progress_bar.py[line:272] - INFO: epoch 002:   5438 / 8233 loss=4.59, loss_v1=0, loss_v2=0, nll_loss=3.297, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=9.83, wps=284.3, ups=0.84, wpb=339.8, bsz=48, num_updates=13650, lr=5.45772e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16442
2023-08-08 22:49:01 - progress_bar.py[line:272] - INFO: epoch 002:   5448 / 8233 loss=4.608, loss_v1=0, loss_v2=0, nll_loss=3.314, ntokens=330.3, nsentences=48, sample_size=330.3, sample_size_v1=0, sample_size_v2=0, ppl=9.95, wps=273.1, ups=0.83, wpb=330.3, bsz=48, num_updates=13660, lr=5.43834e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16454
2023-08-08 22:49:13 - progress_bar.py[line:272] - INFO: epoch 002:   5458 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=282, ups=0.83, wpb=338.2, bsz=48, num_updates=13670, lr=5.41895e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16466
2023-08-08 22:49:25 - progress_bar.py[line:272] - INFO: epoch 002:   5468 / 8233 loss=4.575, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=277.1, ups=0.82, wpb=337, bsz=48, num_updates=13680, lr=5.39957e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16478
2023-08-08 22:49:37 - progress_bar.py[line:272] - INFO: epoch 002:   5478 / 8233 loss=4.541, loss_v1=0, loss_v2=0, nll_loss=3.237, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=283.6, ups=0.83, wpb=340.1, bsz=48, num_updates=13690, lr=5.38019e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16490
2023-08-08 22:49:49 - progress_bar.py[line:272] - INFO: epoch 002:   5488 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.253, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=280.6, ups=0.83, wpb=337.2, bsz=48, num_updates=13700, lr=5.36081e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16502
2023-08-08 22:50:01 - progress_bar.py[line:272] - INFO: epoch 002:   5498 / 8233 loss=4.583, loss_v1=0, loss_v2=0, nll_loss=3.287, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=282.3, ups=0.83, wpb=338.7, bsz=48, num_updates=13710, lr=5.34143e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16514
2023-08-08 22:50:13 - progress_bar.py[line:272] - INFO: epoch 002:   5508 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.294, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=283.6, ups=0.83, wpb=339.7, bsz=48, num_updates=13720, lr=5.32205e-06, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16526
2023-08-08 22:50:25 - progress_bar.py[line:272] - INFO: epoch 002:   5518 / 8233 loss=4.534, loss_v1=0, loss_v2=0, nll_loss=3.232, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=284.1, ups=0.83, wpb=340.4, bsz=48, num_updates=13730, lr=5.30267e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16538
2023-08-08 22:50:37 - progress_bar.py[line:272] - INFO: epoch 002:   5528 / 8233 loss=4.523, loss_v1=0, loss_v2=0, nll_loss=3.221, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=281.2, ups=0.83, wpb=338.4, bsz=48, num_updates=13740, lr=5.28329e-06, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16550
2023-08-08 22:50:49 - progress_bar.py[line:272] - INFO: epoch 002:   5538 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=285, ups=0.84, wpb=340.1, bsz=48, num_updates=13750, lr=5.26391e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16562
2023-08-08 22:51:01 - progress_bar.py[line:272] - INFO: epoch 002:   5548 / 8233 loss=4.591, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=330.7, nsentences=48, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=270.6, ups=0.82, wpb=330.7, bsz=48, num_updates=13760, lr=5.24452e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16574
2023-08-08 22:51:13 - progress_bar.py[line:272] - INFO: epoch 002:   5558 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.272, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=282, ups=0.83, wpb=338.5, bsz=48, num_updates=13770, lr=5.22514e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16586
2023-08-08 22:51:25 - progress_bar.py[line:272] - INFO: epoch 002:   5568 / 8233 loss=4.576, loss_v1=0, loss_v2=0, nll_loss=3.285, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=280, ups=0.83, wpb=336.8, bsz=48, num_updates=13780, lr=5.20576e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16598
2023-08-08 22:51:37 - progress_bar.py[line:272] - INFO: epoch 002:   5578 / 8233 loss=4.546, loss_v1=0, loss_v2=0, nll_loss=3.251, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=285.6, ups=0.83, wpb=342.3, bsz=48, num_updates=13790, lr=5.18638e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16610
2023-08-08 22:51:49 - progress_bar.py[line:272] - INFO: epoch 002:   5588 / 8233 loss=4.606, loss_v1=0, loss_v2=0, nll_loss=3.314, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.94, wps=283.1, ups=0.83, wpb=339.7, bsz=48, num_updates=13800, lr=5.167e-06, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16622
2023-08-08 22:52:01 - progress_bar.py[line:272] - INFO: epoch 002:   5598 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=284.5, ups=0.84, wpb=340.1, bsz=48, num_updates=13810, lr=5.14762e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16634
2023-08-08 22:52:13 - progress_bar.py[line:272] - INFO: epoch 002:   5608 / 8233 loss=4.542, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=280.5, ups=0.83, wpb=337.1, bsz=48, num_updates=13820, lr=5.12824e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16646
2023-08-08 22:52:25 - progress_bar.py[line:272] - INFO: epoch 002:   5618 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.282, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.73, wps=283.6, ups=0.84, wpb=339, bsz=48, num_updates=13830, lr=5.10886e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16658
2023-08-08 22:52:37 - progress_bar.py[line:272] - INFO: epoch 002:   5628 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=283, ups=0.84, wpb=338.7, bsz=48, num_updates=13840, lr=5.08948e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16670
2023-08-08 22:52:49 - progress_bar.py[line:272] - INFO: epoch 002:   5638 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.277, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=9.69, wps=279.3, ups=0.83, wpb=335.6, bsz=48, num_updates=13850, lr=5.07009e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16682
2023-08-08 22:53:01 - progress_bar.py[line:272] - INFO: epoch 002:   5648 / 8233 loss=4.625, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=284.4, ups=0.84, wpb=339.1, bsz=48, num_updates=13860, lr=5.05071e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16694
2023-08-08 22:53:13 - progress_bar.py[line:272] - INFO: epoch 002:   5658 / 8233 loss=4.584, loss_v1=0, loss_v2=0, nll_loss=3.287, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=278.9, ups=0.83, wpb=336, bsz=48, num_updates=13870, lr=5.03133e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16706
2023-08-08 22:53:25 - progress_bar.py[line:272] - INFO: epoch 002:   5668 / 8233 loss=4.562, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=279, ups=0.83, wpb=336.1, bsz=48, num_updates=13880, lr=5.01195e-06, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16718
2023-08-08 22:53:37 - progress_bar.py[line:272] - INFO: epoch 002:   5678 / 8233 loss=4.573, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=281.4, ups=0.83, wpb=337.7, bsz=48, num_updates=13890, lr=4.99257e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16730
2023-08-08 22:53:49 - progress_bar.py[line:272] - INFO: epoch 002:   5688 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=336.6, nsentences=48, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=279.5, ups=0.83, wpb=336.6, bsz=48, num_updates=13900, lr=4.97319e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16742
2023-08-08 22:54:01 - progress_bar.py[line:272] - INFO: epoch 002:   5698 / 8233 loss=4.622, loss_v1=0, loss_v2=0, nll_loss=3.326, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=10.03, wps=281.5, ups=0.83, wpb=337.8, bsz=48, num_updates=13910, lr=4.95381e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16754
2023-08-08 22:54:14 - progress_bar.py[line:272] - INFO: epoch 002:   5708 / 8233 loss=4.548, loss_v1=0, loss_v2=0, nll_loss=3.254, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=280.3, ups=0.83, wpb=337.9, bsz=48, num_updates=13920, lr=4.93443e-06, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16766
2023-08-08 22:54:26 - progress_bar.py[line:272] - INFO: epoch 002:   5718 / 8233 loss=4.595, loss_v1=0, loss_v2=0, nll_loss=3.303, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=9.87, wps=280.4, ups=0.83, wpb=337.6, bsz=48, num_updates=13930, lr=4.91505e-06, gnorm=0.111, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16778
2023-08-08 22:54:38 - progress_bar.py[line:272] - INFO: epoch 002:   5728 / 8233 loss=4.547, loss_v1=0, loss_v2=0, nll_loss=3.25, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=9.51, wps=278.6, ups=0.83, wpb=335.1, bsz=48, num_updates=13940, lr=4.89567e-06, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=16790
2023-08-08 22:54:50 - progress_bar.py[line:272] - INFO: epoch 002:   5738 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.69, wps=281.9, ups=0.83, wpb=338.6, bsz=48, num_updates=13950, lr=4.87628e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16802
2023-08-08 22:55:02 - progress_bar.py[line:272] - INFO: epoch 002:   5748 / 8233 loss=4.542, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=282.3, ups=0.83, wpb=339.6, bsz=48, num_updates=13960, lr=4.8569e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16815
2023-08-08 22:55:14 - progress_bar.py[line:272] - INFO: epoch 002:   5758 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.25, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.51, wps=279.8, ups=0.83, wpb=337.9, bsz=48, num_updates=13970, lr=4.83752e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16827
2023-08-08 22:55:26 - progress_bar.py[line:272] - INFO: epoch 002:   5768 / 8233 loss=4.571, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=281, ups=0.83, wpb=338.4, bsz=48, num_updates=13980, lr=4.81814e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16839
2023-08-08 22:55:38 - progress_bar.py[line:272] - INFO: epoch 002:   5778 / 8233 loss=4.562, loss_v1=0, loss_v2=0, nll_loss=3.264, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=280.2, ups=0.83, wpb=338.1, bsz=48, num_updates=13990, lr=4.79876e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16851
2023-08-08 22:55:50 - progress_bar.py[line:272] - INFO: epoch 002:   5788 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.257, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=283.2, ups=0.83, wpb=339.3, bsz=48, num_updates=14000, lr=4.77938e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16863
2023-08-08 22:56:02 - progress_bar.py[line:272] - INFO: epoch 002:   5798 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=281.6, ups=0.83, wpb=337.9, bsz=48, num_updates=14010, lr=4.76e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16875
2023-08-08 22:56:14 - progress_bar.py[line:272] - INFO: epoch 002:   5808 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.69, wps=283.7, ups=0.84, wpb=339.4, bsz=48, num_updates=14020, lr=4.74062e-06, gnorm=0.099, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16887
2023-08-08 22:56:26 - progress_bar.py[line:272] - INFO: epoch 002:   5818 / 8233 loss=4.525, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=279.4, ups=0.83, wpb=337.5, bsz=48, num_updates=14030, lr=4.72124e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16899
2023-08-08 22:56:38 - progress_bar.py[line:272] - INFO: epoch 002:   5828 / 8233 loss=4.559, loss_v1=0, loss_v2=0, nll_loss=3.266, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.62, wps=282.3, ups=0.83, wpb=339.2, bsz=48, num_updates=14040, lr=4.70185e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16911
2023-08-08 22:56:50 - progress_bar.py[line:272] - INFO: epoch 002:   5838 / 8233 loss=4.531, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=281.2, ups=0.83, wpb=339, bsz=48, num_updates=14050, lr=4.68247e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16923
2023-08-08 22:57:02 - progress_bar.py[line:272] - INFO: epoch 002:   5848 / 8233 loss=4.549, loss_v1=0, loss_v2=0, nll_loss=3.247, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=280.9, ups=0.83, wpb=338.4, bsz=48, num_updates=14060, lr=4.66309e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16935
2023-08-08 22:57:14 - progress_bar.py[line:272] - INFO: epoch 002:   5858 / 8233 loss=4.588, loss_v1=0, loss_v2=0, nll_loss=3.293, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=284.6, ups=0.84, wpb=339.5, bsz=48, num_updates=14070, lr=4.64371e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16947
2023-08-08 22:57:26 - progress_bar.py[line:272] - INFO: epoch 002:   5868 / 8233 loss=4.528, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=284.8, ups=0.84, wpb=340, bsz=48, num_updates=14080, lr=4.62433e-06, gnorm=0.1, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16959
2023-08-08 22:57:38 - progress_bar.py[line:272] - INFO: epoch 002:   5878 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.27, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=283.2, ups=0.83, wpb=339.5, bsz=48, num_updates=14090, lr=4.60495e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16971
2023-08-08 22:57:50 - progress_bar.py[line:272] - INFO: epoch 002:   5888 / 8233 loss=4.542, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=277.8, ups=0.82, wpb=338, bsz=48, num_updates=14100, lr=4.58557e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16983
2023-08-08 22:58:02 - progress_bar.py[line:272] - INFO: epoch 002:   5898 / 8233 loss=4.552, loss_v1=0, loss_v2=0, nll_loss=3.254, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=285, ups=0.84, wpb=337.9, bsz=48, num_updates=14110, lr=4.56619e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=16995
2023-08-08 22:58:14 - progress_bar.py[line:272] - INFO: epoch 002:   5908 / 8233 loss=4.541, loss_v1=0, loss_v2=0, nll_loss=3.247, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=278.8, ups=0.83, wpb=337.1, bsz=48, num_updates=14120, lr=4.54681e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17007
2023-08-08 22:58:26 - progress_bar.py[line:272] - INFO: epoch 002:   5918 / 8233 loss=4.593, loss_v1=0, loss_v2=0, nll_loss=3.293, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=281.1, ups=0.83, wpb=337.2, bsz=48, num_updates=14130, lr=4.52742e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17019
2023-08-08 22:58:38 - progress_bar.py[line:272] - INFO: epoch 002:   5928 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=279.7, ups=0.83, wpb=336.4, bsz=48, num_updates=14140, lr=4.50804e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17031
2023-08-08 22:58:50 - progress_bar.py[line:272] - INFO: epoch 002:   5938 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=278.5, ups=0.83, wpb=335.9, bsz=48, num_updates=14150, lr=4.48866e-06, gnorm=0.109, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17043
2023-08-08 22:59:02 - progress_bar.py[line:272] - INFO: epoch 002:   5948 / 8233 loss=4.576, loss_v1=0, loss_v2=0, nll_loss=3.283, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.73, wps=282.5, ups=0.83, wpb=338.9, bsz=48, num_updates=14160, lr=4.46928e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17055
2023-08-08 22:59:14 - progress_bar.py[line:272] - INFO: epoch 002:   5958 / 8233 loss=4.561, loss_v1=0, loss_v2=0, nll_loss=3.262, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.59, wps=284.8, ups=0.84, wpb=340.9, bsz=48, num_updates=14170, lr=4.4499e-06, gnorm=0.1, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17067
2023-08-08 22:59:26 - progress_bar.py[line:272] - INFO: epoch 002:   5968 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.257, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=284.7, ups=0.84, wpb=339.4, bsz=48, num_updates=14180, lr=4.43052e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17079
2023-08-08 22:59:38 - progress_bar.py[line:272] - INFO: epoch 002:   5978 / 8233 loss=4.545, loss_v1=0, loss_v2=0, nll_loss=3.246, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=278.4, ups=0.83, wpb=336.5, bsz=48, num_updates=14190, lr=4.41114e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17091
2023-08-08 22:59:50 - progress_bar.py[line:272] - INFO: epoch 002:   5988 / 8233 loss=4.55, loss_v1=0, loss_v2=0, nll_loss=3.254, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=281.4, ups=0.83, wpb=339.3, bsz=48, num_updates=14200, lr=4.39176e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17103
2023-08-08 23:00:02 - progress_bar.py[line:272] - INFO: epoch 002:   5998 / 8233 loss=4.544, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=284.5, ups=0.83, wpb=341.1, bsz=48, num_updates=14210, lr=4.37238e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17115
2023-08-08 23:00:14 - progress_bar.py[line:272] - INFO: epoch 002:   6008 / 8233 loss=4.561, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=283.2, ups=0.83, wpb=339.8, bsz=48, num_updates=14220, lr=4.35299e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17127
2023-08-08 23:00:26 - progress_bar.py[line:272] - INFO: epoch 002:   6018 / 8233 loss=4.536, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=282.1, ups=0.83, wpb=339.6, bsz=48, num_updates=14230, lr=4.33361e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17139
2023-08-08 23:00:38 - progress_bar.py[line:272] - INFO: epoch 002:   6028 / 8233 loss=4.537, loss_v1=0, loss_v2=0, nll_loss=3.237, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=282.7, ups=0.84, wpb=338.4, bsz=48, num_updates=14240, lr=4.31423e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17151
2023-08-08 23:00:50 - progress_bar.py[line:272] - INFO: epoch 002:   6038 / 8233 loss=4.58, loss_v1=0, loss_v2=0, nll_loss=3.281, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.72, wps=283.6, ups=0.83, wpb=340.2, bsz=48, num_updates=14250, lr=4.29485e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17163
2023-08-08 23:01:02 - progress_bar.py[line:272] - INFO: epoch 002:   6048 / 8233 loss=4.589, loss_v1=0, loss_v2=0, nll_loss=3.294, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=283.4, ups=0.83, wpb=339.5, bsz=48, num_updates=14260, lr=4.27547e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17175
2023-08-08 23:01:14 - progress_bar.py[line:272] - INFO: epoch 002:   6058 / 8233 loss=4.584, loss_v1=0, loss_v2=0, nll_loss=3.295, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.81, wps=281.1, ups=0.83, wpb=337.7, bsz=48, num_updates=14270, lr=4.25609e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17187
2023-08-08 23:01:26 - progress_bar.py[line:272] - INFO: epoch 002:   6068 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=276.3, ups=0.83, wpb=334.7, bsz=48, num_updates=14280, lr=4.23671e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17199
2023-08-08 23:01:38 - progress_bar.py[line:272] - INFO: epoch 002:   6078 / 8233 loss=4.524, loss_v1=0, loss_v2=0, nll_loss=3.218, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=278.7, ups=0.83, wpb=335.4, bsz=48, num_updates=14290, lr=4.21733e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17211
2023-08-08 23:01:50 - progress_bar.py[line:272] - INFO: epoch 002:   6088 / 8233 loss=4.525, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=283.3, ups=0.84, wpb=339.2, bsz=48, num_updates=14300, lr=4.19795e-06, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17223
2023-08-08 23:02:02 - progress_bar.py[line:272] - INFO: epoch 002:   6098 / 8233 loss=4.566, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=341.3, nsentences=48, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=285, ups=0.84, wpb=341.3, bsz=48, num_updates=14310, lr=4.17856e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17235
2023-08-08 23:02:14 - progress_bar.py[line:272] - INFO: epoch 002:   6108 / 8233 loss=4.577, loss_v1=0, loss_v2=0, nll_loss=3.281, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.72, wps=282.2, ups=0.83, wpb=339.5, bsz=48, num_updates=14320, lr=4.15918e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17247
2023-08-08 23:02:26 - progress_bar.py[line:272] - INFO: epoch 002:   6118 / 8233 loss=4.567, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=278.4, ups=0.83, wpb=337.2, bsz=48, num_updates=14330, lr=4.1398e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17259
2023-08-08 23:02:38 - progress_bar.py[line:272] - INFO: epoch 002:   6128 / 8233 loss=4.552, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=281.1, ups=0.83, wpb=339, bsz=48, num_updates=14340, lr=4.12042e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17271
2023-08-08 23:02:50 - progress_bar.py[line:272] - INFO: epoch 002:   6138 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.277, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=281.7, ups=0.83, wpb=338.6, bsz=48, num_updates=14350, lr=4.10104e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17283
2023-08-08 23:03:03 - progress_bar.py[line:272] - INFO: epoch 002:   6148 / 8233 loss=4.489, loss_v1=0, loss_v2=0, nll_loss=3.185, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=9.09, wps=276.4, ups=0.82, wpb=335.3, bsz=48, num_updates=14360, lr=4.08166e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17295
2023-08-08 23:03:15 - progress_bar.py[line:272] - INFO: epoch 002:   6158 / 8233 loss=4.532, loss_v1=0, loss_v2=0, nll_loss=3.226, ntokens=340, nsentences=48, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=284.2, ups=0.84, wpb=340, bsz=48, num_updates=14370, lr=4.06228e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17307
2023-08-08 23:03:27 - progress_bar.py[line:272] - INFO: epoch 002:   6168 / 8233 loss=4.573, loss_v1=0, loss_v2=0, nll_loss=3.279, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=280.4, ups=0.83, wpb=337.5, bsz=48, num_updates=14380, lr=4.0429e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17319
2023-08-08 23:03:38 - progress_bar.py[line:272] - INFO: epoch 002:   6178 / 8233 loss=4.567, loss_v1=0, loss_v2=0, nll_loss=3.272, ntokens=342.5, nsentences=48, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=288.7, ups=0.84, wpb=342.5, bsz=48, num_updates=14390, lr=4.02352e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17331
2023-08-08 23:03:51 - progress_bar.py[line:272] - INFO: epoch 002:   6188 / 8233 loss=4.54, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=279.4, ups=0.83, wpb=336.9, bsz=48, num_updates=14400, lr=4.00413e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17343
2023-08-08 23:04:03 - progress_bar.py[line:272] - INFO: epoch 002:   6198 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=279.1, ups=0.83, wpb=337.4, bsz=48, num_updates=14410, lr=3.98475e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17356
2023-08-08 23:04:15 - progress_bar.py[line:272] - INFO: epoch 002:   6208 / 8233 loss=4.551, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=281.3, ups=0.83, wpb=338.6, bsz=48, num_updates=14420, lr=3.96537e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17368
2023-08-08 23:04:27 - progress_bar.py[line:272] - INFO: epoch 002:   6218 / 8233 loss=4.534, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=282.5, ups=0.83, wpb=338.4, bsz=48, num_updates=14430, lr=3.94599e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17380
2023-08-08 23:04:39 - progress_bar.py[line:272] - INFO: epoch 002:   6228 / 8233 loss=4.566, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=279, ups=0.83, wpb=336.8, bsz=48, num_updates=14440, lr=3.92661e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17392
2023-08-08 23:04:51 - progress_bar.py[line:272] - INFO: epoch 002:   6238 / 8233 loss=4.534, loss_v1=0, loss_v2=0, nll_loss=3.243, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=282.6, ups=0.84, wpb=338.4, bsz=48, num_updates=14450, lr=3.90723e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=17404
2023-08-08 23:05:03 - progress_bar.py[line:272] - INFO: epoch 002:   6248 / 8233 loss=4.566, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=282.1, ups=0.83, wpb=339.4, bsz=48, num_updates=14460, lr=3.88785e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17416
2023-08-08 23:05:15 - progress_bar.py[line:272] - INFO: epoch 002:   6258 / 8233 loss=4.539, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=283.3, ups=0.83, wpb=340.6, bsz=48, num_updates=14470, lr=3.86847e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17428
2023-08-08 23:05:27 - progress_bar.py[line:272] - INFO: epoch 002:   6268 / 8233 loss=4.516, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=341.1, nsentences=48, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=285.4, ups=0.84, wpb=341.1, bsz=48, num_updates=14480, lr=3.84909e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17440
2023-08-08 23:05:39 - progress_bar.py[line:272] - INFO: epoch 002:   6278 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=278.5, ups=0.83, wpb=336.4, bsz=48, num_updates=14490, lr=3.8297e-06, gnorm=0.109, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17452
2023-08-08 23:05:51 - progress_bar.py[line:272] - INFO: epoch 002:   6288 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=280, ups=0.83, wpb=337.7, bsz=48, num_updates=14500, lr=3.81032e-06, gnorm=0.108, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17464
2023-08-08 23:06:03 - progress_bar.py[line:272] - INFO: epoch 002:   6298 / 8233 loss=4.578, loss_v1=0, loss_v2=0, nll_loss=3.287, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=286, ups=0.84, wpb=340.7, bsz=48, num_updates=14510, lr=3.79094e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17476
2023-08-08 23:06:15 - progress_bar.py[line:272] - INFO: epoch 002:   6308 / 8233 loss=4.507, loss_v1=0, loss_v2=0, nll_loss=3.202, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=283.3, ups=0.83, wpb=340.9, bsz=48, num_updates=14520, lr=3.77156e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17488
2023-08-08 23:06:27 - progress_bar.py[line:272] - INFO: epoch 002:   6318 / 8233 loss=4.529, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=285, ups=0.84, wpb=340.9, bsz=48, num_updates=14530, lr=3.75218e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17500
2023-08-08 23:06:39 - progress_bar.py[line:272] - INFO: epoch 002:   6328 / 8233 loss=4.609, loss_v1=0, loss_v2=0, nll_loss=3.319, ntokens=334.1, nsentences=48, sample_size=334.1, sample_size_v1=0, sample_size_v2=0, ppl=9.98, wps=273.9, ups=0.82, wpb=334.1, bsz=48, num_updates=14540, lr=3.7328e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17512
2023-08-08 23:06:51 - progress_bar.py[line:272] - INFO: epoch 002:   6338 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=275.9, ups=0.82, wpb=335.1, bsz=48, num_updates=14550, lr=3.71342e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17524
2023-08-08 23:07:03 - progress_bar.py[line:272] - INFO: epoch 002:   6348 / 8233 loss=4.573, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=279.1, ups=0.83, wpb=337.2, bsz=48, num_updates=14560, lr=3.69404e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17536
2023-08-08 23:07:15 - progress_bar.py[line:272] - INFO: epoch 002:   6358 / 8233 loss=4.533, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=281.6, ups=0.83, wpb=338.9, bsz=48, num_updates=14570, lr=3.67466e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17548
2023-08-08 23:07:27 - progress_bar.py[line:272] - INFO: epoch 002:   6368 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.269, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=282.1, ups=0.83, wpb=338.8, bsz=48, num_updates=14580, lr=3.65527e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17560
2023-08-08 23:07:39 - progress_bar.py[line:272] - INFO: epoch 002:   6378 / 8233 loss=4.579, loss_v1=0, loss_v2=0, nll_loss=3.287, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=280.8, ups=0.83, wpb=338.3, bsz=48, num_updates=14590, lr=3.63589e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17572
2023-08-08 23:07:51 - progress_bar.py[line:272] - INFO: epoch 002:   6388 / 8233 loss=4.547, loss_v1=0, loss_v2=0, nll_loss=3.25, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=9.51, wps=277.2, ups=0.83, wpb=335.2, bsz=48, num_updates=14600, lr=3.61651e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17584
2023-08-08 23:08:03 - progress_bar.py[line:272] - INFO: epoch 002:   6398 / 8233 loss=4.573, loss_v1=0, loss_v2=0, nll_loss=3.274, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=285.8, ups=0.84, wpb=340.7, bsz=48, num_updates=14610, lr=3.59713e-06, gnorm=0.109, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17596
2023-08-08 23:08:15 - progress_bar.py[line:272] - INFO: epoch 002:   6408 / 8233 loss=4.586, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=285, ups=0.84, wpb=340.3, bsz=48, num_updates=14620, lr=3.57775e-06, gnorm=0.112, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17608
2023-08-08 23:08:27 - progress_bar.py[line:272] - INFO: epoch 002:   6418 / 8233 loss=4.526, loss_v1=0, loss_v2=0, nll_loss=3.222, ntokens=338.9, nsentences=48, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=9.33, wps=283.7, ups=0.84, wpb=338.9, bsz=48, num_updates=14630, lr=3.55837e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17620
2023-08-08 23:08:39 - progress_bar.py[line:272] - INFO: epoch 002:   6428 / 8233 loss=4.507, loss_v1=0, loss_v2=0, nll_loss=3.201, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=279.4, ups=0.83, wpb=335.6, bsz=48, num_updates=14640, lr=3.53899e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17632
2023-08-08 23:08:51 - progress_bar.py[line:272] - INFO: epoch 002:   6438 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=339.6, nsentences=48, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=284.4, ups=0.84, wpb=339.6, bsz=48, num_updates=14650, lr=3.51961e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17644
2023-08-08 23:09:03 - progress_bar.py[line:272] - INFO: epoch 002:   6448 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.297, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.83, wps=282.7, ups=0.84, wpb=337.7, bsz=48, num_updates=14660, lr=3.50023e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17656
2023-08-08 23:09:15 - progress_bar.py[line:272] - INFO: epoch 002:   6458 / 8233 loss=4.549, loss_v1=0, loss_v2=0, nll_loss=3.254, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=281.7, ups=0.83, wpb=337.5, bsz=48, num_updates=14670, lr=3.48085e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17668
2023-08-08 23:09:27 - progress_bar.py[line:272] - INFO: epoch 002:   6468 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.293, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=284.7, ups=0.84, wpb=338.3, bsz=48, num_updates=14680, lr=3.46146e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17680
2023-08-08 23:09:39 - progress_bar.py[line:272] - INFO: epoch 002:   6478 / 8233 loss=4.601, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=284.1, ups=0.84, wpb=338, bsz=48, num_updates=14690, lr=3.44208e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17692
2023-08-08 23:09:51 - progress_bar.py[line:272] - INFO: epoch 002:   6488 / 8233 loss=4.597, loss_v1=0, loss_v2=0, nll_loss=3.301, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=283.6, ups=0.83, wpb=340.4, bsz=48, num_updates=14700, lr=3.4227e-06, gnorm=0.108, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17704
2023-08-08 23:10:03 - progress_bar.py[line:272] - INFO: epoch 002:   6498 / 8233 loss=4.565, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=284.1, ups=0.83, wpb=340.3, bsz=48, num_updates=14710, lr=3.40332e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17716
2023-08-08 23:10:15 - progress_bar.py[line:272] - INFO: epoch 002:   6508 / 8233 loss=4.544, loss_v1=0, loss_v2=0, nll_loss=3.25, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=283.3, ups=0.83, wpb=339.5, bsz=48, num_updates=14720, lr=3.38394e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17728
2023-08-08 23:10:27 - progress_bar.py[line:272] - INFO: epoch 002:   6518 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.265, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=9.62, wps=280.5, ups=0.83, wpb=338.8, bsz=48, num_updates=14730, lr=3.36456e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17740
2023-08-08 23:10:39 - progress_bar.py[line:272] - INFO: epoch 002:   6528 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.263, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=279.7, ups=0.83, wpb=336.8, bsz=48, num_updates=14740, lr=3.34518e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17752
2023-08-08 23:10:51 - progress_bar.py[line:272] - INFO: epoch 002:   6538 / 8233 loss=4.565, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=281.5, ups=0.83, wpb=339.2, bsz=48, num_updates=14750, lr=3.3258e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17764
2023-08-08 23:11:03 - progress_bar.py[line:272] - INFO: epoch 002:   6548 / 8233 loss=4.546, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=280.2, ups=0.83, wpb=337.4, bsz=48, num_updates=14760, lr=3.30642e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17776
2023-08-08 23:11:15 - progress_bar.py[line:272] - INFO: epoch 002:   6558 / 8233 loss=4.538, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=284.6, ups=0.84, wpb=340.3, bsz=48, num_updates=14770, lr=3.28703e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17788
2023-08-08 23:11:27 - progress_bar.py[line:272] - INFO: epoch 002:   6568 / 8233 loss=4.607, loss_v1=0, loss_v2=0, nll_loss=3.315, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=9.95, wps=277.5, ups=0.83, wpb=335.6, bsz=48, num_updates=14780, lr=3.26765e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17800
2023-08-08 23:11:39 - progress_bar.py[line:272] - INFO: epoch 002:   6578 / 8233 loss=4.547, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=279.2, ups=0.83, wpb=336.5, bsz=48, num_updates=14790, lr=3.24827e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17812
2023-08-08 23:11:51 - progress_bar.py[line:272] - INFO: epoch 002:   6588 / 8233 loss=4.52, loss_v1=0, loss_v2=0, nll_loss=3.217, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=281.9, ups=0.83, wpb=338.8, bsz=48, num_updates=14800, lr=3.22889e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17824
2023-08-08 23:12:03 - progress_bar.py[line:272] - INFO: epoch 002:   6598 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.272, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=277.7, ups=0.83, wpb=335.9, bsz=48, num_updates=14810, lr=3.20951e-06, gnorm=0.112, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17836
2023-08-08 23:12:15 - progress_bar.py[line:272] - INFO: epoch 002:   6608 / 8233 loss=4.546, loss_v1=0, loss_v2=0, nll_loss=3.246, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=282.5, ups=0.83, wpb=339.9, bsz=48, num_updates=14820, lr=3.19013e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17848
2023-08-08 23:12:27 - progress_bar.py[line:272] - INFO: epoch 002:   6618 / 8233 loss=4.571, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=334.6, nsentences=48, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=277.2, ups=0.83, wpb=334.6, bsz=48, num_updates=14830, lr=3.17075e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17860
2023-08-08 23:12:39 - progress_bar.py[line:272] - INFO: epoch 002:   6628 / 8233 loss=4.582, loss_v1=0, loss_v2=0, nll_loss=3.288, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.77, wps=284.7, ups=0.84, wpb=339.5, bsz=48, num_updates=14840, lr=3.15137e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17872
2023-08-08 23:12:51 - progress_bar.py[line:272] - INFO: epoch 002:   6638 / 8233 loss=4.536, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=283.4, ups=0.83, wpb=340.2, bsz=48, num_updates=14850, lr=3.13199e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17884
2023-08-08 23:13:03 - progress_bar.py[line:272] - INFO: epoch 002:   6648 / 8233 loss=4.523, loss_v1=0, loss_v2=0, nll_loss=3.217, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=281.9, ups=0.83, wpb=339, bsz=48, num_updates=14860, lr=3.1126e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17896
2023-08-08 23:13:15 - progress_bar.py[line:272] - INFO: epoch 002:   6658 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=334.6, nsentences=48, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=278, ups=0.83, wpb=334.6, bsz=48, num_updates=14870, lr=3.09322e-06, gnorm=0.11, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17908
2023-08-08 23:13:27 - progress_bar.py[line:272] - INFO: epoch 002:   6668 / 8233 loss=4.555, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=282.5, ups=0.83, wpb=338.5, bsz=48, num_updates=14880, lr=3.07384e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17920
2023-08-08 23:13:39 - progress_bar.py[line:272] - INFO: epoch 002:   6678 / 8233 loss=4.581, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=284.3, ups=0.84, wpb=338.7, bsz=48, num_updates=14890, lr=3.05446e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17932
2023-08-08 23:13:51 - progress_bar.py[line:272] - INFO: epoch 002:   6688 / 8233 loss=4.541, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=284.2, ups=0.84, wpb=339.4, bsz=48, num_updates=14900, lr=3.03508e-06, gnorm=0.106, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17944
2023-08-08 23:14:03 - progress_bar.py[line:272] - INFO: epoch 002:   6698 / 8233 loss=4.566, loss_v1=0, loss_v2=0, nll_loss=3.269, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=282.4, ups=0.84, wpb=337.9, bsz=48, num_updates=14910, lr=3.0157e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17956
2023-08-08 23:14:15 - progress_bar.py[line:272] - INFO: epoch 002:   6708 / 8233 loss=4.576, loss_v1=0, loss_v2=0, nll_loss=3.283, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=279.5, ups=0.83, wpb=337.1, bsz=48, num_updates=14920, lr=2.99632e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17968
2023-08-08 23:14:27 - progress_bar.py[line:272] - INFO: epoch 002:   6718 / 8233 loss=4.566, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=283.8, ups=0.84, wpb=339.4, bsz=48, num_updates=14930, lr=2.97694e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17980
2023-08-08 23:14:39 - progress_bar.py[line:272] - INFO: epoch 002:   6728 / 8233 loss=4.477, loss_v1=0, loss_v2=0, nll_loss=3.168, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=8.99, wps=279.2, ups=0.83, wpb=335.9, bsz=48, num_updates=14940, lr=2.95756e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=17992
2023-08-08 23:14:51 - progress_bar.py[line:272] - INFO: epoch 002:   6738 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=342.1, nsentences=48, sample_size=342.1, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=288.4, ups=0.84, wpb=342.1, bsz=48, num_updates=14950, lr=2.93817e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18004
2023-08-08 23:15:03 - progress_bar.py[line:272] - INFO: epoch 002:   6748 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=334.7, nsentences=48, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=276.6, ups=0.83, wpb=334.7, bsz=48, num_updates=14960, lr=2.91879e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18016
2023-08-08 23:15:15 - progress_bar.py[line:272] - INFO: epoch 002:   6758 / 8233 loss=4.568, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=281.8, ups=0.83, wpb=337.9, bsz=48, num_updates=14970, lr=2.89941e-06, gnorm=0.102, clip=0, loss_scale=512, train_wall=12, gb_free=14.5, wall=18028
2023-08-08 23:15:27 - progress_bar.py[line:272] - INFO: epoch 002:   6768 / 8233 loss=4.547, loss_v1=0, loss_v2=0, nll_loss=3.246, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=280.1, ups=0.83, wpb=338.3, bsz=48, num_updates=14980, lr=2.88003e-06, gnorm=0.103, clip=0, loss_scale=512, train_wall=12, gb_free=14.5, wall=18040
2023-08-08 23:15:39 - progress_bar.py[line:272] - INFO: epoch 002:   6778 / 8233 loss=4.541, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=283.3, ups=0.83, wpb=340.2, bsz=48, num_updates=14990, lr=2.86065e-06, gnorm=0.103, clip=0, loss_scale=512, train_wall=12, gb_free=14.5, wall=18052
2023-08-08 23:15:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-08-08 23:15:53 - progress_bar.py[line:272] - INFO: epoch 002:   6789 / 8233 loss=4.552, loss_v1=0, loss_v2=0, nll_loss=3.258, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=257.3, ups=0.76, wpb=339.4, bsz=48, num_updates=15000, lr=2.84127e-06, gnorm=0.108, clip=0, loss_scale=256, train_wall=13, gb_free=14.5, wall=18065
2023-08-08 23:16:05 - progress_bar.py[line:272] - INFO: epoch 002:   6799 / 8233 loss=4.565, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=282.4, ups=0.83, wpb=339.8, bsz=48, num_updates=15010, lr=2.82189e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18077
2023-08-08 23:16:17 - progress_bar.py[line:272] - INFO: epoch 002:   6809 / 8233 loss=4.504, loss_v1=0, loss_v2=0, nll_loss=3.198, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=283.7, ups=0.83, wpb=340.3, bsz=48, num_updates=15020, lr=2.80251e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18089
2023-08-08 23:16:29 - progress_bar.py[line:272] - INFO: epoch 002:   6819 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.274, ntokens=334.5, nsentences=48, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=276.2, ups=0.83, wpb=334.5, bsz=48, num_updates=15030, lr=2.78313e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18102
2023-08-08 23:16:41 - progress_bar.py[line:272] - INFO: epoch 002:   6829 / 8233 loss=4.511, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=283.6, ups=0.84, wpb=339.2, bsz=48, num_updates=15040, lr=2.76374e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18114
2023-08-08 23:16:53 - progress_bar.py[line:272] - INFO: epoch 002:   6839 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=279.8, ups=0.83, wpb=336, bsz=48, num_updates=15050, lr=2.74436e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18126
2023-08-08 23:17:05 - progress_bar.py[line:272] - INFO: epoch 002:   6849 / 8233 loss=4.577, loss_v1=0, loss_v2=0, nll_loss=3.283, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=9.73, wps=288.2, ups=0.85, wpb=340.8, bsz=48, num_updates=15060, lr=2.72498e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18137
2023-08-08 23:17:17 - progress_bar.py[line:272] - INFO: epoch 002:   6859 / 8233 loss=4.516, loss_v1=0, loss_v2=0, nll_loss=3.212, ntokens=334, nsentences=48, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=276.3, ups=0.83, wpb=334, bsz=48, num_updates=15070, lr=2.7056e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18149
2023-08-08 23:17:29 - progress_bar.py[line:272] - INFO: epoch 002:   6869 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=283.8, ups=0.83, wpb=339.9, bsz=48, num_updates=15080, lr=2.68622e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18161
2023-08-08 23:17:41 - progress_bar.py[line:272] - INFO: epoch 002:   6879 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.265, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.61, wps=281.8, ups=0.83, wpb=339.3, bsz=48, num_updates=15090, lr=2.66684e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18174
2023-08-08 23:17:53 - progress_bar.py[line:272] - INFO: epoch 002:   6889 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=283.2, ups=0.83, wpb=339.2, bsz=48, num_updates=15100, lr=2.64746e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18185
2023-08-08 23:18:05 - progress_bar.py[line:272] - INFO: epoch 002:   6899 / 8233 loss=4.546, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=276.4, ups=0.82, wpb=335.2, bsz=48, num_updates=15110, lr=2.62808e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18198
2023-08-08 23:18:17 - progress_bar.py[line:272] - INFO: epoch 002:   6909 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=285.3, ups=0.84, wpb=340.9, bsz=48, num_updates=15120, lr=2.6087e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18210
2023-08-08 23:18:29 - progress_bar.py[line:272] - INFO: epoch 002:   6919 / 8233 loss=4.546, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=278.7, ups=0.83, wpb=335.4, bsz=48, num_updates=15130, lr=2.58931e-06, gnorm=0.096, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18222
2023-08-08 23:18:40 - progress_bar.py[line:272] - INFO: epoch 002:   6929 / 8233 loss=4.535, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=343.6, nsentences=48, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=292.2, ups=0.85, wpb=343.6, bsz=48, num_updates=15140, lr=2.56993e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18233
2023-08-08 23:18:52 - progress_bar.py[line:272] - INFO: epoch 002:   6939 / 8233 loss=4.551, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=281.6, ups=0.83, wpb=337.7, bsz=48, num_updates=15150, lr=2.55055e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18245
2023-08-08 23:19:04 - progress_bar.py[line:272] - INFO: epoch 002:   6949 / 8233 loss=4.57, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=279.5, ups=0.83, wpb=336, bsz=48, num_updates=15160, lr=2.53117e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18257
2023-08-08 23:19:16 - progress_bar.py[line:272] - INFO: epoch 002:   6959 / 8233 loss=4.568, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.69, wps=284.9, ups=0.84, wpb=339.7, bsz=48, num_updates=15170, lr=2.51179e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18269
2023-08-08 23:19:28 - progress_bar.py[line:272] - INFO: epoch 002:   6969 / 8233 loss=4.586, loss_v1=0, loss_v2=0, nll_loss=3.288, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=9.77, wps=280.6, ups=0.83, wpb=336.2, bsz=48, num_updates=15180, lr=2.49241e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18281
2023-08-08 23:19:40 - progress_bar.py[line:272] - INFO: epoch 002:   6979 / 8233 loss=4.524, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=283.5, ups=0.84, wpb=339.3, bsz=48, num_updates=15190, lr=2.47303e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18293
2023-08-08 23:19:52 - progress_bar.py[line:272] - INFO: epoch 002:   6989 / 8233 loss=4.599, loss_v1=0, loss_v2=0, nll_loss=3.303, ntokens=334.4, nsentences=48, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=9.87, wps=277.4, ups=0.83, wpb=334.4, bsz=48, num_updates=15200, lr=2.45365e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18305
2023-08-08 23:20:04 - progress_bar.py[line:272] - INFO: epoch 002:   6999 / 8233 loss=4.554, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=282.4, ups=0.84, wpb=337.7, bsz=48, num_updates=15210, lr=2.43427e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18317
2023-08-08 23:20:16 - progress_bar.py[line:272] - INFO: epoch 002:   7009 / 8233 loss=4.568, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=340.8, nsentences=48, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=288.1, ups=0.85, wpb=340.8, bsz=48, num_updates=15220, lr=2.41488e-06, gnorm=0.101, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18329
2023-08-08 23:20:28 - progress_bar.py[line:272] - INFO: epoch 002:   7019 / 8233 loss=4.546, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=281.8, ups=0.83, wpb=337.8, bsz=48, num_updates=15230, lr=2.3955e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18341
2023-08-08 23:20:40 - progress_bar.py[line:272] - INFO: epoch 002:   7029 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=336, nsentences=48, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=279.7, ups=0.83, wpb=336, bsz=48, num_updates=15240, lr=2.37612e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18353
2023-08-08 23:20:52 - progress_bar.py[line:272] - INFO: epoch 002:   7039 / 8233 loss=4.585, loss_v1=0, loss_v2=0, nll_loss=3.293, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=280.7, ups=0.83, wpb=337.2, bsz=48, num_updates=15250, lr=2.35674e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18365
2023-08-08 23:21:04 - progress_bar.py[line:272] - INFO: epoch 002:   7049 / 8233 loss=4.545, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=336.5, nsentences=48, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=279, ups=0.83, wpb=336.5, bsz=48, num_updates=15260, lr=2.33736e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18377
2023-08-08 23:21:16 - progress_bar.py[line:272] - INFO: epoch 002:   7059 / 8233 loss=4.5, loss_v1=0, loss_v2=0, nll_loss=3.198, ntokens=339, nsentences=48, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=281.8, ups=0.83, wpb=339, bsz=48, num_updates=15270, lr=2.31798e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18389
2023-08-08 23:21:28 - progress_bar.py[line:272] - INFO: epoch 002:   7069 / 8233 loss=4.548, loss_v1=0, loss_v2=0, nll_loss=3.246, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=280.7, ups=0.83, wpb=337.7, bsz=48, num_updates=15280, lr=2.2986e-06, gnorm=0.109, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18401
2023-08-08 23:21:40 - progress_bar.py[line:272] - INFO: epoch 002:   7079 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.257, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=281.9, ups=0.83, wpb=338, bsz=48, num_updates=15290, lr=2.27922e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18413
2023-08-08 23:21:52 - progress_bar.py[line:272] - INFO: epoch 002:   7089 / 8233 loss=4.528, loss_v1=0, loss_v2=0, nll_loss=3.23, ntokens=341.9, nsentences=48, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=285.7, ups=0.84, wpb=341.9, bsz=48, num_updates=15300, lr=2.25984e-06, gnorm=0.102, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18425
2023-08-08 23:22:04 - progress_bar.py[line:272] - INFO: epoch 002:   7099 / 8233 loss=4.55, loss_v1=0, loss_v2=0, nll_loss=3.254, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=283.3, ups=0.83, wpb=340.2, bsz=48, num_updates=15310, lr=2.24045e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18437
2023-08-08 23:22:16 - progress_bar.py[line:272] - INFO: epoch 002:   7109 / 8233 loss=4.552, loss_v1=0, loss_v2=0, nll_loss=3.249, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=9.51, wps=278.7, ups=0.83, wpb=335.6, bsz=48, num_updates=15320, lr=2.22107e-06, gnorm=0.108, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18449
2023-08-08 23:22:28 - progress_bar.py[line:272] - INFO: epoch 002:   7119 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.27, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=284.4, ups=0.84, wpb=339.7, bsz=48, num_updates=15330, lr=2.20169e-06, gnorm=0.111, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18461
2023-08-08 23:22:40 - progress_bar.py[line:272] - INFO: epoch 002:   7129 / 8233 loss=4.58, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=338.2, nsentences=48, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=281.6, ups=0.83, wpb=338.2, bsz=48, num_updates=15340, lr=2.18231e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18473
2023-08-08 23:22:52 - progress_bar.py[line:272] - INFO: epoch 002:   7139 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.266, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=9.62, wps=278.5, ups=0.83, wpb=335.6, bsz=48, num_updates=15350, lr=2.16293e-06, gnorm=0.103, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18485
2023-08-08 23:23:04 - progress_bar.py[line:272] - INFO: epoch 002:   7149 / 8233 loss=4.524, loss_v1=0, loss_v2=0, nll_loss=3.222, ntokens=340.6, nsentences=48, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=9.33, wps=285.5, ups=0.84, wpb=340.6, bsz=48, num_updates=15360, lr=2.14355e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18497
2023-08-08 23:23:16 - progress_bar.py[line:272] - INFO: epoch 002:   7159 / 8233 loss=4.538, loss_v1=0, loss_v2=0, nll_loss=3.235, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.42, wps=282.3, ups=0.84, wpb=337.1, bsz=48, num_updates=15370, lr=2.12417e-06, gnorm=0.105, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18509
2023-08-08 23:23:28 - progress_bar.py[line:272] - INFO: epoch 002:   7169 / 8233 loss=4.532, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=284.9, ups=0.84, wpb=339.1, bsz=48, num_updates=15380, lr=2.10479e-06, gnorm=0.104, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18521
2023-08-08 23:23:40 - progress_bar.py[line:272] - INFO: epoch 002:   7179 / 8233 loss=4.517, loss_v1=0, loss_v2=0, nll_loss=3.214, ntokens=337.2, nsentences=48, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=282.1, ups=0.84, wpb=337.2, bsz=48, num_updates=15390, lr=2.08541e-06, gnorm=0.1, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18533
2023-08-08 23:23:52 - progress_bar.py[line:272] - INFO: epoch 002:   7189 / 8233 loss=4.571, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=281.9, ups=0.83, wpb=337.7, bsz=48, num_updates=15400, lr=2.06602e-06, gnorm=0.107, clip=0, loss_scale=256, train_wall=12, gb_free=14.5, wall=18545
2023-08-08 23:24:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-08-08 23:24:05 - progress_bar.py[line:272] - INFO: epoch 002:   7200 / 8233 loss=4.55, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=254.2, ups=0.76, wpb=336.2, bsz=48, num_updates=15410, lr=2.04664e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=13, gb_free=14.5, wall=18558
2023-08-08 23:24:17 - progress_bar.py[line:272] - INFO: epoch 002:   7210 / 8233 loss=4.581, loss_v1=0, loss_v2=0, nll_loss=3.288, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.77, wps=280.3, ups=0.83, wpb=336.8, bsz=48, num_updates=15420, lr=2.02726e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18570
2023-08-08 23:24:29 - progress_bar.py[line:272] - INFO: epoch 002:   7220 / 8233 loss=4.578, loss_v1=0, loss_v2=0, nll_loss=3.282, ntokens=339.8, nsentences=48, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=9.73, wps=283.6, ups=0.83, wpb=339.8, bsz=48, num_updates=15430, lr=2.00788e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18582
2023-08-08 23:24:41 - progress_bar.py[line:272] - INFO: epoch 002:   7230 / 8233 loss=4.562, loss_v1=0, loss_v2=0, nll_loss=3.269, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=283, ups=0.83, wpb=339.5, bsz=48, num_updates=15440, lr=1.9885e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18594
2023-08-08 23:24:53 - progress_bar.py[line:272] - INFO: epoch 002:   7240 / 8233 loss=4.489, loss_v1=0, loss_v2=0, nll_loss=3.183, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.08, wps=284.9, ups=0.84, wpb=339.9, bsz=48, num_updates=15450, lr=1.96912e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18606
2023-08-08 23:25:05 - progress_bar.py[line:272] - INFO: epoch 002:   7250 / 8233 loss=4.533, loss_v1=0, loss_v2=0, nll_loss=3.236, ntokens=333.3, nsentences=48, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=9.42, wps=274.4, ups=0.82, wpb=333.3, bsz=48, num_updates=15460, lr=1.94974e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18618
2023-08-08 23:25:17 - progress_bar.py[line:272] - INFO: epoch 002:   7260 / 8233 loss=4.587, loss_v1=0, loss_v2=0, nll_loss=3.291, ntokens=335, nsentences=48, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=9.79, wps=278.2, ups=0.83, wpb=335, bsz=48, num_updates=15470, lr=1.93036e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18630
2023-08-08 23:25:29 - progress_bar.py[line:272] - INFO: epoch 002:   7270 / 8233 loss=4.52, loss_v1=0, loss_v2=0, nll_loss=3.214, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=282.8, ups=0.84, wpb=338.6, bsz=48, num_updates=15480, lr=1.91098e-06, gnorm=0.1, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18642
2023-08-08 23:25:41 - progress_bar.py[line:272] - INFO: epoch 002:   7280 / 8233 loss=4.539, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=280.6, ups=0.83, wpb=337, bsz=48, num_updates=15490, lr=1.8916e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18654
2023-08-08 23:25:53 - progress_bar.py[line:272] - INFO: epoch 002:   7290 / 8233 loss=4.57, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=283.1, ups=0.84, wpb=337.1, bsz=48, num_updates=15500, lr=1.87221e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18666
2023-08-08 23:26:05 - progress_bar.py[line:272] - INFO: epoch 002:   7300 / 8233 loss=4.5, loss_v1=0, loss_v2=0, nll_loss=3.197, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=283.2, ups=0.83, wpb=339.2, bsz=48, num_updates=15510, lr=1.85283e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18678
2023-08-08 23:26:17 - progress_bar.py[line:272] - INFO: epoch 002:   7310 / 8233 loss=4.521, loss_v1=0, loss_v2=0, nll_loss=3.22, ntokens=341.2, nsentences=48, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=286.6, ups=0.84, wpb=341.2, bsz=48, num_updates=15520, lr=1.83345e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18690
2023-08-08 23:26:29 - progress_bar.py[line:272] - INFO: epoch 002:   7320 / 8233 loss=4.509, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=284.4, ups=0.84, wpb=340.4, bsz=48, num_updates=15530, lr=1.81407e-06, gnorm=0.098, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18702
2023-08-08 23:26:41 - progress_bar.py[line:272] - INFO: epoch 002:   7330 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.279, ntokens=339.2, nsentences=48, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=9.71, wps=284.1, ups=0.84, wpb=339.2, bsz=48, num_updates=15540, lr=1.79469e-06, gnorm=0.1, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18714
2023-08-08 23:26:53 - progress_bar.py[line:272] - INFO: epoch 002:   7340 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=279.9, ups=0.83, wpb=337, bsz=48, num_updates=15550, lr=1.77531e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18726
2023-08-08 23:27:05 - progress_bar.py[line:272] - INFO: epoch 002:   7350 / 8233 loss=4.589, loss_v1=0, loss_v2=0, nll_loss=3.292, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.8, wps=282.5, ups=0.84, wpb=337.7, bsz=48, num_updates=15560, lr=1.75593e-06, gnorm=0.11, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18738
2023-08-08 23:27:17 - progress_bar.py[line:272] - INFO: epoch 002:   7360 / 8233 loss=4.55, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=335.8, nsentences=48, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=278.6, ups=0.83, wpb=335.8, bsz=48, num_updates=15570, lr=1.73655e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18750
2023-08-08 23:27:29 - progress_bar.py[line:272] - INFO: epoch 002:   7370 / 8233 loss=4.535, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=337, nsentences=48, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=280.9, ups=0.83, wpb=337, bsz=48, num_updates=15580, lr=1.71717e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18762
2023-08-08 23:27:41 - progress_bar.py[line:272] - INFO: epoch 002:   7380 / 8233 loss=4.54, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=283.7, ups=0.84, wpb=339.4, bsz=48, num_updates=15590, lr=1.69778e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18774
2023-08-08 23:27:53 - progress_bar.py[line:272] - INFO: epoch 002:   7390 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.257, ntokens=337.7, nsentences=48, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=281.3, ups=0.83, wpb=337.7, bsz=48, num_updates=15600, lr=1.6784e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18786
2023-08-08 23:28:05 - progress_bar.py[line:272] - INFO: epoch 002:   7400 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=338.6, nsentences=48, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=9.69, wps=281, ups=0.83, wpb=338.6, bsz=48, num_updates=15610, lr=1.65902e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18798
2023-08-08 23:28:17 - progress_bar.py[line:272] - INFO: epoch 002:   7410 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.264, ntokens=342.3, nsentences=48, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=9.61, wps=287, ups=0.84, wpb=342.3, bsz=48, num_updates=15620, lr=1.63964e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18810
2023-08-08 23:28:29 - progress_bar.py[line:272] - INFO: epoch 002:   7420 / 8233 loss=4.522, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=334, nsentences=48, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=276.5, ups=0.83, wpb=334, bsz=48, num_updates=15630, lr=1.62026e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18822
2023-08-08 23:28:41 - progress_bar.py[line:272] - INFO: epoch 002:   7430 / 8233 loss=4.574, loss_v1=0, loss_v2=0, nll_loss=3.28, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.71, wps=280.1, ups=0.83, wpb=337.1, bsz=48, num_updates=15640, lr=1.60088e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18834
2023-08-08 23:28:53 - progress_bar.py[line:272] - INFO: epoch 002:   7440 / 8233 loss=4.516, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=279.7, ups=0.83, wpb=336.3, bsz=48, num_updates=15650, lr=1.5815e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18846
2023-08-08 23:29:05 - progress_bar.py[line:272] - INFO: epoch 002:   7450 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.255, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=284.2, ups=0.84, wpb=338.7, bsz=48, num_updates=15660, lr=1.56212e-06, gnorm=0.101, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18858
2023-08-08 23:29:17 - progress_bar.py[line:272] - INFO: epoch 002:   7460 / 8233 loss=4.569, loss_v1=0, loss_v2=0, nll_loss=3.267, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.62, wps=284.2, ups=0.84, wpb=339.7, bsz=48, num_updates=15670, lr=1.54274e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18870
2023-08-08 23:29:29 - progress_bar.py[line:272] - INFO: epoch 002:   7470 / 8233 loss=4.519, loss_v1=0, loss_v2=0, nll_loss=3.217, ntokens=334.8, nsentences=48, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=277.6, ups=0.83, wpb=334.8, bsz=48, num_updates=15680, lr=1.52335e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18882
2023-08-08 23:29:41 - progress_bar.py[line:272] - INFO: epoch 002:   7480 / 8233 loss=4.529, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=284.6, ups=0.84, wpb=340.3, bsz=48, num_updates=15690, lr=1.50397e-06, gnorm=0.099, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18894
2023-08-08 23:29:53 - progress_bar.py[line:272] - INFO: epoch 002:   7490 / 8233 loss=4.532, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=340.7, nsentences=48, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=285.2, ups=0.84, wpb=340.7, bsz=48, num_updates=15700, lr=1.48459e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18906
2023-08-08 23:30:05 - progress_bar.py[line:272] - INFO: epoch 002:   7500 / 8233 loss=4.491, loss_v1=0, loss_v2=0, nll_loss=3.187, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.11, wps=285.1, ups=0.84, wpb=340.1, bsz=48, num_updates=15710, lr=1.46521e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18918
2023-08-08 23:30:17 - progress_bar.py[line:272] - INFO: epoch 002:   7510 / 8233 loss=4.532, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=280.8, ups=0.83, wpb=336.9, bsz=48, num_updates=15720, lr=1.44583e-06, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18930
2023-08-08 23:30:29 - progress_bar.py[line:272] - INFO: epoch 002:   7520 / 8233 loss=4.499, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=337.5, nsentences=48, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=280.3, ups=0.83, wpb=337.5, bsz=48, num_updates=15730, lr=1.42645e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18942
2023-08-08 23:30:41 - progress_bar.py[line:272] - INFO: epoch 002:   7530 / 8233 loss=4.539, loss_v1=0, loss_v2=0, nll_loss=3.236, ntokens=335.1, nsentences=48, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=9.42, wps=279.5, ups=0.83, wpb=335.1, bsz=48, num_updates=15740, lr=1.40707e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18954
2023-08-08 23:30:53 - progress_bar.py[line:272] - INFO: epoch 002:   7540 / 8233 loss=4.599, loss_v1=0, loss_v2=0, nll_loss=3.31, ntokens=337.6, nsentences=48, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=9.92, wps=282.4, ups=0.84, wpb=337.6, bsz=48, num_updates=15750, lr=1.38769e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18966
2023-08-08 23:31:05 - progress_bar.py[line:272] - INFO: epoch 002:   7550 / 8233 loss=4.553, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=333.7, nsentences=48, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=276.6, ups=0.83, wpb=333.7, bsz=48, num_updates=15760, lr=1.36831e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18978
2023-08-08 23:31:17 - progress_bar.py[line:272] - INFO: epoch 002:   7560 / 8233 loss=4.564, loss_v1=0, loss_v2=0, nll_loss=3.272, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=283.4, ups=0.84, wpb=339.4, bsz=48, num_updates=15770, lr=1.34892e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=18990
2023-08-08 23:31:29 - progress_bar.py[line:272] - INFO: epoch 002:   7570 / 8233 loss=4.523, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=285.1, ups=0.84, wpb=339.3, bsz=48, num_updates=15780, lr=1.32954e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19002
2023-08-08 23:31:41 - progress_bar.py[line:272] - INFO: epoch 002:   7580 / 8233 loss=4.531, loss_v1=0, loss_v2=0, nll_loss=3.23, ntokens=340.3, nsentences=48, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=285.9, ups=0.84, wpb=340.3, bsz=48, num_updates=15790, lr=1.31016e-06, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19014
2023-08-08 23:31:53 - progress_bar.py[line:272] - INFO: epoch 002:   7590 / 8233 loss=4.565, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=339.9, nsentences=48, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=284.8, ups=0.84, wpb=339.9, bsz=48, num_updates=15800, lr=1.29078e-06, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19026
2023-08-08 23:32:05 - progress_bar.py[line:272] - INFO: epoch 002:   7600 / 8233 loss=4.544, loss_v1=0, loss_v2=0, nll_loss=3.239, ntokens=339.4, nsentences=48, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=284.1, ups=0.84, wpb=339.4, bsz=48, num_updates=15810, lr=1.2714e-06, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19038
2023-08-08 23:32:17 - progress_bar.py[line:272] - INFO: epoch 002:   7610 / 8233 loss=4.529, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=281.9, ups=0.83, wpb=338.4, bsz=48, num_updates=15820, lr=1.25202e-06, gnorm=0.105, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19050
2023-08-08 23:32:29 - progress_bar.py[line:272] - INFO: epoch 002:   7620 / 8233 loss=4.56, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=284.3, ups=0.84, wpb=340.2, bsz=48, num_updates=15830, lr=1.23264e-06, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19062
2023-08-08 23:32:41 - progress_bar.py[line:272] - INFO: epoch 002:   7630 / 8233 loss=4.579, loss_v1=0, loss_v2=0, nll_loss=3.285, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=282.7, ups=0.84, wpb=338.5, bsz=48, num_updates=15840, lr=1.21326e-06, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19074
2023-08-08 23:32:53 - progress_bar.py[line:272] - INFO: epoch 002:   7640 / 8233 loss=4.541, loss_v1=0, loss_v2=0, nll_loss=3.237, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=279.3, ups=0.83, wpb=336.9, bsz=48, num_updates=15850, lr=1.19388e-06, gnorm=0.1, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19086
2023-08-08 23:33:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 23:33:06 - progress_bar.py[line:272] - INFO: epoch 002:   7651 / 8233 loss=4.534, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=256.5, ups=0.76, wpb=337.4, bsz=48, num_updates=15860, lr=1.17449e-06, gnorm=0.108, clip=0, loss_scale=64, train_wall=13, gb_free=14.5, wall=19099
2023-08-08 23:33:18 - progress_bar.py[line:272] - INFO: epoch 002:   7661 / 8233 loss=4.526, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=333.9, nsentences=47.1, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=283.3, ups=0.85, wpb=333.9, bsz=47.1, num_updates=15870, lr=1.15511e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19111
2023-08-08 23:33:30 - progress_bar.py[line:272] - INFO: epoch 002:   7671 / 8233 loss=4.524, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=336.9, nsentences=48, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=278.9, ups=0.83, wpb=336.9, bsz=48, num_updates=15880, lr=1.13573e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19123
2023-08-08 23:33:42 - progress_bar.py[line:272] - INFO: epoch 002:   7681 / 8233 loss=4.504, loss_v1=0, loss_v2=0, nll_loss=3.197, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=283.7, ups=0.83, wpb=340.5, bsz=48, num_updates=15890, lr=1.11635e-06, gnorm=0.101, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19135
2023-08-08 23:33:54 - progress_bar.py[line:272] - INFO: epoch 002:   7691 / 8233 loss=4.559, loss_v1=0, loss_v2=0, nll_loss=3.269, ntokens=335.9, nsentences=48, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=278.4, ups=0.83, wpb=335.9, bsz=48, num_updates=15900, lr=1.09697e-06, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19147
2023-08-08 23:34:06 - progress_bar.py[line:272] - INFO: epoch 002:   7701 / 8233 loss=4.543, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=279.8, ups=0.83, wpb=338, bsz=48, num_updates=15910, lr=1.07759e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19159
2023-08-08 23:34:18 - progress_bar.py[line:272] - INFO: epoch 002:   7711 / 8233 loss=4.53, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=278.1, ups=0.83, wpb=336.4, bsz=48, num_updates=15920, lr=1.05821e-06, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19171
2023-08-08 23:34:30 - progress_bar.py[line:272] - INFO: epoch 002:   7721 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=337.4, nsentences=48, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=281.9, ups=0.84, wpb=337.4, bsz=48, num_updates=15930, lr=1.03883e-06, gnorm=0.1, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19183
2023-08-08 23:34:42 - progress_bar.py[line:272] - INFO: epoch 002:   7731 / 8233 loss=4.555, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=340.5, nsentences=48, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=286.2, ups=0.84, wpb=340.5, bsz=48, num_updates=15940, lr=1.01945e-06, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19195
2023-08-08 23:34:54 - progress_bar.py[line:272] - INFO: epoch 002:   7741 / 8233 loss=4.549, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=281.1, ups=0.83, wpb=337.3, bsz=48, num_updates=15950, lr=1.00006e-06, gnorm=0.1, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19207
2023-08-08 23:35:06 - progress_bar.py[line:272] - INFO: epoch 002:   7751 / 8233 loss=4.543, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=336.3, nsentences=48, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=281.1, ups=0.84, wpb=336.3, bsz=48, num_updates=15960, lr=9.80684e-07, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19219
2023-08-08 23:35:18 - progress_bar.py[line:272] - INFO: epoch 002:   7761 / 8233 loss=4.562, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=338.5, nsentences=48, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=282.3, ups=0.83, wpb=338.5, bsz=48, num_updates=15970, lr=9.61302e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19231
2023-08-08 23:35:30 - progress_bar.py[line:272] - INFO: epoch 002:   7771 / 8233 loss=4.503, loss_v1=0, loss_v2=0, nll_loss=3.196, ntokens=342.4, nsentences=48, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=287.6, ups=0.84, wpb=342.4, bsz=48, num_updates=15980, lr=9.41921e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19243
2023-08-08 23:35:42 - progress_bar.py[line:272] - INFO: epoch 002:   7781 / 8233 loss=4.522, loss_v1=0, loss_v2=0, nll_loss=3.216, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=283, ups=0.84, wpb=337.9, bsz=48, num_updates=15990, lr=9.2254e-07, gnorm=0.101, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19255
2023-08-08 23:35:54 - progress_bar.py[line:272] - INFO: epoch 002:   7791 / 8233 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.266, ntokens=338.1, nsentences=48, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=9.62, wps=281.9, ups=0.83, wpb=338.1, bsz=48, num_updates=16000, lr=9.03159e-07, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19267
2023-08-08 23:36:06 - progress_bar.py[line:272] - INFO: epoch 002:   7801 / 8233 loss=4.523, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=341.5, nsentences=48, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=284.6, ups=0.83, wpb=341.5, bsz=48, num_updates=16010, lr=8.83778e-07, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19279
2023-08-08 23:36:18 - progress_bar.py[line:272] - INFO: epoch 002:   7811 / 8233 loss=4.55, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=340.9, nsentences=48, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=9.55, wps=284.8, ups=0.84, wpb=340.9, bsz=48, num_updates=16020, lr=8.64397e-07, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19291
2023-08-08 23:36:30 - progress_bar.py[line:272] - INFO: epoch 002:   7821 / 8233 loss=4.564, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=282.6, ups=0.84, wpb=338, bsz=48, num_updates=16030, lr=8.45016e-07, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19303
2023-08-08 23:36:42 - progress_bar.py[line:272] - INFO: epoch 002:   7831 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.258, ntokens=338.8, nsentences=48, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=282.5, ups=0.83, wpb=338.8, bsz=48, num_updates=16040, lr=8.25635e-07, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19315
2023-08-08 23:36:54 - progress_bar.py[line:272] - INFO: epoch 002:   7841 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.257, ntokens=335.6, nsentences=48, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=278, ups=0.83, wpb=335.6, bsz=48, num_updates=16050, lr=8.06254e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19327
2023-08-08 23:37:06 - progress_bar.py[line:272] - INFO: epoch 002:   7851 / 8233 loss=4.531, loss_v1=0, loss_v2=0, nll_loss=3.232, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=277.2, ups=0.83, wpb=335.4, bsz=48, num_updates=16060, lr=7.86873e-07, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19339
2023-08-08 23:37:18 - progress_bar.py[line:272] - INFO: epoch 002:   7861 / 8233 loss=4.57, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=280, ups=0.83, wpb=337.3, bsz=48, num_updates=16070, lr=7.67491e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19351
2023-08-08 23:37:30 - progress_bar.py[line:272] - INFO: epoch 002:   7871 / 8233 loss=4.522, loss_v1=0, loss_v2=0, nll_loss=3.217, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=278.7, ups=0.83, wpb=336.8, bsz=48, num_updates=16080, lr=7.4811e-07, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19363
2023-08-08 23:37:42 - progress_bar.py[line:272] - INFO: epoch 002:   7881 / 8233 loss=4.528, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=341.8, nsentences=48, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=286.9, ups=0.84, wpb=341.8, bsz=48, num_updates=16090, lr=7.28729e-07, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19375
2023-08-08 23:37:54 - progress_bar.py[line:272] - INFO: epoch 002:   7891 / 8233 loss=4.572, loss_v1=0, loss_v2=0, nll_loss=3.276, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=9.69, wps=275.8, ups=0.82, wpb=335.5, bsz=48, num_updates=16100, lr=7.09348e-07, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19387
2023-08-08 23:38:06 - progress_bar.py[line:272] - INFO: epoch 002:   7901 / 8233 loss=4.541, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=337.1, nsentences=48, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=281.2, ups=0.83, wpb=337.1, bsz=48, num_updates=16110, lr=6.89967e-07, gnorm=0.1, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19399
2023-08-08 23:38:18 - progress_bar.py[line:272] - INFO: epoch 002:   7911 / 8233 loss=4.516, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=285.9, ups=0.84, wpb=340.4, bsz=48, num_updates=16120, lr=6.70586e-07, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19411
2023-08-08 23:38:30 - progress_bar.py[line:272] - INFO: epoch 002:   7921 / 8233 loss=4.544, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=279.8, ups=0.83, wpb=336.4, bsz=48, num_updates=16130, lr=6.51205e-07, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19423
2023-08-08 23:38:42 - progress_bar.py[line:272] - INFO: epoch 002:   7931 / 8233 loss=4.57, loss_v1=0, loss_v2=0, nll_loss=3.269, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.64, wps=281.3, ups=0.83, wpb=338, bsz=48, num_updates=16140, lr=6.31824e-07, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19435
2023-08-08 23:38:54 - progress_bar.py[line:272] - INFO: epoch 002:   7941 / 8233 loss=4.543, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=336.8, nsentences=48, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=279.3, ups=0.83, wpb=336.8, bsz=48, num_updates=16150, lr=6.12443e-07, gnorm=0.1, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19447
2023-08-08 23:39:06 - progress_bar.py[line:272] - INFO: epoch 002:   7951 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=283.5, ups=0.83, wpb=339.7, bsz=48, num_updates=16160, lr=5.93062e-07, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19459
2023-08-08 23:39:18 - progress_bar.py[line:272] - INFO: epoch 002:   7961 / 8233 loss=4.556, loss_v1=0, loss_v2=0, nll_loss=3.254, ntokens=339.7, nsentences=48, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=282.2, ups=0.83, wpb=339.7, bsz=48, num_updates=16170, lr=5.7368e-07, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19471
2023-08-08 23:39:30 - progress_bar.py[line:272] - INFO: epoch 002:   7971 / 8233 loss=4.582, loss_v1=0, loss_v2=0, nll_loss=3.29, ntokens=336.7, nsentences=48, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=9.78, wps=279.5, ups=0.83, wpb=336.7, bsz=48, num_updates=16180, lr=5.54299e-07, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19483
2023-08-08 23:39:42 - progress_bar.py[line:272] - INFO: epoch 002:   7981 / 8233 loss=4.54, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=341.9, nsentences=48, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=286.7, ups=0.84, wpb=341.9, bsz=48, num_updates=16190, lr=5.34918e-07, gnorm=0.108, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19495
2023-08-08 23:39:54 - progress_bar.py[line:272] - INFO: epoch 002:   7991 / 8233 loss=4.54, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=340.2, nsentences=48, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=286.3, ups=0.84, wpb=340.2, bsz=48, num_updates=16200, lr=5.15537e-07, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19507
2023-08-08 23:40:06 - progress_bar.py[line:272] - INFO: epoch 002:   8001 / 8233 loss=4.57, loss_v1=0, loss_v2=0, nll_loss=3.278, ntokens=336.2, nsentences=48, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=9.7, wps=280.1, ups=0.83, wpb=336.2, bsz=48, num_updates=16210, lr=4.96156e-07, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19519
2023-08-08 23:40:18 - progress_bar.py[line:272] - INFO: epoch 002:   8011 / 8233 loss=4.567, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=335.3, nsentences=48, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=277.3, ups=0.83, wpb=335.3, bsz=48, num_updates=16220, lr=4.76775e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19531
2023-08-08 23:40:30 - progress_bar.py[line:272] - INFO: epoch 002:   8021 / 8233 loss=4.561, loss_v1=0, loss_v2=0, nll_loss=3.262, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.59, wps=284.4, ups=0.84, wpb=340.1, bsz=48, num_updates=16230, lr=4.57394e-07, gnorm=0.104, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19543
2023-08-08 23:40:42 - progress_bar.py[line:272] - INFO: epoch 002:   8031 / 8233 loss=4.552, loss_v1=0, loss_v2=0, nll_loss=3.256, ntokens=335.4, nsentences=48, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=277.6, ups=0.83, wpb=335.4, bsz=48, num_updates=16240, lr=4.38013e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19555
2023-08-08 23:40:54 - progress_bar.py[line:272] - INFO: epoch 002:   8041 / 8233 loss=4.555, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=338.4, nsentences=48, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=284.8, ups=0.84, wpb=338.4, bsz=48, num_updates=16250, lr=4.18632e-07, gnorm=0.109, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19567
2023-08-08 23:41:06 - progress_bar.py[line:272] - INFO: epoch 002:   8051 / 8233 loss=4.541, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=334.9, nsentences=48, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=278, ups=0.83, wpb=334.9, bsz=48, num_updates=16260, lr=3.99251e-07, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19579
2023-08-08 23:41:18 - progress_bar.py[line:272] - INFO: epoch 002:   8061 / 8233 loss=4.527, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=339.1, nsentences=48, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=282.7, ups=0.83, wpb=339.1, bsz=48, num_updates=16270, lr=3.7987e-07, gnorm=0.102, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19591
2023-08-08 23:41:30 - progress_bar.py[line:272] - INFO: epoch 002:   8071 / 8233 loss=4.558, loss_v1=0, loss_v2=0, nll_loss=3.26, ntokens=337.9, nsentences=48, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=9.58, wps=282.1, ups=0.83, wpb=337.9, bsz=48, num_updates=16280, lr=3.60488e-07, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19603
2023-08-08 23:41:42 - progress_bar.py[line:272] - INFO: epoch 002:   8081 / 8233 loss=4.603, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=281.6, ups=0.83, wpb=337.3, bsz=48, num_updates=16290, lr=3.41107e-07, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19615
2023-08-08 23:41:54 - progress_bar.py[line:272] - INFO: epoch 002:   8091 / 8233 loss=4.524, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=335.2, nsentences=48, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=278.4, ups=0.83, wpb=335.2, bsz=48, num_updates=16300, lr=3.21726e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19627
2023-08-08 23:42:06 - progress_bar.py[line:272] - INFO: epoch 002:   8101 / 8233 loss=4.568, loss_v1=0, loss_v2=0, nll_loss=3.272, ntokens=336.1, nsentences=48, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=281.1, ups=0.84, wpb=336.1, bsz=48, num_updates=16310, lr=3.02345e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19639
2023-08-08 23:42:18 - progress_bar.py[line:272] - INFO: epoch 002:   8111 / 8233 loss=4.571, loss_v1=0, loss_v2=0, nll_loss=3.271, ntokens=338, nsentences=48, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=283.6, ups=0.84, wpb=338, bsz=48, num_updates=16320, lr=2.82964e-07, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19651
2023-08-08 23:42:30 - progress_bar.py[line:272] - INFO: epoch 002:   8121 / 8233 loss=4.527, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=340.1, nsentences=48, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=287.7, ups=0.85, wpb=340.1, bsz=48, num_updates=16330, lr=2.63583e-07, gnorm=0.103, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19663
2023-08-08 23:42:42 - progress_bar.py[line:272] - INFO: epoch 002:   8131 / 8233 loss=4.561, loss_v1=0, loss_v2=0, nll_loss=3.268, ntokens=338.3, nsentences=48, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=9.63, wps=282.5, ups=0.84, wpb=338.3, bsz=48, num_updates=16340, lr=2.44202e-07, gnorm=0.106, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19675
2023-08-08 23:42:54 - progress_bar.py[line:272] - INFO: epoch 002:   8141 / 8233 loss=4.533, loss_v1=0, loss_v2=0, nll_loss=3.239, ntokens=334.8, nsentences=48, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=277.7, ups=0.83, wpb=334.8, bsz=48, num_updates=16350, lr=2.24821e-07, gnorm=0.105, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19687
2023-08-08 23:43:06 - progress_bar.py[line:272] - INFO: epoch 002:   8151 / 8233 loss=4.557, loss_v1=0, loss_v2=0, nll_loss=3.259, ntokens=338.7, nsentences=48, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=283.3, ups=0.84, wpb=338.7, bsz=48, num_updates=16360, lr=2.0544e-07, gnorm=0.107, clip=0, loss_scale=64, train_wall=12, gb_free=14.5, wall=19699
2023-08-08 23:43:18 - progress_bar.py[line:272] - INFO: epoch 002:   8161 / 8233 loss=4.534, loss_v1=0, loss_v2=0, nll_loss=3.237, ntokens=339.3, nsentences=48, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=283.5, ups=0.84, wpb=339.3, bsz=48, num_updates=16370, lr=1.86059e-07, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19711
2023-08-08 23:43:30 - progress_bar.py[line:272] - INFO: epoch 002:   8171 / 8233 loss=4.602, loss_v1=0, loss_v2=0, nll_loss=3.312, ntokens=340.4, nsentences=48, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=9.93, wps=284.6, ups=0.84, wpb=340.4, bsz=48, num_updates=16380, lr=1.66677e-07, gnorm=0.104, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19723
2023-08-08 23:43:42 - progress_bar.py[line:272] - INFO: epoch 002:   8181 / 8233 loss=4.494, loss_v1=0, loss_v2=0, nll_loss=3.188, ntokens=336.4, nsentences=48, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=279.1, ups=0.83, wpb=336.4, bsz=48, num_updates=16390, lr=1.47296e-07, gnorm=0.1, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19735
2023-08-08 23:43:54 - progress_bar.py[line:272] - INFO: epoch 002:   8191 / 8233 loss=4.578, loss_v1=0, loss_v2=0, nll_loss=3.28, ntokens=341, nsentences=48, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=9.71, wps=286.2, ups=0.84, wpb=341, bsz=48, num_updates=16400, lr=1.27915e-07, gnorm=0.103, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19747
2023-08-08 23:44:06 - progress_bar.py[line:272] - INFO: epoch 002:   8201 / 8233 loss=4.534, loss_v1=0, loss_v2=0, nll_loss=3.236, ntokens=335.5, nsentences=48, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=9.42, wps=280.3, ups=0.84, wpb=335.5, bsz=48, num_updates=16410, lr=1.08534e-07, gnorm=0.102, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19759
2023-08-08 23:44:18 - progress_bar.py[line:272] - INFO: epoch 002:   8211 / 8233 loss=4.545, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=337.3, nsentences=48, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=281.8, ups=0.84, wpb=337.3, bsz=48, num_updates=16420, lr=8.9153e-08, gnorm=0.106, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19771
2023-08-08 23:44:30 - progress_bar.py[line:272] - INFO: epoch 002:   8221 / 8233 loss=4.551, loss_v1=0, loss_v2=0, nll_loss=3.25, ntokens=337.8, nsentences=48, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=9.51, wps=282.3, ups=0.84, wpb=337.8, bsz=48, num_updates=16430, lr=6.97719e-08, gnorm=0.107, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19783
2023-08-08 23:44:42 - progress_bar.py[line:272] - INFO: epoch 002:   8231 / 8233 loss=4.516, loss_v1=0, loss_v2=0, nll_loss=3.212, ntokens=339.5, nsentences=48, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=286, ups=0.84, wpb=339.5, bsz=48, num_updates=16440, lr=5.03909e-08, gnorm=0.108, clip=0, loss_scale=128, train_wall=12, gb_free=14.5, wall=19794
2023-08-08 23:44:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 16442 updates
2023-08-08 23:44:44 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt/checkpoint2.pt
2023-08-08 23:44:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt/checkpoint2.pt
2023-08-08 23:44:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/vrd2_checkpoints/_2_3e-5_512_mix_wearing_prompt/checkpoint2.pt (epoch 2 @ 16442 updates, score None) (writing took 2.3056285260245204 seconds)
2023-08-08 23:44:46 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-08-08 23:44:46 - progress_bar.py[line:282] - INFO: epoch 002 | loss 4.617 | loss_v1 0 | loss_v2 0 | nll_loss 3.323 | ntokens 338.261 | nsentences 47.999 | sample_size 338.261 | sample_size_v1 0 | sample_size_v2 0 | ppl 10.01 | wps 281.2 | ups 0.83 | wpb 338.3 | bsz 48 | num_updates 16442 | lr 4.65146e-08 | gnorm 0.108 | clip 0 | loss_scale 128 | train_wall 9869 | gb_free 14.5 | wall 19799
2023-08-08 23:44:46 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_mix//vg_train_wearing.tsv slice_id 0 row count 395175 total row count 395175
slice_id 0 seek offset 0
2023-08-08 23:44:47 - train.py[line:214] - INFO: done training in 19798.3 seconds
2023-08-08 23:44:47 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-08 23:44:47 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  train/bsz ▁▁
wandb:                 train/clip ▁▁
wandb:              train/gb_free ▁▁
wandb:                train/gnorm █▁
wandb:                 train/loss █▁
wandb:           train/loss_scale ▁█
wandb:              train/loss_v1 ▁▁
wandb:              train/loss_v2 ▁▁
wandb:                   train/lr █▁
wandb:             train/nll_loss █▁
wandb:           train/nsentences ▁▁
wandb:              train/ntokens █▁
wandb:                  train/ppl █▁
wandb:          train/sample_size █▁
wandb:       train/sample_size_v1 ▁▁
wandb:       train/sample_size_v2 ▁▁
wandb:           train/train_wall █▁
wandb:                  train/ups ▁▁
wandb:                 train/wall ▁█
wandb:                  train/wpb ▁▁
wandb:                  train/wps ▁█
wandb:            train_inner/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_inner/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/gb_free ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          train_inner/gnorm █▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_inner/loss █▇▆▅▄▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/loss_scale ▁▁▁▁▂▁▁▂▂▂▂▂▃▂▃▂▃▂▂▃▃▄▄▄▃▃▃▃▄█▄▃▄▃▄███▄▃
wandb:        train_inner/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             train_inner/lr ▂▄████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       train_inner/nll_loss ██▆▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/ntokens ▃▆▆▅▅▅▆▄▇▄█▇▇▁▅▇▅▄▄▄▅▅▄▆▇▆▅▆▆▄▇▆▄▁▅▅▆▇▆▅
wandb:            train_inner/ppl █▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train_inner/sample_size ▃▆▆▅▅▅▆▄▇▄█▇▇▁▅▇▅▄▄▄▅▅▄▆▇▆▅▆▆▄▇▆▄▁▅▅▆▇▆▅
wandb: train_inner/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_inner/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/train_wall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            train_inner/ups ▅▅▅▅▅▅█▅█▅█▅▅▁█▅█▅▅▅▅▅▅██▅▅▅█▁██▅▁█▅████
wandb:           train_inner/wall ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train_inner/wpb ▃▆▆▅▅▅▆▄▇▄█▇▇▁▅▇▅▄▄▄▅▅▄▆▇▆▅▆▆▄▇▆▄▁▅▅▆▇▆▅
wandb:            train_inner/wps ▃▅▆▄▄▅▇▄▇▅█▆▇▁▆▆▆▄▄▄▅▅▄▇▇▆▅▆▇▄▇▆▄▁▆▅▆▇▆▆
wandb: 
wandb: Run summary:
wandb:                  train/bsz 48.0
wandb:                 train/clip 0.0
wandb:              train/gb_free 14.5
wandb:                train/gnorm 0.108
wandb:                 train/loss 4.617
wandb:           train/loss_scale 128.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 3.323
wandb:           train/nsentences 47.999
wandb:              train/ntokens 338.261
wandb:                  train/ppl 10.01
wandb:          train/sample_size 338.261
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 9869.0
wandb:                  train/ups 0.83
wandb:                 train/wall 19799.0
wandb:                  train/wpb 338.3
wandb:                  train/wps 281.2
wandb:            train_inner/bsz 48.0
wandb:           train_inner/clip 0.0
wandb:        train_inner/gb_free 14.5
wandb:          train_inner/gnorm 0.108
wandb:           train_inner/loss 4.516
wandb:     train_inner/loss_scale 128.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 3.212
wandb:     train_inner/nsentences 48.0
wandb:        train_inner/ntokens 339.5
wandb:            train_inner/ppl 9.27
wandb:    train_inner/sample_size 339.5
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 12.0
wandb:            train_inner/ups 0.84
wandb:           train_inner/wall 19794.0
wandb:            train_inner/wpb 339.5
wandb:            train_inner/wps 286.0
wandb: 
wandb: 🚀 View run _2_3e-5_512_mix_wearing_prompt at: https://wandb.ai/jackcai1206/OFA-VG/runs/3h1afsvo
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230808_181449-3h1afsvo/logs
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
